{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sequence-to-sequence Tensorflow model for Amazon reviews\n",
    "\n",
    "This notebook walks through training a [Sequence to sequence model](https://www.tensorflow.org/tutorials/seq2seq) with Tensorflow (version 1.1).\n",
    "\n",
    "The model is currently used as the predictive backend for the SUMZ chrome extension, which takes in Amazon reviews on the current web page and displays a small summary of each review. The model is trained on the the [Amazon fine food reviews dataset.](https://www.kaggle.com/snap/amazon-fine-food-reviews) from Kaggle, which consists of 568K review-summary pairs.\n",
    "\n",
    "This notebook goes through the following:\n",
    "- Building a sequence-to-sequence model using Tensorflow\n",
    "- Using the preprocessed data from the data_preprocessing notebook to train the model\n",
    "- Exporting the model into ProtoBuff format for serving in a production environment\n",
    "\n",
    "This builds on the [Text Summarization](https://github.com/Currie32/Text-Summarization-with-Amazon-Reviews) project by David Currie (this [Medium post](https://medium.com/towards-data-science/text-summarization-with-amazon-reviews-41801c2210b) goes into excellent detail as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "from tensorflow.contrib.rnn import GRUCell, LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_input_placeholders():\n",
    "    \"\"\"\n",
    "    Create model input placeholders\n",
    "    : return: placeholder tensors\n",
    "    \"\"\"    \n",
    "    inputs = tf.placeholder(tf.int32, [None,None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None,None])\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    keep_probability = tf.placeholder(tf.float32, name='keep_probability')\n",
    "    target_seq_len = tf.placeholder(tf.int32, (None,), name='target_seq_len')\n",
    "    max_target_seq_len = tf.reduce_max(target_seq_len, name='max_target_seq_len')\n",
    "    source_seq_len = tf.placeholder(tf.int32, (None,), name='source_seq_len')\n",
    "    \n",
    "    return inputs, targets, learning_rate, keep_probability, target_seq_len, max_target_seq_len, source_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def embedded_encoder_input(input_data, word_embedding_matrix):\n",
    "    return tf.nn.embedding_lookup(word_embedding_matrix, input_data)\n",
    "\n",
    "def encoding_layer(encoder_inputs, rnn_size, \n",
    "                   source_seq_len, num_layers, \n",
    "                   keep_prob, \n",
    "                   encoder_style, \n",
    "                   base_cell):\n",
    "    \"\"\"\n",
    "    Works with bidirectional and regular (unidirectional RNN)\n",
    "    as specificed by the 'encoder_style' parameter that can be either\n",
    "    'bidirectional_rnn' or 'unidirectional_rnn'\n",
    "    \n",
    "    Also can be passed in either a LSTMCell or GRUCell for 'LSTMCell' param\n",
    "    \"\"\"\n",
    "\n",
    "    if encoder_style == 'unidirectional_rnn':\n",
    "        print(\"UNIDIRECTIONAL ENCODER\")\n",
    "        print(\"ENCODER BASE CELL IS\", base_cell)\n",
    "        def make_cell(rnn_size):\n",
    "            if base_cell == 'LSTM':\n",
    "                enc_cell = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.random_uniform_initializer(-0.1,0.1,seed=2))\n",
    "                enc_cell = tf.contrib.rnn.DropoutWrapper(enc_cell, output_keep_prob=keep_prob)\n",
    "            else:\n",
    "                enc_cell = tf.contrib.rnn.GRUCell(rnn_size)\n",
    "                enc_cell = tf.contrib.rnn.DropoutWrapper(enc_cell, output_keep_prob=keep_prob)           \n",
    "            return enc_cell\n",
    "        enc_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])\n",
    "        enc_output, enc_state = tf.nn.dynamic_rnn(enc_cell, \n",
    "                                                  encoder_inputs, \n",
    "                                                  sequence_length=source_seq_len, \n",
    "                                                  dtype=tf.float32)\n",
    "        \n",
    "    else:\n",
    "        print(\"BIDRECTIONAL ENCODER\")\n",
    "        print(\"ENCODER BASE CELL IS\", base_cell)\n",
    "        for layer in range(num_layers):\n",
    "            with tf.variable_scope('encoder_{}'.format(layer)):\n",
    "                \n",
    "                if base_cell =='LSTM':\n",
    "                    fwCell = tf.contrib.rnn.LSTMCell(num_units = rnn_size,\n",
    "                                                      initializer = tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "                    bwCell = tf.contrib.rnn.LSTMCell(num_units = rnn_size,\n",
    "                                                      initializer = tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "                else:\n",
    "                    fwCell = tf.contrib.rnn.GRUCell(num_units = rnn_size)\n",
    "                    bwCell = tf.contrib.rnn.GRUCell(num_units = rnn_size)\n",
    "                \n",
    "#                 fwCell = base_cell(rnn_size)\n",
    "#                 bwCell = base_cell(rnn_size)\n",
    "                single_rnn_cell_forward = tf.contrib.rnn.DropoutWrapper(cell = fwCell,\n",
    "                                                                        output_keep_prob = keep_prob)\n",
    "                single_rnn_cell_backward = tf.contrib.rnn.DropoutWrapper(cell = bwCell,\n",
    "                                                                         output_keep_prob = keep_prob)\n",
    "                enc_output, enc_state = tf.nn.bidirectional_dynamic_rnn(single_rnn_cell_forward,\n",
    "                                                                        single_rnn_cell_backward,\n",
    "                                                                        encoder_inputs,\n",
    "                                                                        source_seq_len,\n",
    "                                                                        dtype = tf.float32)\n",
    "        enc_output = tf.concat(enc_output, 2) # Concatenate both outputs together\n",
    "        \n",
    "    return enc_output, enc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_decoder_input(target_data, vocab_to_int, batch_size):\n",
    "\n",
    "    # Remove the last word (integer) from each target sequence\n",
    "    ending = tf.strided_slice(target_data, [0,0], [batch_size,-1], [1,1])\n",
    "    \n",
    "    # Add the <GO> token to each target sequence\n",
    "    decoder_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n",
    "    \n",
    "    return decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def embedded_decoder_input(input_data, word_embedding_matrix):\n",
    "    return tf.nn.embedding_lookup(word_embedding_matrix, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_decoder_cell(rnn_size, \n",
    "                      num_layers, \n",
    "                      encoder_output, \n",
    "                      source_seq_len, \n",
    "                      keep_prob,\n",
    "                      batch_size,\n",
    "                      encoder_state, \n",
    "                      attention, \n",
    "                      base_cell):\n",
    "\n",
    "    \"\"\"\n",
    "    Works with either GRU or basic LSTM cells, as 'GRUCell' or 'BasicLSTM'\n",
    "    for the 'cell_style' parameter\n",
    "    \n",
    "    Also works with or without Attention mechanism, as specified by the\n",
    "    'attention' parameter\n",
    "    \n",
    "    [@TODO Allow different attention mechanisms for comparison]\n",
    "    \"\"\"    \n",
    "    print(\"DECODER BASE CELL\", base_cell)\n",
    "    if attention == True:\n",
    "        print(\"DECODER ATTENTOIN IS TRUE\")\n",
    "        for layer in range(num_layers):\n",
    "            with tf.variable_scope('decoder_{}'.format(layer)):\n",
    "                if base_cell =='LSTM':\n",
    "                    single_cell = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                                  initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "#                     dec_cell = tf.contrib.rnn.DropoutWrapper(single_cell, input_keep_prob=keep_prob)\n",
    "                else:\n",
    "                    single_cell = tf.contrib.rnn.GRUCell(rnn_size)\n",
    "                dec_cell = tf.contrib.rnn.DropoutWrapper(single_cell, input_keep_prob=keep_prob)                    \n",
    "                    \n",
    "#                     dec_cell = tf.contrib.rnn.DropoutWrapper(base_cell(rnn_size), output_keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(rnn_size,\n",
    "                                                                   encoder_output,\n",
    "                                                                   source_seq_len,\n",
    "                                                                   normalize=False,\n",
    "                                                                   name='BahdanauAttention')\n",
    "\n",
    "        dec_cell = tf.contrib.seq2seq.DynamicAttentionWrapper(dec_cell,\n",
    "                                                              attention_mechanism,\n",
    "                                                              rnn_size)\n",
    "\n",
    "        initial_state = tf.contrib.seq2seq.DynamicAttentionWrapperState(encoder_state[0],\n",
    "                                                                        _zero_state_tensors(rnn_size, \n",
    "                                                                                            batch_size, \n",
    "                                                                                            tf.float32))\n",
    "    \n",
    "    else:\n",
    "        print(\"DECODER ATTENTION IS FALSE\")\n",
    "        def make_cell(rnn_size):\n",
    "            if base_cell == 'LSTM':\n",
    "                dec_cell = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.random_uniform_initializer(-0.1,0.1,seed=2))\n",
    "                dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, output_keep_prob=keep_prob)\n",
    "            else:\n",
    "                dec_cell = tf.contrib.rnn.GRUCell(rnn_size)\n",
    "                dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, output_keep_prob=keep_prob)           \n",
    "            return dec_cell            \n",
    "#             return tf.contrib.rnn.DropoutWrapper(base_cell(rnn_size), output_keep_prob=keep_prob)\n",
    "\n",
    "        dec_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])\n",
    "        initial_state = encoder_state\n",
    "        \n",
    "    return dec_cell, initial_state \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer(input_data,\n",
    "                   word_embedding_matrix,\n",
    "                   num_layers, \n",
    "                   rnn_size, \n",
    "                   keep_prob, \n",
    "                   encoder_output, \n",
    "                   source_seq_len,\n",
    "                   encoder_state,\n",
    "                   batch_size,\n",
    "                   vocab_size,\n",
    "                   target_seq_len,\n",
    "                   max_target_seq_len,\n",
    "                   vocab_to_int,\n",
    "                   attention,\n",
    "                   base_cell):\n",
    "    \n",
    "    decoder_embedded_input = embedded_decoder_input(input_data, word_embedding_matrix)\n",
    "    decoder_cell, initial_state = make_decoder_cell(rnn_size, \n",
    "                                                    num_layers, \n",
    "                                                    encoder_output, \n",
    "                                                    source_seq_len, \n",
    "                                                    keep_prob, \n",
    "                                                    batch_size,\n",
    "                                                    encoder_state,\n",
    "                                                    attention=attention,\n",
    "                                                    base_cell=base_cell\n",
    "                                                   )\n",
    "    \n",
    "    output_layer = Dense(vocab_size,\n",
    "                        kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "\n",
    "    # Training\n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=decoder_embedded_input,\n",
    "                                                            sequence_length = target_seq_len,\n",
    "                                                            time_major=False)\n",
    "        training_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell,\n",
    "                                                           training_helper,\n",
    "                                                           initial_state,\n",
    "                                                           output_layer)\n",
    "        training_logits, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                               output_time_major=False,\n",
    "                                                               impute_finished=True,\n",
    "                                                               maximum_iterations=max_target_seq_len)\n",
    "    \n",
    "    with tf.variable_scope(\"decode\", reuse=True): # Reuse same params for inference\n",
    "        \n",
    "        start_tokens = tf.tile(tf.constant([vocab_to_int['<GO>']], dtype=tf.int32), \n",
    "                               [batch_size], \n",
    "                               name='start_tokens')\n",
    "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(word_embedding_matrix,\n",
    "                                                                    start_tokens,\n",
    "                                                                    vocab_to_int['<EOS>'])\n",
    "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell,\n",
    "                                                            inference_helper,\n",
    "                                                            initial_state,\n",
    "                                                            output_layer)\n",
    "        inference_logits, _ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                              output_time_major=False,\n",
    "                                                              impute_finished=True,\n",
    "                                                              maximum_iterations=max_target_seq_len)\n",
    "    \n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def full_seq2seq(input_data, \n",
    "                 word_embedding_matrix,\n",
    "                 rnn_size,\n",
    "                 source_seq_len,\n",
    "                 num_layers,\n",
    "                 keep_prob,\n",
    "                 target_data,\n",
    "                 vocab_to_int,\n",
    "                 batch_size,\n",
    "                 vocab_size,\n",
    "                 target_seq_len,\n",
    "                 max_target_seq_len,\n",
    "                 encoder_style,\n",
    "                 attention,\n",
    "                 base_cell\n",
    "                 ):\n",
    "    \n",
    "\n",
    "    \n",
    "    # Encoding layer\n",
    "    encoder_inputs = embedded_encoder_input(input_data, word_embedding_matrix)\n",
    "    encoder_output, encoder_state = encoding_layer(encoder_inputs, \n",
    "                                                   rnn_size, \n",
    "                                                   source_seq_len, \n",
    "                                                   num_layers, \n",
    "                                                   keep_prob,\n",
    "                                                   encoder_style=encoder_style,\n",
    "                                                   base_cell=base_cell)\n",
    "    \n",
    "    # Decoding layer\n",
    "    processed_decoder_input = process_decoder_input(target_data, \n",
    "                                                    vocab_to_int, \n",
    "                                                    batch_size)\n",
    "    training_logits, inference_logits = decoding_layer(processed_decoder_input,\n",
    "                                                       word_embedding_matrix,\n",
    "                                                       num_layers, \n",
    "                                                       rnn_size, \n",
    "                                                       keep_prob, \n",
    "                                                       encoder_output, \n",
    "                                                       source_seq_len,\n",
    "                                                       encoder_state,\n",
    "                                                       batch_size,\n",
    "                                                       vocab_size,\n",
    "                                                       target_seq_len,\n",
    "                                                       max_target_seq_len,\n",
    "                                                       vocab_to_int,\n",
    "                                                       attention=attention,\n",
    "                                                       base_cell=base_cell)\n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pad_batch(batch_to_pad):\n",
    "    max_size = max([len(item) for item in batch_to_pad])\n",
    "    padded_batch = [item + [vocab_to_int['<PAD>']] * (max_size - len(item)) for item in batch_to_pad]\n",
    "    return padded_batch\n",
    "\n",
    "def get_batches(summaries, reviews, batch_size):\n",
    "    for batch_i in range(0, len(reviews)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        summaries_batch = summaries[start_i:start_i + batch_size]\n",
    "        reviews_batch = reviews[start_i:start_i + batch_size]\n",
    "        pad_summaries_batch = pad_batch(summaries_batch)\n",
    "        pad_reviews_batch = pad_batch(reviews_batch)\n",
    "        pad_summaries_lengths = []\n",
    "        for summary in pad_summaries_batch:\n",
    "            pad_summaries_lengths.append(len(summary))\n",
    "        pad_reviews_lengths = []\n",
    "        for review in pad_reviews_batch:\n",
    "            pad_reviews_lengths.append(len(review))\n",
    "        \n",
    "        yield pad_summaries_batch, pad_reviews_batch, pad_summaries_lengths, pad_reviews_lengths\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10\n",
    "rnn_size = 256\n",
    "batch_size = 64\n",
    "num_layers = 2\n",
    "lr = 0.001\n",
    "keep_prob = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_and_train_model(word_embedding_matrix, \n",
    "                rnn_size,\n",
    "                num_layers,\n",
    "                keep_probability,\n",
    "                vocab_to_int,\n",
    "                batch_size,\n",
    "                sorted_summaries,\n",
    "                sorted_reviews,\n",
    "                encoder_style='unidirectional_rnn',\n",
    "                attention=True,\n",
    "                base_cell='LSTM',\n",
    "                checkpoint_file='./model_checkpoints/best_model.ckpt',\n",
    "                losses_arr_path='./checkpointed_data/losses/LOSS_ARR.p'):\n",
    "    \n",
    "\n",
    "    # GRAPH BUILDING\n",
    "    train_graph = tf.Graph()\n",
    "    with train_graph.as_default():\n",
    "        \n",
    "        # Model inputs\n",
    "        inputs, targets, learning_rate, keep_probability, target_seq_len, max_target_seq_len, source_seq_len = model_input_placeholders()\n",
    "        \n",
    "        # Create final logits tensors\n",
    "        training_logits, inference_logits = full_seq2seq(tf.reverse(inputs, [-1]),\n",
    "                                                         word_embedding_matrix,\n",
    "                                                         rnn_size,\n",
    "                                                         source_seq_len,\n",
    "                                                         num_layers,\n",
    "                                                         keep_probability,\n",
    "                                                         targets,\n",
    "                                                         vocab_to_int,\n",
    "                                                         batch_size,\n",
    "                                                         len(vocab_to_int)+1,\n",
    "                                                         target_seq_len,\n",
    "                                                         max_target_seq_len,                  \n",
    "                                                         encoder_style=encoder_style,\n",
    "                                                         attention=attention,\n",
    "                                                         base_cell=base_cell)\n",
    "\n",
    "        training_logits = tf.identity(training_logits.rnn_output, 'logits')\n",
    "        inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "        \n",
    "        masks = tf.sequence_mask(target_seq_len, max_target_seq_len, dtype=tf.float32, name='masks')\n",
    "        \n",
    "        # Set up optimizer\n",
    "        with tf.name_scope(\"optimization\"):\n",
    "            \n",
    "            cost = tf.contrib.seq2seq.sequence_loss(training_logits,\n",
    "                                                    targets,\n",
    "                                                    masks)\n",
    "            \n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            \n",
    "            gradients = optimizer.compute_gradients(cost)\n",
    "            capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "            train_operation = optimizer.apply_gradients(capped_gradients)\n",
    "\n",
    "     \n",
    "    \n",
    "    start = 200000\n",
    "    end = start + 50000\n",
    "    sorted_summaries_short = sorted_summaries[start:end]\n",
    "    sorted_reviews_short = sorted_reviews[start:end]\n",
    "    \n",
    "    display_step = 20 # Check training loss after every 20 batches\n",
    "    stop = 10 # Stop training if average loss doesn't decrease in this mean update_checks\n",
    "    per_epoch = 5 # update checks per epoch\n",
    "    update_check = (len(sorted_reviews_short)//batch_size//per_epoch)-1\n",
    "\n",
    "    update_loss = 0 \n",
    "    batch_loss = 0\n",
    "    summary_update_loss = [] # Record the update losses for saving improvements in the model\n",
    "    avg_update_loss = [] # Record avg updates, for charting\n",
    "    batch_infos = [] # losses and times for each batch, for charting\n",
    "\n",
    "    checkpoint = checkpoint_file\n",
    "    \n",
    "    with tf.Session(graph=train_graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch_i in range(1, epochs+1):\n",
    "            update_loss = 0\n",
    "            batch_loss = 0\n",
    "            for batch_i, (summaries_batch, reviews_batch, summaries_lengths, reviews_lengths) in enumerate(\n",
    "                    get_batches(sorted_summaries_short, sorted_reviews_short, batch_size)):\n",
    "                start_time = time.time()\n",
    "                _, loss = sess.run(\n",
    "                    [train_operation, cost],\n",
    "                    {inputs: reviews_batch,\n",
    "                     targets: summaries_batch,\n",
    "                     learning_rate: lr,\n",
    "                     target_seq_len: summaries_lengths,\n",
    "                     source_seq_len: reviews_lengths,\n",
    "                     keep_probability: keep_prob})\n",
    "\n",
    "                batch_loss += loss\n",
    "                update_loss += loss\n",
    "                end_time = time.time()\n",
    "                batch_time = end_time - start_time\n",
    "                batch_infos.append((round(loss,3),round(batch_time,3)))\n",
    "#                 print(batch_infos)\n",
    "\n",
    "                if batch_i % display_step == 0 and batch_i > 0:\n",
    "                    print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
    "                          .format(epoch_i,\n",
    "                                  epochs, \n",
    "                                  batch_i, \n",
    "                                  len(sorted_reviews_short) // batch_size, \n",
    "                                  batch_loss / display_step, \n",
    "                                  batch_time*display_step))\n",
    "                    batch_loss = 0\n",
    "\n",
    "                if batch_i % update_check == 0 and batch_i > 0:\n",
    "                    print(\"Average loss for this update:\", round(update_loss/update_check,3), end=\"\")\n",
    "                    summary_update_loss.append(update_loss)\n",
    "#                     avg_update_loss.append(round(update_loss/update_check,3))\n",
    "#                     print(\"DUMPING TO\", losses_arr_path)\n",
    "#                     pickle.dump(avg_update_loss, open(losses_arr_path, 'wb'))\n",
    "                    pickle.dump(batch_infos, open(losses_arr_path, 'wb'))\n",
    "\n",
    "                    # If the update loss is at a new minimum, save the model\n",
    "                    if update_loss <= min(summary_update_loss):\n",
    "                        print(' -- New Record!') \n",
    "                        stop_early = 0\n",
    "                        saver = tf.train.Saver() \n",
    "                        saver.save(sess, checkpoint)\n",
    "\n",
    "                    else:\n",
    "                        print(\"-- No Improvement.\")\n",
    "                        stop_early += 1\n",
    "                        if stop_early == stop:\n",
    "                            break\n",
    "                    update_loss = 0\n",
    "    print(\"\\n=====Finished training!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_pickled_data():\n",
    "    word_dicts_path = './checkpointed_data/word_dicts.p'\n",
    "    model_input_data_path = './checkpointed_data/model_input_data.p'\n",
    "    vocab_to_int, int_to_vocab, word_embedding_matrix = pickle.load(open(word_dicts_path, mode='rb'))\n",
    "    sorted_summaries, sorted_reviews = pickle.load(open(model_input_data_path, mode='rb'))\n",
    "    return vocab_to_int, int_to_vocab, word_embedding_matrix, sorted_summaries, sorted_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab_to_int, int_to_vocab, word_embedding_matrix, sorted_summaries, sorted_reviews = load_pickled_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######\n",
      "Training bidirectional / GRUCell / NO Attention\n",
      "#######\n",
      "BIDRECTIONAL ENCODER\n",
      "ENCODER BASE CELL IS GRU\n",
      "DECODER BASE CELL GRU\n",
      "DECODER ATTENTION IS FALSE\n",
      "Epoch   1/10 Batch   20/781 - Loss:  5.413, Seconds: 4.95\n",
      "Epoch   1/10 Batch   40/781 - Loss:  3.181, Seconds: 5.31\n",
      "Epoch   1/10 Batch   60/781 - Loss:  3.023, Seconds: 4.34\n",
      "Epoch   1/10 Batch   80/781 - Loss:  2.873, Seconds: 5.32\n",
      "Epoch   1/10 Batch  100/781 - Loss:  2.942, Seconds: 4.68\n",
      "Epoch   1/10 Batch  120/781 - Loss:  2.858, Seconds: 4.67\n",
      "Epoch   1/10 Batch  140/781 - Loss:  2.765, Seconds: 4.67\n",
      "Average loss for this update: 3.249 -- New Record!\n",
      "Epoch   1/10 Batch  160/781 - Loss:  2.773, Seconds: 5.35\n",
      "Epoch   1/10 Batch  180/781 - Loss:  2.695, Seconds: 5.03\n",
      "Epoch   1/10 Batch  200/781 - Loss:  2.789, Seconds: 4.37\n",
      "Epoch   1/10 Batch  220/781 - Loss:  2.796, Seconds: 4.70\n",
      "Epoch   1/10 Batch  240/781 - Loss:  2.760, Seconds: 3.71\n",
      "Epoch   1/10 Batch  260/781 - Loss:  2.611, Seconds: 4.71\n",
      "Epoch   1/10 Batch  280/781 - Loss:  2.511, Seconds: 5.38\n",
      "Epoch   1/10 Batch  300/781 - Loss:  2.589, Seconds: 4.71\n",
      "Average loss for this update: 2.674 -- New Record!\n",
      "Epoch   1/10 Batch  320/781 - Loss:  2.669, Seconds: 4.71\n",
      "Epoch   1/10 Batch  340/781 - Loss:  2.824, Seconds: 3.75\n",
      "Epoch   1/10 Batch  360/781 - Loss:  2.610, Seconds: 5.41\n",
      "Epoch   1/10 Batch  380/781 - Loss:  2.612, Seconds: 5.41\n",
      "Epoch   1/10 Batch  400/781 - Loss:  2.449, Seconds: 5.37\n",
      "Epoch   1/10 Batch  420/781 - Loss:  2.480, Seconds: 4.42\n",
      "Epoch   1/10 Batch  440/781 - Loss:  2.456, Seconds: 4.71\n",
      "Epoch   1/10 Batch  460/781 - Loss:  2.667, Seconds: 4.77\n",
      "Average loss for this update: 2.591 -- New Record!\n",
      "Epoch   1/10 Batch  480/781 - Loss:  2.620, Seconds: 4.42\n",
      "Epoch   1/10 Batch  500/781 - Loss:  2.560, Seconds: 5.44\n",
      "Epoch   1/10 Batch  520/781 - Loss:  2.560, Seconds: 5.11\n",
      "Epoch   1/10 Batch  540/781 - Loss:  2.524, Seconds: 4.10\n",
      "Epoch   1/10 Batch  560/781 - Loss:  2.496, Seconds: 4.43\n",
      "Epoch   1/10 Batch  580/781 - Loss:  2.575, Seconds: 4.45\n",
      "Epoch   1/10 Batch  600/781 - Loss:  2.527, Seconds: 4.12\n",
      "Epoch   1/10 Batch  620/781 - Loss:  2.691, Seconds: 5.13\n",
      "Average loss for this update: 2.57 -- New Record!\n",
      "Epoch   1/10 Batch  640/781 - Loss:  2.594, Seconds: 5.47\n",
      "Epoch   1/10 Batch  660/781 - Loss:  2.541, Seconds: 4.79\n",
      "Epoch   1/10 Batch  680/781 - Loss:  2.498, Seconds: 4.44\n",
      "Epoch   1/10 Batch  700/781 - Loss:  2.376, Seconds: 5.47\n",
      "Epoch   1/10 Batch  720/781 - Loss:  2.445, Seconds: 4.84\n",
      "Epoch   1/10 Batch  740/781 - Loss:  2.628, Seconds: 3.83\n",
      "Epoch   1/10 Batch  760/781 - Loss:  2.566, Seconds: 4.17\n",
      "Average loss for this update: 2.505 -- New Record!\n",
      "Epoch   1/10 Batch  780/781 - Loss:  2.371, Seconds: 4.84\n",
      "Epoch   2/10 Batch   20/781 - Loss:  2.458, Seconds: 4.98\n",
      "Epoch   2/10 Batch   40/781 - Loss:  2.313, Seconds: 5.32\n",
      "Epoch   2/10 Batch   60/781 - Loss:  2.369, Seconds: 4.34\n",
      "Epoch   2/10 Batch   80/781 - Loss:  2.278, Seconds: 5.31\n",
      "Epoch   2/10 Batch  100/781 - Loss:  2.367, Seconds: 4.66\n",
      "Epoch   2/10 Batch  120/781 - Loss:  2.303, Seconds: 4.68\n",
      "Epoch   2/10 Batch  140/781 - Loss:  2.234, Seconds: 4.67\n",
      "Average loss for this update: 2.329 -- New Record!\n",
      "Epoch   2/10 Batch  160/781 - Loss:  2.255, Seconds: 5.32\n",
      "Epoch   2/10 Batch  180/781 - Loss:  2.187, Seconds: 5.04\n",
      "Epoch   2/10 Batch  200/781 - Loss:  2.293, Seconds: 4.38\n",
      "Epoch   2/10 Batch  220/781 - Loss:  2.307, Seconds: 4.73\n",
      "Epoch   2/10 Batch  240/781 - Loss:  2.269, Seconds: 3.72\n",
      "Epoch   2/10 Batch  260/781 - Loss:  2.130, Seconds: 4.72\n",
      "Epoch   2/10 Batch  280/781 - Loss:  2.027, Seconds: 5.36\n",
      "Epoch   2/10 Batch  300/781 - Loss:  2.121, Seconds: 4.70\n",
      "Average loss for this update: 2.184 -- New Record!\n",
      "Epoch   2/10 Batch  320/781 - Loss:  2.195, Seconds: 4.74\n",
      "Epoch   2/10 Batch  340/781 - Loss:  2.388, Seconds: 3.73\n",
      "Epoch   2/10 Batch  360/781 - Loss:  2.198, Seconds: 5.37\n",
      "Epoch   2/10 Batch  380/781 - Loss:  2.207, Seconds: 5.40\n",
      "Epoch   2/10 Batch  400/781 - Loss:  2.054, Seconds: 5.43\n",
      "Epoch   2/10 Batch  420/781 - Loss:  2.055, Seconds: 4.41\n",
      "Epoch   2/10 Batch  440/781 - Loss:  2.052, Seconds: 4.74\n",
      "Epoch   2/10 Batch  460/781 - Loss:  2.243, Seconds: 4.76\n",
      "Average loss for this update: 2.176 -- New Record!\n",
      "Epoch   2/10 Batch  480/781 - Loss:  2.233, Seconds: 4.45\n",
      "Epoch   2/10 Batch  500/781 - Loss:  2.158, Seconds: 5.43\n",
      "Epoch   2/10 Batch  520/781 - Loss:  2.177, Seconds: 5.09\n",
      "Epoch   2/10 Batch  540/781 - Loss:  2.107, Seconds: 4.11\n",
      "Epoch   2/10 Batch  560/781 - Loss:  2.080, Seconds: 4.43\n",
      "Epoch   2/10 Batch  580/781 - Loss:  2.170, Seconds: 4.45\n",
      "Epoch   2/10 Batch  600/781 - Loss:  2.148, Seconds: 4.14\n",
      "Epoch   2/10 Batch  620/781 - Loss:  2.349, Seconds: 5.14\n",
      "Average loss for this update: 2.178-- No Improvement.\n",
      "Epoch   2/10 Batch  640/781 - Loss:  2.218, Seconds: 5.47\n",
      "Epoch   2/10 Batch  660/781 - Loss:  2.190, Seconds: 4.80\n",
      "Epoch   2/10 Batch  680/781 - Loss:  2.093, Seconds: 4.47\n",
      "Epoch   2/10 Batch  700/781 - Loss:  2.023, Seconds: 5.45\n",
      "Epoch   2/10 Batch  720/781 - Loss:  2.098, Seconds: 4.86\n",
      "Epoch   2/10 Batch  740/781 - Loss:  2.324, Seconds: 3.83\n",
      "Epoch   2/10 Batch  760/781 - Loss:  2.277, Seconds: 4.19\n",
      "Average loss for this update: 2.165 -- New Record!\n",
      "Epoch   2/10 Batch  780/781 - Loss:  2.089, Seconds: 4.85\n",
      "Epoch   3/10 Batch   20/781 - Loss:  2.220, Seconds: 4.98\n",
      "Epoch   3/10 Batch   40/781 - Loss:  2.086, Seconds: 5.31\n",
      "Epoch   3/10 Batch   60/781 - Loss:  2.117, Seconds: 4.32\n",
      "Epoch   3/10 Batch   80/781 - Loss:  2.030, Seconds: 5.31\n",
      "Epoch   3/10 Batch  100/781 - Loss:  2.110, Seconds: 4.68\n",
      "Epoch   3/10 Batch  120/781 - Loss:  2.035, Seconds: 4.69\n",
      "Epoch   3/10 Batch  140/781 - Loss:  1.971, Seconds: 4.67\n",
      "Average loss for this update: 2.078 -- New Record!\n",
      "Epoch   3/10 Batch  160/781 - Loss:  1.989, Seconds: 5.34\n",
      "Epoch   3/10 Batch  180/781 - Loss:  1.950, Seconds: 5.05\n",
      "Epoch   3/10 Batch  200/781 - Loss:  2.041, Seconds: 4.36\n",
      "Epoch   3/10 Batch  220/781 - Loss:  2.057, Seconds: 4.71\n",
      "Epoch   3/10 Batch  240/781 - Loss:  2.005, Seconds: 3.72\n",
      "Epoch   3/10 Batch  260/781 - Loss:  1.876, Seconds: 4.70\n",
      "Epoch   3/10 Batch  280/781 - Loss:  1.766, Seconds: 5.38\n",
      "Epoch   3/10 Batch  300/781 - Loss:  1.878, Seconds: 4.71\n",
      "Average loss for this update: 1.931 -- New Record!\n",
      "Epoch   3/10 Batch  320/781 - Loss:  1.937, Seconds: 4.74\n",
      "Epoch   3/10 Batch  340/781 - Loss:  2.163, Seconds: 3.74\n",
      "Epoch   3/10 Batch  360/781 - Loss:  1.974, Seconds: 5.39\n",
      "Epoch   3/10 Batch  380/781 - Loss:  1.974, Seconds: 5.40\n",
      "Epoch   3/10 Batch  400/781 - Loss:  1.831, Seconds: 5.38\n",
      "Epoch   3/10 Batch  420/781 - Loss:  1.811, Seconds: 4.41\n",
      "Epoch   3/10 Batch  440/781 - Loss:  1.831, Seconds: 4.74\n",
      "Epoch   3/10 Batch  460/781 - Loss:  2.002, Seconds: 4.76\n",
      "Average loss for this update: 1.945-- No Improvement.\n",
      "Epoch   3/10 Batch  480/781 - Loss:  2.012, Seconds: 4.45\n",
      "Epoch   3/10 Batch  500/781 - Loss:  1.931, Seconds: 5.42\n",
      "Epoch   3/10 Batch  520/781 - Loss:  1.948, Seconds: 5.10\n",
      "Epoch   3/10 Batch  540/781 - Loss:  1.857, Seconds: 4.10\n",
      "Epoch   3/10 Batch  560/781 - Loss:  1.837, Seconds: 4.46\n",
      "Epoch   3/10 Batch  580/781 - Loss:  1.922, Seconds: 4.44\n",
      "Epoch   3/10 Batch  600/781 - Loss:  1.917, Seconds: 4.14\n",
      "Epoch   3/10 Batch  620/781 - Loss:  2.143, Seconds: 5.10\n",
      "Average loss for this update: 1.946-- No Improvement.\n",
      "Epoch   3/10 Batch  640/781 - Loss:  1.983, Seconds: 5.47\n",
      "Epoch   3/10 Batch  660/781 - Loss:  1.952, Seconds: 4.81\n",
      "Epoch   3/10 Batch  680/781 - Loss:  1.832, Seconds: 4.48\n",
      "Epoch   3/10 Batch  700/781 - Loss:  1.789, Seconds: 5.43\n",
      "Epoch   3/10 Batch  720/781 - Loss:  1.871, Seconds: 4.83\n",
      "Epoch   3/10 Batch  740/781 - Loss:  2.125, Seconds: 3.84\n",
      "Epoch   3/10 Batch  760/781 - Loss:  2.095, Seconds: 4.15\n",
      "Average loss for this update: 1.944-- No Improvement.\n",
      "Epoch   3/10 Batch  780/781 - Loss:  1.912, Seconds: 4.85\n",
      "Epoch   4/10 Batch   20/781 - Loss:  2.075, Seconds: 4.98\n",
      "Epoch   4/10 Batch   40/781 - Loss:  1.923, Seconds: 5.35\n",
      "Epoch   4/10 Batch   60/781 - Loss:  1.933, Seconds: 4.33\n",
      "Epoch   4/10 Batch   80/781 - Loss:  1.841, Seconds: 5.32\n",
      "Epoch   4/10 Batch  100/781 - Loss:  1.914, Seconds: 4.70\n",
      "Epoch   4/10 Batch  120/781 - Loss:  1.819, Seconds: 4.67\n",
      "Epoch   4/10 Batch  140/781 - Loss:  1.766, Seconds: 4.67\n",
      "Average loss for this update: 1.891 -- New Record!\n",
      "Epoch   4/10 Batch  160/781 - Loss:  1.789, Seconds: 5.34\n",
      "Epoch   4/10 Batch  180/781 - Loss:  1.767, Seconds: 5.04\n",
      "Epoch   4/10 Batch  200/781 - Loss:  1.849, Seconds: 4.36\n",
      "Epoch   4/10 Batch  220/781 - Loss:  1.865, Seconds: 4.71\n",
      "Epoch   4/10 Batch  240/781 - Loss:  1.808, Seconds: 3.71\n",
      "Epoch   4/10 Batch  260/781 - Loss:  1.684, Seconds: 4.71\n",
      "Epoch   4/10 Batch  280/781 - Loss:  1.576, Seconds: 5.38\n",
      "Epoch   4/10 Batch  300/781 - Loss:  1.696, Seconds: 4.70\n",
      "Average loss for this update: 1.741 -- New Record!\n",
      "Epoch   4/10 Batch  320/781 - Loss:  1.742, Seconds: 4.74\n",
      "Epoch   4/10 Batch  340/781 - Loss:  1.978, Seconds: 3.74\n",
      "Epoch   4/10 Batch  360/781 - Loss:  1.804, Seconds: 5.42\n",
      "Epoch   4/10 Batch  380/781 - Loss:  1.788, Seconds: 5.42\n",
      "Epoch   4/10 Batch  400/781 - Loss:  1.652, Seconds: 5.42\n",
      "Epoch   4/10 Batch  420/781 - Loss:  1.619, Seconds: 4.40\n",
      "Epoch   4/10 Batch  440/781 - Loss:  1.653, Seconds: 4.72\n",
      "Epoch   4/10 Batch  460/781 - Loss:  1.813, Seconds: 4.76\n",
      "Average loss for this update: 1.761-- No Improvement.\n",
      "Epoch   4/10 Batch  480/781 - Loss:  1.829, Seconds: 4.44\n",
      "Epoch   4/10 Batch  500/781 - Loss:  1.755, Seconds: 5.44\n",
      "Epoch   4/10 Batch  520/781 - Loss:  1.759, Seconds: 5.11\n",
      "Epoch   4/10 Batch  540/781 - Loss:  1.643, Seconds: 4.17\n",
      "Epoch   4/10 Batch  560/781 - Loss:  1.642, Seconds: 4.46\n",
      "Epoch   4/10 Batch  580/781 - Loss:  1.732, Seconds: 4.43\n",
      "Epoch   4/10 Batch  600/781 - Loss:  1.742, Seconds: 4.14\n",
      "Epoch   4/10 Batch  620/781 - Loss:  1.949, Seconds: 5.13\n",
      "Average loss for this update: 1.756-- No Improvement.\n",
      "Epoch   4/10 Batch  640/781 - Loss:  1.792, Seconds: 5.46\n",
      "Epoch   4/10 Batch  660/781 - Loss:  1.776, Seconds: 4.82\n",
      "Epoch   4/10 Batch  680/781 - Loss:  1.634, Seconds: 4.48\n",
      "Epoch   4/10 Batch  700/781 - Loss:  1.607, Seconds: 5.46\n",
      "Epoch   4/10 Batch  720/781 - Loss:  1.693, Seconds: 4.83\n",
      "Epoch   4/10 Batch  740/781 - Loss:  1.969, Seconds: 3.86\n",
      "Epoch   4/10 Batch  760/781 - Loss:  1.933, Seconds: 4.17\n",
      "Average loss for this update: 1.768-- No Improvement.\n",
      "Epoch   4/10 Batch  780/781 - Loss:  1.760, Seconds: 4.85\n",
      "Epoch   5/10 Batch   20/781 - Loss:  1.952, Seconds: 4.96\n",
      "Epoch   5/10 Batch   40/781 - Loss:  1.794, Seconds: 5.33\n",
      "Epoch   5/10 Batch   60/781 - Loss:  1.771, Seconds: 4.34\n",
      "Epoch   5/10 Batch   80/781 - Loss:  1.687, Seconds: 5.37\n",
      "Epoch   5/10 Batch  100/781 - Loss:  1.758, Seconds: 4.65\n",
      "Epoch   5/10 Batch  120/781 - Loss:  1.649, Seconds: 4.67\n",
      "Epoch   5/10 Batch  140/781 - Loss:  1.605, Seconds: 4.67\n",
      "Average loss for this update: 1.739 -- New Record!\n",
      "Epoch   5/10 Batch  160/781 - Loss:  1.631, Seconds: 5.33\n",
      "Epoch   5/10 Batch  180/781 - Loss:  1.628, Seconds: 5.04\n",
      "Epoch   5/10 Batch  200/781 - Loss:  1.684, Seconds: 4.36\n",
      "Epoch   5/10 Batch  220/781 - Loss:  1.700, Seconds: 4.72\n",
      "Epoch   5/10 Batch  240/781 - Loss:  1.641, Seconds: 3.72\n",
      "Epoch   5/10 Batch  260/781 - Loss:  1.534, Seconds: 4.71\n",
      "Epoch   5/10 Batch  280/781 - Loss:  1.421, Seconds: 5.37\n",
      "Epoch   5/10 Batch  300/781 - Loss:  1.557, Seconds: 4.70\n",
      "Average loss for this update: 1.587 -- New Record!\n",
      "Epoch   5/10 Batch  320/781 - Loss:  1.582, Seconds: 4.74\n",
      "Epoch   5/10 Batch  340/781 - Loss:  1.802, Seconds: 3.75\n",
      "Epoch   5/10 Batch  360/781 - Loss:  1.653, Seconds: 5.40\n",
      "Epoch   5/10 Batch  380/781 - Loss:  1.621, Seconds: 5.40\n",
      "Epoch   5/10 Batch  400/781 - Loss:  1.500, Seconds: 5.40\n",
      "Epoch   5/10 Batch  420/781 - Loss:  1.460, Seconds: 4.40\n",
      "Epoch   5/10 Batch  440/781 - Loss:  1.504, Seconds: 4.74\n",
      "Epoch   5/10 Batch  460/781 - Loss:  1.644, Seconds: 4.79\n",
      "Average loss for this update: 1.601-- No Improvement.\n",
      "Epoch   5/10 Batch  480/781 - Loss:  1.679, Seconds: 4.44\n",
      "Epoch   5/10 Batch  500/781 - Loss:  1.584, Seconds: 5.41\n",
      "Epoch   5/10 Batch  520/781 - Loss:  1.599, Seconds: 5.07\n",
      "Epoch   5/10 Batch  540/781 - Loss:  1.481, Seconds: 4.11\n",
      "Epoch   5/10 Batch  560/781 - Loss:  1.486, Seconds: 4.46\n",
      "Epoch   5/10 Batch  580/781 - Loss:  1.575, Seconds: 4.44\n",
      "Epoch   5/10 Batch  600/781 - Loss:  1.588, Seconds: 4.17\n",
      "Epoch   5/10 Batch  620/781 - Loss:  1.789, Seconds: 5.14\n",
      "Average loss for this update: 1.596-- No Improvement.\n",
      "Epoch   5/10 Batch  640/781 - Loss:  1.626, Seconds: 5.46\n",
      "Epoch   5/10 Batch  660/781 - Loss:  1.615, Seconds: 4.81\n",
      "Epoch   5/10 Batch  680/781 - Loss:  1.471, Seconds: 4.50\n",
      "Epoch   5/10 Batch  700/781 - Loss:  1.458, Seconds: 5.49\n",
      "Epoch   5/10 Batch  720/781 - Loss:  1.543, Seconds: 4.84\n",
      "Epoch   5/10 Batch  740/781 - Loss:  1.818, Seconds: 3.84\n",
      "Epoch   5/10 Batch  760/781 - Loss:  1.785, Seconds: 4.17\n",
      "Average loss for this update: 1.616-- No Improvement.\n",
      "Epoch   5/10 Batch  780/781 - Loss:  1.636, Seconds: 4.85\n",
      "Epoch   6/10 Batch   20/781 - Loss:  1.840, Seconds: 4.98\n",
      "Epoch   6/10 Batch   40/781 - Loss:  1.671, Seconds: 5.36\n",
      "Epoch   6/10 Batch   60/781 - Loss:  1.642, Seconds: 4.33\n",
      "Epoch   6/10 Batch   80/781 - Loss:  1.561, Seconds: 5.36\n",
      "Epoch   6/10 Batch  100/781 - Loss:  1.620, Seconds: 4.70\n",
      "Epoch   6/10 Batch  120/781 - Loss:  1.507, Seconds: 4.66\n",
      "Epoch   6/10 Batch  140/781 - Loss:  1.462, Seconds: 4.68\n",
      "Average loss for this update: 1.609-- No Improvement.\n",
      "Epoch   6/10 Batch  160/781 - Loss:  1.507, Seconds: 5.32\n",
      "Epoch   6/10 Batch  180/781 - Loss:  1.498, Seconds: 5.02\n",
      "Epoch   6/10 Batch  200/781 - Loss:  1.552, Seconds: 4.38\n",
      "Epoch   6/10 Batch  220/781 - Loss:  1.556, Seconds: 4.71\n",
      "Epoch   6/10 Batch  240/781 - Loss:  1.500, Seconds: 3.70\n",
      "Epoch   6/10 Batch  260/781 - Loss:  1.407, Seconds: 4.70\n",
      "Epoch   6/10 Batch  280/781 - Loss:  1.298, Seconds: 5.38\n",
      "Epoch   6/10 Batch  300/781 - Loss:  1.435, Seconds: 4.72\n",
      "Average loss for this update: 1.457 -- New Record!\n",
      "Epoch   6/10 Batch  320/781 - Loss:  1.457, Seconds: 4.75\n",
      "Epoch   6/10 Batch  340/781 - Loss:  1.653, Seconds: 3.78\n",
      "Epoch   6/10 Batch  360/781 - Loss:  1.518, Seconds: 5.41\n",
      "Epoch   6/10 Batch  380/781 - Loss:  1.496, Seconds: 5.40\n",
      "Epoch   6/10 Batch  400/781 - Loss:  1.373, Seconds: 5.37\n",
      "Epoch   6/10 Batch  420/781 - Loss:  1.335, Seconds: 4.42\n",
      "Epoch   6/10 Batch  440/781 - Loss:  1.380, Seconds: 4.75\n",
      "Epoch   6/10 Batch  460/781 - Loss:  1.517, Seconds: 4.79\n",
      "Average loss for this update: 1.471-- No Improvement.\n",
      "Epoch   6/10 Batch  480/781 - Loss:  1.543, Seconds: 4.43\n",
      "Epoch   6/10 Batch  500/781 - Loss:  1.452, Seconds: 5.43\n",
      "Epoch   6/10 Batch  520/781 - Loss:  1.471, Seconds: 5.12\n",
      "Epoch   6/10 Batch  540/781 - Loss:  1.338, Seconds: 4.09\n",
      "Epoch   6/10 Batch  560/781 - Loss:  1.363, Seconds: 4.44\n",
      "Epoch   6/10 Batch  580/781 - Loss:  1.440, Seconds: 4.44\n",
      "Epoch   6/10 Batch  600/781 - Loss:  1.457, Seconds: 4.12\n",
      "Epoch   6/10 Batch  620/781 - Loss:  1.642, Seconds: 5.16\n",
      "Average loss for this update: 1.462-- No Improvement.\n",
      "Epoch   6/10 Batch  640/781 - Loss:  1.497, Seconds: 5.47\n",
      "Epoch   6/10 Batch  660/781 - Loss:  1.486, Seconds: 4.86\n",
      "Epoch   6/10 Batch  680/781 - Loss:  1.337, Seconds: 4.50\n",
      "Epoch   6/10 Batch  700/781 - Loss:  1.344, Seconds: 5.47\n",
      "Epoch   6/10 Batch  720/781 - Loss:  1.423, Seconds: 4.84\n",
      "Epoch   6/10 Batch  740/781 - Loss:  1.690, Seconds: 3.83\n",
      "Epoch   6/10 Batch  760/781 - Loss:  1.682, Seconds: 4.18\n",
      "Average loss for this update: 1.495-- No Improvement.\n",
      "Epoch   6/10 Batch  780/781 - Loss:  1.525, Seconds: 4.86\n",
      "Epoch   7/10 Batch   20/781 - Loss:  1.728, Seconds: 4.97\n",
      "Epoch   7/10 Batch   40/781 - Loss:  1.557, Seconds: 5.34\n",
      "Epoch   7/10 Batch   60/781 - Loss:  1.528, Seconds: 4.34\n",
      "Epoch   7/10 Batch   80/781 - Loss:  1.449, Seconds: 5.35\n",
      "Epoch   7/10 Batch  100/781 - Loss:  1.509, Seconds: 4.66\n",
      "Epoch   7/10 Batch  120/781 - Loss:  1.386, Seconds: 4.69\n",
      "Epoch   7/10 Batch  140/781 - Loss:  1.346, Seconds: 4.67\n",
      "Average loss for this update: 1.495-- No Improvement.\n",
      "Epoch   7/10 Batch  160/781 - Loss:  1.398, Seconds: 5.31\n",
      "Epoch   7/10 Batch  180/781 - Loss:  1.391, Seconds: 5.05\n",
      "Epoch   7/10 Batch  200/781 - Loss:  1.430, Seconds: 4.37\n",
      "Epoch   7/10 Batch  220/781 - Loss:  1.435, Seconds: 4.73\n",
      "Epoch   7/10 Batch  240/781 - Loss:  1.387, Seconds: 3.72\n",
      "Epoch   7/10 Batch  260/781 - Loss:  1.299, Seconds: 4.73\n",
      "Epoch   7/10 Batch  280/781 - Loss:  1.187, Seconds: 5.40\n",
      "Epoch   7/10 Batch  300/781 - Loss:  1.328, Seconds: 4.70\n",
      "Average loss for this update: 1.345 -- New Record!\n",
      "Epoch   7/10 Batch  320/781 - Loss:  1.347, Seconds: 4.72\n",
      "Epoch   7/10 Batch  340/781 - Loss:  1.534, Seconds: 3.74\n",
      "Epoch   7/10 Batch  360/781 - Loss:  1.410, Seconds: 5.38\n",
      "Epoch   7/10 Batch  380/781 - Loss:  1.364, Seconds: 5.40\n",
      "Epoch   7/10 Batch  400/781 - Loss:  1.267, Seconds: 5.40\n",
      "Epoch   7/10 Batch  420/781 - Loss:  1.240, Seconds: 4.42\n",
      "Epoch   7/10 Batch  440/781 - Loss:  1.276, Seconds: 4.75\n",
      "Epoch   7/10 Batch  460/781 - Loss:  1.389, Seconds: 4.81\n",
      "Average loss for this update: 1.357-- No Improvement.\n",
      "Epoch   7/10 Batch  480/781 - Loss:  1.418, Seconds: 4.47\n",
      "Epoch   7/10 Batch  500/781 - Loss:  1.333, Seconds: 5.43\n",
      "Epoch   7/10 Batch  520/781 - Loss:  1.359, Seconds: 5.10\n",
      "Epoch   7/10 Batch  540/781 - Loss:  1.243, Seconds: 4.11\n",
      "Epoch   7/10 Batch  560/781 - Loss:  1.255, Seconds: 4.43\n",
      "Epoch   7/10 Batch  580/781 - Loss:  1.345, Seconds: 4.46\n",
      "Epoch   7/10 Batch  600/781 - Loss:  1.345, Seconds: 4.16\n",
      "Epoch   7/10 Batch  620/781 - Loss:  1.508, Seconds: 5.16\n",
      "Average loss for this update: 1.35-- No Improvement.\n",
      "Epoch   7/10 Batch  640/781 - Loss:  1.367, Seconds: 5.47\n",
      "Epoch   7/10 Batch  660/781 - Loss:  1.370, Seconds: 4.81\n",
      "Epoch   7/10 Batch  680/781 - Loss:  1.219, Seconds: 4.47\n",
      "Epoch   7/10 Batch  700/781 - Loss:  1.247, Seconds: 5.49\n",
      "Epoch   7/10 Batch  720/781 - Loss:  1.321, Seconds: 4.83\n",
      "Epoch   7/10 Batch  740/781 - Loss:  1.567, Seconds: 3.86\n",
      "Epoch   7/10 Batch  760/781 - Loss:  1.561, Seconds: 4.18\n",
      "Average loss for this update: 1.381-- No Improvement.\n",
      "Epoch   7/10 Batch  780/781 - Loss:  1.431, Seconds: 4.83\n",
      "Epoch   8/10 Batch   20/781 - Loss:  1.631, Seconds: 4.99\n",
      "Epoch   8/10 Batch   40/781 - Loss:  1.464, Seconds: 5.33\n",
      "Epoch   8/10 Batch   60/781 - Loss:  1.416, Seconds: 4.35\n",
      "Epoch   8/10 Batch   80/781 - Loss:  1.348, Seconds: 5.34\n",
      "Epoch   8/10 Batch  100/781 - Loss:  1.394, Seconds: 4.67\n",
      "Epoch   8/10 Batch  120/781 - Loss:  1.283, Seconds: 4.68\n",
      "Epoch   8/10 Batch  140/781 - Loss:  1.240, Seconds: 4.66\n",
      "Average loss for this update: 1.391-- No Improvement.\n",
      "Epoch   8/10 Batch  160/781 - Loss:  1.295, Seconds: 5.38\n",
      "Epoch   8/10 Batch  180/781 - Loss:  1.299, Seconds: 5.03\n",
      "Epoch   8/10 Batch  200/781 - Loss:  1.324, Seconds: 4.38\n",
      "Epoch   8/10 Batch  220/781 - Loss:  1.333, Seconds: 4.70\n",
      "Epoch   8/10 Batch  240/781 - Loss:  1.288, Seconds: 3.71\n",
      "Epoch   8/10 Batch  260/781 - Loss:  1.199, Seconds: 4.69\n",
      "Epoch   8/10 Batch  280/781 - Loss:  1.094, Seconds: 5.38\n",
      "Epoch   8/10 Batch  300/781 - Loss:  1.230, Seconds: 4.70\n",
      "Average loss for this update: 1.246 -- New Record!\n",
      "Epoch   8/10 Batch  320/781 - Loss:  1.246, Seconds: 4.73\n",
      "Epoch   8/10 Batch  340/781 - Loss:  1.411, Seconds: 3.74\n",
      "Epoch   8/10 Batch  360/781 - Loss:  1.306, Seconds: 5.41\n",
      "Epoch   8/10 Batch  380/781 - Loss:  1.263, Seconds: 5.39\n",
      "Epoch   8/10 Batch  400/781 - Loss:  1.177, Seconds: 5.40\n",
      "Epoch   8/10 Batch  420/781 - Loss:  1.140, Seconds: 4.40\n",
      "Epoch   8/10 Batch  440/781 - Loss:  1.182, Seconds: 4.74\n",
      "Epoch   8/10 Batch  460/781 - Loss:  1.290, Seconds: 4.79\n",
      "Average loss for this update: 1.256-- No Improvement.\n",
      "Epoch   8/10 Batch  480/781 - Loss:  1.323, Seconds: 4.46\n",
      "Epoch   8/10 Batch  500/781 - Loss:  1.242, Seconds: 5.45\n",
      "Epoch   8/10 Batch  520/781 - Loss:  1.275, Seconds: 5.09\n",
      "Epoch   8/10 Batch  540/781 - Loss:  1.141, Seconds: 4.12\n",
      "Epoch   8/10 Batch  560/781 - Loss:  1.174, Seconds: 4.46\n",
      "Epoch   8/10 Batch  580/781 - Loss:  1.240, Seconds: 4.45\n",
      "Epoch   8/10 Batch  600/781 - Loss:  1.248, Seconds: 4.14\n",
      "Epoch   8/10 Batch  620/781 - Loss:  1.397, Seconds: 5.13\n",
      "Average loss for this update: 1.254-- No Improvement.\n",
      "Epoch   8/10 Batch  640/781 - Loss:  1.276, Seconds: 5.43\n",
      "Epoch   8/10 Batch  660/781 - Loss:  1.273, Seconds: 4.82\n",
      "Epoch   8/10 Batch  680/781 - Loss:  1.121, Seconds: 4.48\n",
      "Epoch   8/10 Batch  700/781 - Loss:  1.152, Seconds: 5.47\n",
      "Epoch   8/10 Batch  720/781 - Loss:  1.226, Seconds: 4.84\n",
      "Epoch   8/10 Batch  740/781 - Loss:  1.473, Seconds: 3.84\n",
      "Epoch   8/10 Batch  760/781 - Loss:  1.472, Seconds: 4.22\n",
      "Average loss for this update: 1.287-- No Improvement.\n",
      "Epoch   8/10 Batch  780/781 - Loss:  1.339, Seconds: 4.83\n",
      "Epoch   9/10 Batch   20/781 - Loss:  1.535, Seconds: 4.98\n",
      "Epoch   9/10 Batch   40/781 - Loss:  1.372, Seconds: 5.35\n",
      "Epoch   9/10 Batch   60/781 - Loss:  1.332, Seconds: 4.34\n",
      "Epoch   9/10 Batch   80/781 - Loss:  1.268, Seconds: 5.31\n",
      "Epoch   9/10 Batch  100/781 - Loss:  1.305, Seconds: 4.66\n",
      "Epoch   9/10 Batch  120/781 - Loss:  1.188, Seconds: 4.69\n",
      "Epoch   9/10 Batch  140/781 - Loss:  1.154, Seconds: 4.68\n",
      "Average loss for this update: 1.304-- No Improvement.\n",
      "Epoch   9/10 Batch  160/781 - Loss:  1.224, Seconds: 5.35\n",
      "Epoch   9/10 Batch  180/781 - Loss:  1.210, Seconds: 5.04\n",
      "Epoch   9/10 Batch  200/781 - Loss:  1.240, Seconds: 4.36\n",
      "Epoch   9/10 Batch  220/781 - Loss:  1.237, Seconds: 4.69\n",
      "Epoch   9/10 Batch  240/781 - Loss:  1.197, Seconds: 3.69\n",
      "Epoch   9/10 Batch  260/781 - Loss:  1.120, Seconds: 4.72\n",
      "Epoch   9/10 Batch  280/781 - Loss:  1.030, Seconds: 5.37\n",
      "Epoch   9/10 Batch  300/781 - Loss:  1.155, Seconds: 4.70\n",
      "Average loss for this update: 1.164 -- New Record!\n",
      "Epoch   9/10 Batch  320/781 - Loss:  1.161, Seconds: 4.73\n",
      "Epoch   9/10 Batch  340/781 - Loss:  1.314, Seconds: 3.74\n",
      "Epoch   9/10 Batch  360/781 - Loss:  1.237, Seconds: 5.40\n",
      "Epoch   9/10 Batch  380/781 - Loss:  1.183, Seconds: 5.42\n",
      "Epoch   9/10 Batch  400/781 - Loss:  1.109, Seconds: 5.42\n",
      "Epoch   9/10 Batch  420/781 - Loss:  1.068, Seconds: 4.41\n",
      "Epoch   9/10 Batch  440/781 - Loss:  1.108, Seconds: 4.73\n",
      "Epoch   9/10 Batch  460/781 - Loss:  1.189, Seconds: 4.78\n",
      "Average loss for this update: 1.176-- No Improvement.\n",
      "Epoch   9/10 Batch  480/781 - Loss:  1.232, Seconds: 4.44\n",
      "Epoch   9/10 Batch  500/781 - Loss:  1.157, Seconds: 5.42\n",
      "Epoch   9/10 Batch  520/781 - Loss:  1.189, Seconds: 5.11\n",
      "Epoch   9/10 Batch  540/781 - Loss:  1.061, Seconds: 4.12\n",
      "Epoch   9/10 Batch  560/781 - Loss:  1.083, Seconds: 4.45\n",
      "Epoch   9/10 Batch  580/781 - Loss:  1.150, Seconds: 4.44\n",
      "Epoch   9/10 Batch  600/781 - Loss:  1.160, Seconds: 4.15\n",
      "Epoch   9/10 Batch  620/781 - Loss:  1.303, Seconds: 5.13\n",
      "Average loss for this update: 1.166-- No Improvement.\n",
      "Epoch   9/10 Batch  640/781 - Loss:  1.191, Seconds: 5.46\n",
      "Epoch   9/10 Batch  660/781 - Loss:  1.190, Seconds: 4.81\n",
      "Epoch   9/10 Batch  680/781 - Loss:  1.040, Seconds: 4.47\n",
      "Epoch   9/10 Batch  700/781 - Loss:  1.082, Seconds: 5.44\n",
      "Epoch   9/10 Batch  720/781 - Loss:  1.145, Seconds: 4.83\n",
      "Epoch   9/10 Batch  740/781 - Loss:  1.385, Seconds: 3.84\n",
      "Epoch   9/10 Batch  760/781 - Loss:  1.377, Seconds: 4.20\n",
      "Average loss for this update: 1.206-- No Improvement.\n",
      "Epoch   9/10 Batch  780/781 - Loss:  1.268, Seconds: 4.82\n",
      "Epoch  10/10 Batch   20/781 - Loss:  1.452, Seconds: 5.00\n",
      "Epoch  10/10 Batch   40/781 - Loss:  1.290, Seconds: 5.32\n",
      "Epoch  10/10 Batch   60/781 - Loss:  1.250, Seconds: 4.35\n",
      "Epoch  10/10 Batch   80/781 - Loss:  1.191, Seconds: 5.35\n",
      "Epoch  10/10 Batch  100/781 - Loss:  1.223, Seconds: 4.68\n",
      "Epoch  10/10 Batch  120/781 - Loss:  1.116, Seconds: 4.70\n",
      "Epoch  10/10 Batch  140/781 - Loss:  1.080, Seconds: 4.67\n",
      "Average loss for this update: 1.224-- No Improvement.\n",
      "Epoch  10/10 Batch  160/781 - Loss:  1.140, Seconds: 5.31\n",
      "Epoch  10/10 Batch  180/781 - Loss:  1.137, Seconds: 5.04\n",
      "Epoch  10/10 Batch  200/781 - Loss:  1.163, Seconds: 4.39\n",
      "Epoch  10/10 Batch  220/781 - Loss:  1.159, Seconds: 4.71\n",
      "Epoch  10/10 Batch  240/781 - Loss:  1.119, Seconds: 3.70\n",
      "Epoch  10/10 Batch  260/781 - Loss:  1.046, Seconds: 4.71\n",
      "Epoch  10/10 Batch  280/781 - Loss:  0.959, Seconds: 5.37\n",
      "Epoch  10/10 Batch  300/781 - Loss:  1.088, Seconds: 4.71\n",
      "Average loss for this update: 1.09 -- New Record!\n",
      "Epoch  10/10 Batch  320/781 - Loss:  1.087, Seconds: 4.79\n",
      "Epoch  10/10 Batch  340/781 - Loss:  1.228, Seconds: 3.75\n",
      "Epoch  10/10 Batch  360/781 - Loss:  1.147, Seconds: 5.41\n",
      "Epoch  10/10 Batch  380/781 - Loss:  1.100, Seconds: 5.41\n",
      "Epoch  10/10 Batch  400/781 - Loss:  1.041, Seconds: 5.41\n",
      "Epoch  10/10 Batch  420/781 - Loss:  0.998, Seconds: 4.40\n",
      "Epoch  10/10 Batch  440/781 - Loss:  1.042, Seconds: 4.73\n",
      "Epoch  10/10 Batch  460/781 - Loss:  1.123, Seconds: 4.77\n",
      "Average loss for this update: 1.1-- No Improvement.\n",
      "Epoch  10/10 Batch  480/781 - Loss:  1.161, Seconds: 4.45\n",
      "Epoch  10/10 Batch  500/781 - Loss:  1.080, Seconds: 5.42\n",
      "Epoch  10/10 Batch  520/781 - Loss:  1.123, Seconds: 5.12\n",
      "Epoch  10/10 Batch  540/781 - Loss:  1.001, Seconds: 4.13\n",
      "Epoch  10/10 Batch  560/781 - Loss:  1.032, Seconds: 4.44\n",
      "Epoch  10/10 Batch  580/781 - Loss:  1.085, Seconds: 4.44\n",
      "Epoch  10/10 Batch  600/781 - Loss:  1.083, Seconds: 4.14\n",
      "Epoch  10/10 Batch  620/781 - Loss:  1.228, Seconds: 5.12\n",
      "Average loss for this update: 1.098-- No Improvement.\n",
      "Epoch  10/10 Batch  640/781 - Loss:  1.115, Seconds: 5.49\n",
      "Epoch  10/10 Batch  660/781 - Loss:  1.130, Seconds: 4.81\n",
      "Epoch  10/10 Batch  680/781 - Loss:  0.969, Seconds: 4.50\n",
      "Epoch  10/10 Batch  700/781 - Loss:  1.019, Seconds: 5.47\n",
      "Epoch  10/10 Batch  720/781 - Loss:  1.081, Seconds: 4.84\n",
      "Epoch  10/10 Batch  740/781 - Loss:  1.308, Seconds: 3.84\n",
      "Epoch  10/10 Batch  760/781 - Loss:  1.300, Seconds: 4.18\n",
      "Average loss for this update: 1.136-- No Improvement.\n",
      "Epoch  10/10 Batch  780/781 - Loss:  1.194, Seconds: 4.84\n",
      "\n",
      "=====Finished training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LSTM_UNI_ATTN_CHECKPOINTDIR = './model_checkpoints/LSTM_UNI_ATTN/best_model.ckpt'\n",
    "LSTM_UNI_ATTN_LOSSES_PATH   = './checkpointed_data/losses/LSTM_UNI_ATTN_LOSS_ARR.p'\n",
    "GRU_UNI_ATTN_CHECKPOINTDIR = './model_checkpoints/GRU_UNI_ATTN/best_model.ckpt'\n",
    "GRU_UNI_ATTN_LOSSES_PATH   = './checkpointed_data/losses/GRU_UNI_ATTN_LOSS_ARR.p'\n",
    "LSTM_BI_ATTN_CHECKPOINTDIR = './model_checkpoints/LSTM_BI_ATTN/best_model.ckpt'\n",
    "LSTM_BI_ATTN_LOSSES_PATH   = './checkpointed_data/losses/LSTM_BI_ATTN_LOSS_ARR.p'\n",
    "GRU_BI_ATTN_CHECKPOINTDIR = './model_checkpoints/GRU_BI_ATTN/best_model.ckpt'\n",
    "GRU_BI_ATTN_LOSSES_PATH   = './checkpointed_data/losses/GRU_BI_ATTN_LOSS_ARR.p'\n",
    "\n",
    "LSTM_UNI_CHECKPOINTDIR = './model_checkpoints/LSTM_UNI/best_model.ckpt'\n",
    "LSTM_UNI_LOSSES_PATH   = './checkpointed_data/losses/LSTM_UNI_LOSS_ARR.p'\n",
    "GRU_UNI_CHECKPOINTDIR = './model_checkpoints/GRU_UNI/best_model.ckpt'\n",
    "GRU_UNI_LOSSES_PATH   = './checkpointed_data/losses/GRU_UNI_LOSS_ARR.p'\n",
    "\n",
    "LSTM_BI_CHECKPOINTDIR = './model_checkpoints/LSTM_BI/best_model.ckpt'\n",
    "LSTM_BI_LOSSES_PATH   = './checkpointed_data/losses/LSTM_BI_LOSS_ARR.p'\n",
    "GRU_BI_CHECKPOINTDIR = './model_checkpoints/GRU_BI/best_model.ckpt'\n",
    "GRU_BI_LOSSES_PATH   = './checkpointed_data/losses/GRU_BI_LOSS_ARR.p'\n",
    "\n",
    "\n",
    "# ''' \n",
    "#     ENCODER STYLE:    BIDIRECTIONAL\n",
    "#     LSTM CELL STYLE:  LSTMCell\n",
    "#     ATTENTION:        TRUE\n",
    "# '''\n",
    "# print(\"\\n#######\\nTraining Bidirectional / LSTMCell / Attention\\n#######\")\n",
    "# tf.reset_default_graph()\n",
    "# tf.set_random_seed(1)\n",
    "# build_and_train_model(word_embedding_matrix, \n",
    "#                       rnn_size,\n",
    "#                       num_layers,\n",
    "#                       keep_prob,\n",
    "#                       vocab_to_int,\n",
    "#                       batch_size,\n",
    "#                       sorted_summaries,\n",
    "#                       sorted_reviews,\n",
    "#                       encoder_style='bidirectional_rnn',\n",
    "#                       attention=True,\n",
    "#                       base_cell='LSTM',\n",
    "#                       checkpoint_file=LSTM_BI_ATTN_CHECKPOINTDIR,\n",
    "#                       losses_arr_path=LSTM_BI_ATTN_LOSSES_PATH)\n",
    "\n",
    "\n",
    "# ''' \n",
    "#     ENCODER STYLE:    UNIDIRECTIONAL\n",
    "#     LSTM CELL STYLE:  LSTMCell\n",
    "#     ATTENTION:        TRUE\n",
    "# '''\n",
    "# print(\"\\n#######\\nTraining Unidirectional / LSTMCell / Attention\\n#######\")\n",
    "# tf.reset_default_graph()\n",
    "# tf.set_random_seed(1)\n",
    "# build_and_train_model(word_embedding_matrix, \n",
    "#                       rnn_size,\n",
    "#                       num_layers,\n",
    "#                       keep_prob,\n",
    "#                       vocab_to_int,\n",
    "#                       batch_size,\n",
    "#                       sorted_summaries,\n",
    "#                       sorted_reviews,\n",
    "#                       encoder_style='unidirectional_rnn',\n",
    "#                       attention=True,\n",
    "#                       base_cell='LSTM',\n",
    "#                       checkpoint_file=LSTM_UNI_ATTN_CHECKPOINTDIR,\n",
    "#                       losses_arr_path=LSTM_UNI_ATTN_LOSSES_PATH\n",
    "#                      )\n",
    "\n",
    "# ''' \n",
    "#     ENCODER STYLE:    UNIDIRECTIONAL\n",
    "#     LSTM CELL STYLE:  GRUCell\n",
    "#     ATTENTION:        TRUE\n",
    "# '''\n",
    "# print(\"\\n#######\\nTraining Unidirectional / GRUCell / Attention\\n#######\")\n",
    "# tf.reset_default_graph()\n",
    "# tf.set_random_seed(1)\n",
    "# build_and_train_model(word_embedding_matrix, \n",
    "#                       rnn_size,\n",
    "#                       num_layers,\n",
    "#                       keep_prob,\n",
    "#                       vocab_to_int,\n",
    "#                       batch_size,\n",
    "#                       sorted_summaries,\n",
    "#                       sorted_reviews,\n",
    "#                       encoder_style='unidirectional_rnn',\n",
    "#                       attention=True,\n",
    "#                       base_cell='GRU',\n",
    "#                       checkpoint_file=GRU_UNI_ATTN_CHECKPOINTDIR,\n",
    "#                       losses_arr_path=GRU_UNI_ATTN_LOSSES_PATH)\n",
    "\n",
    "# ''' \n",
    "#     ENCODER STYLE:    BIDIRECTIONAL\n",
    "#     LSTM CELL STYLE:  GRUCell\n",
    "#     ATTENTION:        TRUE\n",
    "# '''\n",
    "# print(\"\\n#######\\nTraining Bidirectional / GRUCell / Attention\\n#######\")\n",
    "# tf.reset_default_graph()\n",
    "# tf.set_random_seed(1)\n",
    "# build_and_train_model(word_embedding_matrix, \n",
    "#                       rnn_size,\n",
    "#                       num_layers,\n",
    "#                       keep_prob,\n",
    "#                       vocab_to_int,\n",
    "#                       batch_size,\n",
    "#                       sorted_summaries,\n",
    "#                       sorted_reviews,\n",
    "#                       encoder_style='bidirectional_rnn',\n",
    "#                       attention=True,\n",
    "#                       base_cell='GRU',\n",
    "#                       checkpoint_file=GRU_BI_ATTN_CHECKPOINTDIR,\n",
    "#                       losses_arr_path=GRU_BI_ATTN_LOSSES_PATH                      \n",
    "#                      )\n",
    "\n",
    "# ''' \n",
    "#     ENCODER STYLE:    UNIDIRECTIONAL\n",
    "#     LSTM CELL STYLE:  LSTMCell\n",
    "#     ATTENTION:        FALSE\n",
    "# '''\n",
    "# print(\"\\n#######\\nTraining Unidirectional / LSTMCell / NO Attention\\n#######\")\n",
    "# tf.reset_default_graph()\n",
    "# tf.set_random_seed(1)\n",
    "# build_and_train_model(word_embedding_matrix, \n",
    "#                       rnn_size,\n",
    "#                       num_layers,\n",
    "#                       keep_prob,\n",
    "#                       vocab_to_int,\n",
    "#                       batch_size,\n",
    "#                       sorted_summaries,\n",
    "#                       sorted_reviews,\n",
    "#                       encoder_style='unidirectional_rnn',\n",
    "#                       attention=False,\n",
    "#                       base_cell='LSTM',\n",
    "#                       checkpoint_file=LSTM_UNI_CHECKPOINTDIR,\n",
    "#                       losses_arr_path=LSTM_UNI_LOSSES_PATH\n",
    "#                      )\n",
    "\n",
    "# ''' \n",
    "#     ENCODER STYLE:    UNIDIRECTIONAL\n",
    "#     LSTM CELL STYLE:  GRUCell\n",
    "#     ATTENTION:        FALSE\n",
    "# '''\n",
    "# print(\"\\n#######\\nTraining Unidirectional / GRUCell / NO Attention\\n#######\")\n",
    "# tf.reset_default_graph()\n",
    "# tf.set_random_seed(1)\n",
    "# build_and_train_model(word_embedding_matrix, \n",
    "#                       rnn_size,\n",
    "#                       num_layers,\n",
    "#                       keep_prob,\n",
    "#                       vocab_to_int,\n",
    "#                       batch_size,\n",
    "#                       sorted_summaries,\n",
    "#                       sorted_reviews,\n",
    "#                       encoder_style='unidirectional_rnn',\n",
    "#                       attention=False,\n",
    "#                       base_cell='GRU',\n",
    "#                       checkpoint_file=GRU_UNI_CHECKPOINTDIR,\n",
    "#                       losses_arr_path=GRU_UNI_LOSSES_PATH)\n",
    "\n",
    "# ''' \n",
    "#     ENCODER STYLE:    BIDIRECTIONAL\n",
    "#     LSTM CELL STYLE:  LSTMCell\n",
    "#     ATTENTION:        FALSE\n",
    "# '''\n",
    "# print(\"\\n#######\\nTraining bidirectional / LSTMCell / NO Attention\\n#######\")\n",
    "# tf.reset_default_graph()\n",
    "# tf.set_random_seed(1)\n",
    "# build_and_train_model(word_embedding_matrix, \n",
    "#                       rnn_size,\n",
    "#                       num_layers,\n",
    "#                       keep_prob,\n",
    "#                       vocab_to_int,\n",
    "#                       batch_size,\n",
    "#                       sorted_summaries,\n",
    "#                       sorted_reviews,\n",
    "#                       encoder_style='bidirectional_rnn',\n",
    "#                       attention=False,\n",
    "#                       base_cell='LSTM',\n",
    "#                       checkpoint_file=LSTM_BI_CHECKPOINTDIR,\n",
    "#                       losses_arr_path=LSTM_BI_LOSSES_PATH\n",
    "#                      )\n",
    "\n",
    "''' \n",
    "    ENCODER STYLE:    BIDIRECTIONAL\n",
    "    LSTM CELL STYLE:  GRUCell\n",
    "    ATTENTION:        FALSE\n",
    "'''\n",
    "print(\"\\n#######\\nTraining bidirectional / GRUCell / NO Attention\\n#######\")\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "build_and_train_model(word_embedding_matrix, \n",
    "                      rnn_size,\n",
    "                      num_layers,\n",
    "                      keep_prob,\n",
    "                      vocab_to_int,\n",
    "                      batch_size,\n",
    "                      sorted_summaries,\n",
    "                      sorted_reviews,\n",
    "                      encoder_style='bidirectional_rnn',\n",
    "                      attention=False,\n",
    "                      base_cell='GRU',\n",
    "                      checkpoint_file=GRU_BI_CHECKPOINTDIR,\n",
    "                      losses_arr_path=GRU_BI_LOSSES_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_BI_LOSSES:  [(10.908, 0.779), (9.8100004, 0.247), (8.5419998, 0.225), (8.1020002, 0.182), (4.717, 0.265), (4.9000001, 0.232), (4.0419998, 0.248), (5.2880001, 0.214), (4.777, 0.216), (4.283, 0.248), (4.5219998, 0.215), (3.721, 0.265), (4.5890002, 0.216), (4.9260001, 0.197), (3.306, 0.248), (3.8469999, 0.231), (4.5640001, 0.199), (3.431, 0.25), (3.5420001, 0.247), (3.0869999, 0.264), (3.3469999, 0.248), (3.4549999, 0.232), (3.322, 0.248), (3.2620001, 0.248), (3.7, 0.215), (3.1930001, 0.215), (3.1140001, 0.232), (2.78, 0.265), (3.2219999, 0.214), (2.8540001, 0.249), (3.2379999, 0.251), (3.6819999, 0.201), (3.2149999, 0.216), (3.526, 0.2), (2.7509999, 0.267), (2.7839999, 0.267), (3.783, 0.183), (3.4920001, 0.217), (2.6370001, 0.252), (3.211, 0.234), (2.3989999, 0.265), (3.2090001, 0.234), (3.3169999, 0.218), (2.836, 0.234), (3.1900001, 0.234), (2.404, 0.252), (3.4100001, 0.217), (2.845, 0.266), (3.4089999, 0.217), (4.0279999, 0.184), (2.845, 0.217), (2.605, 0.266), (2.983, 0.217), (2.477, 0.266), (2.5120001, 0.25), (3.211, 0.2), (2.7520001, 0.233), (3.582, 0.184), (2.5309999, 0.251), (3.256, 0.217), (3.05, 0.217), (2.6919999, 0.267), (2.3399999, 0.266), (2.641, 0.232), (2.938, 0.217), (2.5539999, 0.251), (2.8310001, 0.233), (3.2, 0.217), (3.2320001, 0.201), (2.516, 0.234), (2.576, 0.25), (2.5739999, 0.251), (2.7360001, 0.249), (3.4349999, 0.2), (3.5350001, 0.217), (3.5020001, 0.2), (3.2309999, 0.217), (2.7260001, 0.216), (2.9630001, 0.25), (2.6949999, 0.249), (2.5469999, 0.266), (2.9920001, 0.235), (2.9619999, 0.217), (2.9590001, 0.217), (2.5020001, 0.25), (3.4560001, 0.201), (2.8050001, 0.251), (3.0450001, 0.233), (3.3759999, 0.217), (2.5190001, 0.266), (2.744, 0.251), (2.569, 0.251), (2.7739999, 0.25), (3.184, 0.234), (3.286, 0.201), (2.5510001, 0.251), (3.3469999, 0.2), (2.4990001, 0.25), (2.993, 0.218), (3.556, 0.201), (2.7290001, 0.234), (2.4400001, 0.267), (2.8440001, 0.249), (2.4360001, 0.267), (3.1659999, 0.218), (2.809, 0.216), (3.053, 0.2), (3.1170001, 0.201), (2.5639999, 0.252), (2.707, 0.234), (3.25, 0.235), (2.448, 0.267), (3.0369999, 0.218), (3.263, 0.202), (2.437, 0.234), (3.25, 0.201), (2.608, 0.232), (2.628, 0.251), (3.7820001, 0.184), (2.4990001, 0.25), (2.8169999, 0.234), (2.5580001, 0.267), (2.9100001, 0.218), (2.2690001, 0.267), (2.7060001, 0.251), (2.4820001, 0.233), (3.013, 0.216), (2.5999999, 0.251), (2.937, 0.216), (2.3959999, 0.266), (3.1489999, 0.2), (2.414, 0.25), (3.563, 0.184), (3.033, 0.233), (3.299, 0.2), (2.365, 0.267), (3.6459999, 0.184), (2.8150001, 0.251), (2.3970001, 0.266), (2.1489999, 0.25), (2.598, 0.234), (2.707, 0.25), (2.7579999, 0.25), (3.348, 0.201), (2.9560001, 0.216), (2.9070001, 0.2), (2.655, 0.218), (3.1589999, 0.219), (2.188, 0.268), (3.2579999, 0.201), (2.243, 0.267), (3.2190001, 0.184), (3.0350001, 0.234), (2.5309999, 0.249), (2.7130001, 0.218), (2.7490001, 0.218), (2.5079999, 0.284), (2.723, 0.24), (2.9909999, 0.216), (2.645, 0.251), (2.171, 0.267), (2.395, 0.251), (2.513, 0.25), (2.8829999, 0.217), (2.836, 0.2), (2.6619999, 0.25), (3.168, 0.216), (2.7950001, 0.218), (3.395, 0.183), (3.0350001, 0.218), (2.3929999, 0.249), (2.118, 0.269), (2.967, 0.233), (2.358, 0.252), (2.325, 0.268), (2.7030001, 0.235), (2.3499999, 0.25), (2.1719999, 0.268), (2.3800001, 0.268), (3.517, 0.203), (2.9430001, 0.252), (2.9230001, 0.221), (2.756, 0.251), (2.796, 0.236), (2.1789999, 0.251), (3.5209999, 0.186), (2.5150001, 0.253), (3.237, 0.186), (3.1259999, 0.235), (2.904, 0.236), (3.132, 0.219), (2.8729999, 0.218), (2.674, 0.269), (2.757, 0.253), (3.0090001, 0.219), (2.4809999, 0.251), (2.3970001, 0.268), (2.4419999, 0.251), (2.5739999, 0.267), (2.763, 0.235), (2.717, 0.218), (3.148, 0.202), (2.5810001, 0.235), (2.575, 0.253), (2.803, 0.235), (2.385, 0.251), (3.0380001, 0.202), (2.3640001, 0.235), (3.027, 0.217), (2.47, 0.267), (2.8099999, 0.233), (2.5650001, 0.253), (3.3340001, 0.203), (3.2869999, 0.186), (2.619, 0.252), (2.7130001, 0.268), (2.6389999, 0.236), (3.0880001, 0.202), (2.9630001, 0.236), (2.635, 0.236), (2.882, 0.235), (3.027, 0.202), (3.0179999, 0.218), (2.5999999, 0.253), (3.494, 0.202), (3.026, 0.218), (2.4519999, 0.237), (2.6010001, 0.251), (2.5179999, 0.251), (2.421, 0.268), (2.404, 0.268), (2.415, 0.235), (2.4200001, 0.268), (2.8940001, 0.218), (2.7650001, 0.253), (2.875, 0.219), (2.227, 0.269), (2.74, 0.251), (2.973, 0.219), (2.9159999, 0.252), (3.402, 0.186), (3.22, 0.201), (2.2780001, 0.252), (2.286, 0.267), (2.8239999, 0.202), (2.349, 0.269), (3.1070001, 0.202), (2.513, 0.234), (2.7550001, 0.235), (3.039, 0.201), (2.5409999, 0.235), (2.2260001, 0.269), (2.1789999, 0.269), (2.9619999, 0.234), (2.7179999, 0.218), (2.6860001, 0.218), (2.54, 0.252), (2.3099999, 0.251), (2.53, 0.27), (2.5669999, 0.22), (2.5910001, 0.235), (2.1470001, 0.269), (2.5780001, 0.252), (2.5079999, 0.235), (2.171, 0.268), (3.3180001, 0.202), (2.4690001, 0.219), (2.3710001, 0.234), (3.023, 0.202), (2.711, 0.235), (2.54, 0.234), (2.2219999, 0.269), (2.813, 0.236), (2.6889999, 0.219), (2.1989999, 0.27), (2.1600001, 0.269), (2.369, 0.252), (2.362, 0.269), (2.7279999, 0.219), (2.6500001, 0.237), (2.197, 0.269), (2.1489999, 0.269), (2.299, 0.236), (2.303, 0.268), (2.7920001, 0.236), (2.7509999, 0.235), (2.277, 0.268), (2.4860001, 0.252), (2.8499999, 0.236), (2.855, 0.236), (2.2349999, 0.235), (2.6630001, 0.236), (3.0999999, 0.235), (2.5780001, 0.236), (3.3369999, 0.185), (2.533, 0.236), (2.368, 0.236), (2.098, 0.269), (2.6889999, 0.218), (3.007, 0.218), (2.4070001, 0.236), (2.756, 0.219), (2.8789999, 0.202), (2.7490001, 0.202), (2.3870001, 0.236), (2.6789999, 0.22), (2.448, 0.252), (2.707, 0.203), (2.3929999, 0.236), (2.0639999, 0.267), (3.355, 0.202), (3.2, 0.209), (1.992, 0.269), (2.7160001, 0.236), (2.223, 0.268), (2.79, 0.235), (2.72, 0.219), (2.28, 0.27), (3.6659999, 0.187), (2.553, 0.237), (2.829, 0.235), (2.6300001, 0.255), (2.9890001, 0.22), (2.3640001, 0.253), (3.573, 0.186), (2.7750001, 0.237), (2.553, 0.253), (2.6129999, 0.237), (2.256, 0.254), (2.928, 0.22), (3.2650001, 0.202), (3.0569999, 0.219), (2.707, 0.221), (2.6500001, 0.253), (3.3940001, 0.204), (2.4679999, 0.271), (2.8499999, 0.221), (2.707, 0.22), (2.503, 0.254), (3.0009999, 0.22), (3.191, 0.188), (2.0350001, 0.27), (2.3710001, 0.253), (2.556, 0.237), (3.148, 0.205), (2.51, 0.252), (2.8789999, 0.222), (2.8399999, 0.238), (2.589, 0.219), (2.4170001, 0.253), (3.29, 0.187), (2.5450001, 0.237), (2.7590001, 0.221), (3.02, 0.22), (3.0039999, 0.204), (2.7820001, 0.238), (2.2219999, 0.254), (2.783, 0.221), (2.164, 0.271), (1.98, 0.271), (2.3099999, 0.27), (2.677, 0.238), (2.5420001, 0.271), (2.7620001, 0.237), (2.438, 0.253), (2.5039999, 0.237), (2.3699999, 0.27), (2.0650001, 0.271), (3.4070001, 0.204), (2.5829999, 0.238), (3.2190001, 0.204), (2.4679999, 0.238), (2.3199999, 0.27), (2.6359999, 0.238), (2.7739999, 0.219), (2.454, 0.27), (2.619, 0.204), (3.5039999, 0.187), (2.428, 0.239), (2.3870001, 0.235), (2.092, 0.27), (2.5880001, 0.22), (2.802, 0.238), (3.1170001, 0.221), (2.161, 0.269), (2.3659999, 0.253), (2.227, 0.254), (2.414, 0.253), (2.1289999, 0.269), (2.4909999, 0.254), (2.256, 0.237), (2.3710001, 0.237), (2.4489999, 0.27), (2.5139999, 0.253), (2.4449999, 0.252), (2.2780001, 0.253), (2.1530001, 0.252), (2.5910001, 0.238), (2.793, 0.22), (2.655, 0.22), (2.1800001, 0.268), (2.2479999, 0.253), (2.178, 0.253), (2.312, 0.253), (2.046, 0.269), (2.6429999, 0.22), (2.148, 0.254), (1.992, 0.27), (2.9549999, 0.187), (2.2750001, 0.269), (2.977, 0.22), (3.0079999, 0.22), (2.2460001, 0.269), (2.7460001, 0.203), (3.131, 0.204), (2.4679999, 0.237), (2.9030001, 0.22), (2.362, 0.269), (2.102, 0.252), (2.2049999, 0.269), (2.6619999, 0.221), (2.256, 0.269), (2.599, 0.238), (2.5780001, 0.236), (2.4000001, 0.238), (2.5, 0.253), (2.3870001, 0.27), (2.786, 0.238), (2.6900001, 0.203), (2.29, 0.253), (2.4389999, 0.237), (2.7880001, 0.204), (2.4170001, 0.221), (2.0769999, 0.253), (2.0439999, 0.269), (2.773, 0.237), (2.0610001, 0.253), (2.4059999, 0.236), (3.1559999, 0.219), (2.1659999, 0.271), (2.3150001, 0.235), (2.655, 0.222), (2.3429999, 0.237), (2.2149999, 0.253), (2.7320001, 0.22), (2.8559999, 0.22), (3.1889999, 0.205), (2.6719999, 0.238), (2.839, 0.221), (2.566, 0.221), (2.0539999, 0.27), (2.9560001, 0.204), (2.5009999, 0.253), (2.267, 0.272), (2.829, 0.206), (2.6270001, 0.239), (2.5109999, 0.257), (2.8640001, 0.238), (2.8570001, 0.239), (3.243, 0.188), (2.5580001, 0.238), (2.3570001, 0.255), (2.3299999, 0.272), (2.658, 0.221), (2.7260001, 0.222), (2.632, 0.272), (1.8839999, 0.366), (3.2019999, 0.216), (2.6199999, 0.231), (2.747, 0.207), (2.2090001, 0.272), (2.7279999, 0.24), (2.0480001, 0.254), (2.471, 0.271), (3.0929999, 0.206), (3.1689999, 0.189), (2.7579999, 0.239), (2.5120001, 0.238), (2.7980001, 0.239), (2.6860001, 0.237), (2.766, 0.221), (3.151, 0.206), (2.7349999, 0.238), (3.319, 0.206), (2.5510001, 0.255), (2.388, 0.256), (2.3469999, 0.254), (2.5150001, 0.24), (2.539, 0.222), (2.4579999, 0.273), (2.401, 0.254), (2.369, 0.239), (2.325, 0.256), (2.414, 0.254), (2.9170001, 0.239), (2.3610001, 0.272), (2.517, 0.238), (2.6459999, 0.238), (2.743, 0.205), (2.359, 0.272), (2.138, 0.272), (2.691, 0.221), (2.4590001, 0.272), (2.5220001, 0.254), (2.9809999, 0.222), (2.948, 0.238), (2.5929999, 0.222), (2.247, 0.272), (2.5409999, 0.271), (2.6670001, 0.239), (2.299, 0.254), (2.3699999, 0.273), (2.4530001, 0.256), (2.9130001, 0.239), (2.747, 0.238), (2.289, 0.255), (2.543, 0.271), (2.5239999, 0.239), (2.635, 0.237), (2.342, 0.272), (2.438, 0.256), (2.55, 0.222), (2.4200001, 0.239), (2.6229999, 0.239), (2.5420001, 0.255), (2.1259999, 0.271), (2.444, 0.238), (2.49, 0.254), (2.6570001, 0.239), (2.5650001, 0.239), (2.6570001, 0.272), (2.0550001, 0.272), (2.2539999, 0.255), (2.1659999, 0.255), (2.5710001, 0.238), (2.2809999, 0.271), (2.599, 0.238), (2.944, 0.205), (2.5829999, 0.255), (2.556, 0.222), (3.405, 0.205), (2.438, 0.254), (2.5599999, 0.256), (2.6259999, 0.254), (2.5179999, 0.238), (2.4119999, 0.256), (2.9159999, 0.206), (2.5999999, 0.239), (2.323, 0.256), (2.135, 0.254), (2.1240001, 0.271), (2.921, 0.222), (2.0829999, 0.256), (2.3759999, 0.255), (2.316, 0.256), (2.704, 0.238), (2.71, 0.205), (2.6489999, 0.255), (2.464, 0.255), (2.5150001, 0.221), (2.5239999, 0.221), (2.757, 0.222), (2.576, 0.24), (2.4449999, 0.237), (2.994, 0.205), (2.9630001, 0.255), (2.1989999, 0.256), (2.1889999, 0.255), (2.6259999, 0.222), (2.4059999, 0.255), (2.6919999, 0.239), (2.4000001, 0.254), (2.2079999, 0.255), (2.5120001, 0.239), (3.0120001, 0.207), (2.332, 0.271), (2.6960001, 0.205), (2.8169999, 0.222), (2.8870001, 0.208), (2.3080001, 0.255), (2.47, 0.223), (1.867, 0.255), (2.1429999, 0.272), (2.4860001, 0.222), (2.6429999, 0.222), (2.3900001, 0.222), (2.8559999, 0.222), (2.1400001, 0.271), (3.223, 0.191), (2.9990001, 0.226), (2.2179999, 0.272), (2.5550001, 0.257), (2.0899999, 0.274), (2.575, 0.24), (2.503, 0.256), (2.733, 0.241), (2.7880001, 0.24), (2.4070001, 0.257), (2.323, 0.274), (2.6429999, 0.24), (2.95, 0.206), (2.6500001, 0.208), (2.3740001, 0.224), (2.8770001, 0.208), (2.707, 0.24), (2.55, 0.239), (2.5999999, 0.225), (2.8499999, 0.223), (2.665, 0.224), (2.5450001, 0.24), (2.1429999, 0.257), (2.773, 0.24), (2.8280001, 0.223), (3.2690001, 0.19), (2.642, 0.223), (2.977, 0.207), (2.5650001, 0.241), (2.4860001, 0.24), (2.8829999, 0.24), (3.0480001, 0.224), (2.3829999, 0.256), (2.7869999, 0.231), (3.0209999, 0.207), (2.72, 0.256), (2.3989999, 0.273), (2.569, 0.24), (2.369, 0.255), (2.4389999, 0.24), (2.7379999, 0.223), (2.2820001, 0.24), (2.451, 0.24), (2.3180001, 0.239), (2.6849999, 0.224), (2.3959999, 0.241), (2.6619999, 0.223), (2.2149999, 0.239), (2.895, 0.192), (3.1589999, 0.207), (2.881, 0.207), (2.8310001, 0.224), (2.072, 0.274), (2.527, 0.258), (2.5039999, 0.241), (3.0450001, 0.224), (2.385, 0.256), (2.7160001, 0.224), (3.155, 0.207), (2.313, 0.257), (2.003, 0.273), (2.737, 0.207), (2.737, 0.224), (2.1689999, 0.257), (2.3299999, 0.239), (3.122, 0.205), (2.523, 0.24), (2.2490001, 0.273), (2.2449999, 0.24), (2.3829999, 0.24), (2.3740001, 0.24), (2.6530001, 0.224), (2.6570001, 0.239), (2.704, 0.24), (2.1070001, 0.272), (3.2750001, 0.174), (2.217, 0.255), (2.316, 0.241), (2.3599999, 0.24), (2.4000001, 0.24), (2.7850001, 0.24), (2.3540001, 0.223), (2.7030001, 0.223), (2.2, 0.24), (2.5380001, 0.24), (2.395, 0.241), (2.3180001, 0.24), (2.648, 0.223), (3.033, 0.206), (1.8329999, 0.273), (2.2460001, 0.257), (2.974, 0.24), (2.5580001, 0.222), (2.536, 0.256), (2.1070001, 0.256), (3.007, 0.207), (2.654, 0.224), (1.869, 0.257), (2.4649999, 0.24), (2.5940001, 0.239), (2.2219999, 0.24), (2.687, 0.224), (2.0899999, 0.257), (2.3570001, 0.242), (2.7190001, 0.225), (2.4170001, 0.241), (2.391, 0.24), (2.0650001, 0.259), (2.227, 0.223), (2.0929999, 0.273), (1.882, 0.273), (2.9879999, 0.207), (2.1440001, 0.274), (2.1329999, 0.256), (2.0420001, 0.272), (1.858, 0.273), (1.896, 0.274), (2.6719999, 0.241), (2.8959999, 0.207), (2.3440001, 0.274), (2.661, 0.224), (2.3629999, 0.223), (1.776, 0.273), (2.7869999, 0.207), (2.983, 0.206), (2.0610001, 0.255), (2.6730001, 0.224), (2.7449999, 0.208), (2.556, 0.223), (2.0840001, 0.274), (3.2030001, 0.193), (2.414, 0.275), (2.747, 0.242), (2.661, 0.242), (2.158, 0.275), (2.7869999, 0.224), (2.293, 0.276), (2.8, 0.241), (2.6600001, 0.244), (2.638, 0.241), (2.7950001, 0.225), (2.368, 0.274), (3.02, 0.226), (2.3269999, 0.258), (2.3970001, 0.274), (2.4809999, 0.226), (2.7390001, 0.225), (2.4349999, 0.275), (2.777, 0.225), (2.1170001, 0.243), (2.6570001, 0.24), (3.1849999, 0.208), (3.263, 0.191), (2.362, 0.259), (2.592, 0.242), (2.392, 0.241), (2.152, 0.273), (2.635, 0.225), (2.7349999, 0.209), (2.3269999, 0.258), (2.3440001, 0.225), (2.539, 0.26), (2.1889999, 0.243), (2.6819999, 0.225), (2.513, 0.208), (3.22, 0.208), (2.0420001, 0.274), (2.1800001, 0.226), (2.8989999, 0.226), (2.358, 0.241), (3.279, 0.192), (2.875, 0.225), (3.006, 0.208), (2.372, 0.242), (2.302, 0.259), (2.082, 0.276), (2.194, 0.275), (2.473, 0.242), (2.405, 0.242), (2.9189999, 0.208), (2.609, 0.242), (2.3410001, 0.243), (2.2980001, 0.258), (2.0739999, 0.274), (2.5250001, 0.224), (2.0780001, 0.275), (2.154, 0.274), (2.5280001, 0.225), (2.7579999, 0.334), (2.04, 0.311), (2.8340001, 0.214), (2.1919999, 0.275), (2.2479999, 0.242), (2.421, 0.215), (2.494, 0.215), (2.5309999, 0.217), (2.954, 0.183), (1.946, 0.265), (2.5139999, 0.232), (2.2939999, 0.249), (2.812, 0.216), (2.3570001, 0.216), (2.0610001, 0.248), (2.3150001, 0.215), (1.877, 0.266), (2.4879999, 0.216), (2.918, 0.2), (1.804, 0.247), (2.2679999, 0.232), (2.6010001, 0.199), (2.046, 0.248), (2.3499999, 0.249), (1.948, 0.265), (2.152, 0.249), (2.1830001, 0.233), (2.2379999, 0.249), (2.2720001, 0.248), (2.569, 0.216), (2.2160001, 0.215), (2.138, 0.232), (2.013, 0.265), (2.3410001, 0.216), (2.0739999, 0.248), (2.438, 0.249), (2.8369999, 0.201), (2.352, 0.218), (2.539, 0.2), (2.0929999, 0.266), (2.0999999, 0.266), (2.8139999, 0.184), (2.658, 0.216), (2.0320001, 0.25), (2.5220001, 0.233), (1.832, 0.266), (2.5599999, 0.233), (2.5739999, 0.218), (2.1960001, 0.234), (2.526, 0.234), (1.8559999, 0.25), (2.5899999, 0.216), (2.263, 0.267), (2.576, 0.217), (3.1240001, 0.186), (2.233, 0.216), (2.0450001, 0.264), (2.2980001, 0.218), (1.979, 0.266), (1.943, 0.251), (2.6489999, 0.2), (2.178, 0.233), (2.756, 0.185), (2.023, 0.252), (2.566, 0.218), (2.4519999, 0.217), (2.0899999, 0.267), (1.789, 0.266), (2.079, 0.234), (2.358, 0.216), (1.965, 0.249), (2.2709999, 0.234), (2.5510001, 0.218), (2.5599999, 0.201), (2.085, 0.235), (1.993, 0.25), (2.0190001, 0.251), (2.1689999, 0.25), (2.73, 0.202), (2.812, 0.217), (2.717, 0.201), (2.592, 0.216), (2.1800001, 0.218), (2.414, 0.25), (2.0840001, 0.251), (2.098, 0.266), (2.3940001, 0.233), (2.3280001, 0.218), (2.3329999, 0.217), (1.998, 0.25), (2.839, 0.201), (2.2320001, 0.25), (2.4949999, 0.234), (2.6719999, 0.217), (2.0050001, 0.267), (2.1800001, 0.249), (2.1370001, 0.25), (2.2650001, 0.25), (2.5380001, 0.233), (2.5699999, 0.201), (2.0650001, 0.25), (2.7279999, 0.201), (2.033, 0.251), (2.3559999, 0.217), (2.9489999, 0.2), (2.2320001, 0.233), (2.069, 0.268), (2.3529999, 0.25), (1.965, 0.267), (2.559, 0.217), (2.2060001, 0.217), (2.48, 0.2), (2.5669999, 0.2), (2.098, 0.251), (2.1140001, 0.234), (2.6670001, 0.234), (1.969, 0.266), (2.4089999, 0.217), (2.642, 0.201), (1.905, 0.234), (2.612, 0.2), (2.063, 0.233), (2.1300001, 0.25), (3.082, 0.184), (1.921, 0.25), (2.243, 0.234), (2.0450001, 0.267), (2.3199999, 0.217), (1.878, 0.267), (2.27, 0.251), (1.9809999, 0.233), (2.414, 0.216), (2.096, 0.251), (2.428, 0.218), (1.967, 0.267), (2.5280001, 0.201), (1.937, 0.251), (2.7869999, 0.183), (2.487, 0.234), (2.6760001, 0.202), (1.957, 0.266), (2.8599999, 0.185), (2.3380001, 0.251), (1.904, 0.265), (1.719, 0.25), (2.0899999, 0.234), (2.283, 0.25), (2.247, 0.249), (2.7290001, 0.201), (2.4530001, 0.218), (2.4089999, 0.201), (2.102, 0.217), (2.6010001, 0.217), (1.789, 0.266), (2.7579999, 0.2), (1.8559999, 0.268), (2.576, 0.184), (2.4779999, 0.234), (2.0450001, 0.25), (2.161, 0.217), (2.1340001, 0.217), (2.059, 0.251), (2.1500001, 0.235), (2.4030001, 0.216), (2.1600001, 0.249), (1.706, 0.266), (1.972, 0.249), (1.989, 0.25), (2.2780001, 0.217), (2.233, 0.201), (2.1270001, 0.25), (2.5710001, 0.216), (2.303, 0.216), (2.6659999, 0.184), (2.4849999, 0.216), (1.923, 0.25), (1.729, 0.267), (2.4519999, 0.234), (1.845, 0.251), (1.975, 0.269), (2.2969999, 0.234), (1.955, 0.251), (1.8, 0.269), (1.929, 0.269), (2.7550001, 0.202), (2.4549999, 0.252), (2.415, 0.219), (2.283, 0.25), (2.3940001, 0.236), (1.6849999, 0.251), (2.858, 0.185), (2.1389999, 0.254), (2.612, 0.186), (2.589, 0.236), (2.3870001, 0.235), (2.6140001, 0.219), (2.3670001, 0.22), (2.2149999, 0.269), (2.2179999, 0.254), (2.45, 0.219), (2.0350001, 0.251), (1.994, 0.268), (2.0339999, 0.251), (2.0840001, 0.268), (2.2550001, 0.236), (2.2260001, 0.219), (2.569, 0.203), (2.0680001, 0.234), (2.1329999, 0.252), (2.345, 0.235), (1.999, 0.25), (2.5280001, 0.201), (1.845, 0.235), (2.4619999, 0.218), (2.0409999, 0.268), (2.329, 0.235), (2.109, 0.25), (2.789, 0.202), (2.677, 0.186), (2.223, 0.253), (2.276, 0.269), (2.1630001, 0.236), (2.572, 0.203), (2.503, 0.235), (2.1589999, 0.236), (2.3440001, 0.236), (2.4890001, 0.202), (2.4690001, 0.219), (2.1240001, 0.253), (2.8770001, 0.202), (2.53, 0.219), (2.056, 0.236), (2.1129999, 0.252), (2.0669999, 0.251), (2.0109999, 0.268), (1.941, 0.267), (1.96, 0.235), (1.905, 0.267), (2.332, 0.218), (2.3369999, 0.25), (2.398, 0.219), (1.7690001, 0.268), (2.3280001, 0.252), (2.4489999, 0.219), (2.4920001, 0.251), (2.7349999, 0.186), (2.582, 0.203), (1.858, 0.25), (2.003, 0.269), (2.2920001, 0.202), (1.931, 0.267), (2.5780001, 0.202), (1.993, 0.235), (2.253, 0.236), (2.54, 0.202), (2.0079999, 0.236), (1.696, 0.268), (1.783, 0.268), (2.483, 0.235), (2.2309999, 0.219), (2.194, 0.218), (2.1700001, 0.253), (1.842, 0.252), (1.992, 0.269), (2.109, 0.219), (2.0699999, 0.236), (1.635, 0.267), (2.142, 0.252), (2.0669999, 0.235), (1.696, 0.267), (2.6559999, 0.202), (1.994, 0.22), (1.808, 0.236), (2.526, 0.203), (2.2160001, 0.235), (2.029, 0.235), (1.863, 0.267), (2.2739999, 0.235), (2.161, 0.217), (1.791, 0.267), (1.7869999, 0.267), (1.931, 0.254), (1.9349999, 0.269), (2.1210001, 0.219), (2.188, 0.236), (1.711, 0.268), (1.749, 0.268), (1.832, 0.236), (1.942, 0.269), (2.382, 0.235), (2.3510001, 0.235), (1.877, 0.268), (2.076, 0.251), (2.2750001, 0.236), (2.4579999, 0.235), (1.851, 0.235), (2.1300001, 0.237), (2.5840001, 0.234), (2.155, 0.236), (2.7750001, 0.188), (2.1029999, 0.235), (1.816, 0.235), (1.646, 0.267), (2.1059999, 0.218), (2.368, 0.218), (1.934, 0.235), (2.25, 0.218), (2.4230001, 0.202), (2.125, 0.203), (1.9220001, 0.235), (2.1719999, 0.219), (2.0639999, 0.252), (2.237, 0.202), (1.875, 0.235), (1.66, 0.268), (2.6559999, 0.202), (2.4189999, 0.278), (1.709, 0.319), (2.2219999, 0.247), (1.761, 0.269), (2.312, 0.235), (2.3199999, 0.22), (1.9349999, 0.269), (3.174, 0.188), (2.1889999, 0.237), (2.48, 0.237), (2.2360001, 0.254), (2.579, 0.221), (1.928, 0.254), (3.003, 0.187), (2.3789999, 0.238), (2.152, 0.253), (2.217, 0.237), (1.949, 0.253), (2.4630001, 0.22), (2.7550001, 0.205), (2.529, 0.221), (2.3050001, 0.221), (2.323, 0.253), (2.8800001, 0.204), (2.062, 0.27), (2.424, 0.221), (2.3740001, 0.219), (2.0840001, 0.254), (2.46, 0.22), (2.6659999, 0.187), (1.773, 0.27), (1.943, 0.254), (2.1819999, 0.235), (2.645, 0.204), (2.1359999, 0.255), (2.487, 0.221), (2.3499999, 0.237), (2.2, 0.22), (2.0179999, 0.253), (2.7219999, 0.187), (2.1329999, 0.236), (2.2690001, 0.222), (2.5510001, 0.221), (2.47, 0.205), (2.3859999, 0.237), (1.896, 0.253), (2.378, 0.219), (1.788, 0.269), (1.652, 0.27), (1.973, 0.269), (2.2650001, 0.237), (2.0780001, 0.269), (2.4070001, 0.237), (2.092, 0.253), (2.0999999, 0.237), (1.979, 0.27), (1.745, 0.27), (2.8239999, 0.203), (2.154, 0.238), (2.7130001, 0.204), (2.0539999, 0.238), (2.039, 0.27), (2.2390001, 0.237), (2.3929999, 0.222), (2.131, 0.27), (2.181, 0.204), (2.8410001, 0.187), (2.0599999, 0.237), (2.1070001, 0.238), (1.744, 0.27), (2.1949999, 0.221), (2.3410001, 0.236), (2.612, 0.22), (1.79, 0.269), (1.934, 0.253), (1.858, 0.254), (2.0150001, 0.253), (1.783, 0.271), (2.0599999, 0.253), (1.9450001, 0.236), (2.0179999, 0.237), (2.1289999, 0.27), (2.141, 0.254), (2.046, 0.254), (1.7970001, 0.254), (1.804, 0.253), (2.1949999, 0.235), (2.3540001, 0.221), (2.2249999, 0.221), (1.847, 0.271), (1.795, 0.252), (1.714, 0.255), (1.91, 0.254), (1.671, 0.271), (2.164, 0.22), (1.762, 0.254), (1.675, 0.27), (2.372, 0.188), (1.947, 0.272), (2.4389999, 0.221), (2.5639999, 0.221), (1.882, 0.27), (2.2460001, 0.205), (2.6459999, 0.204), (2.017, 0.236), (2.4960001, 0.221), (1.92, 0.27), (1.696, 0.254), (1.964, 0.271), (2.224, 0.221), (1.864, 0.27), (2.1800001, 0.237), (2.1730001, 0.237), (2.043, 0.237), (2.0580001, 0.254), (2.0599999, 0.269), (2.3659999, 0.237), (2.2880001, 0.204), (1.8940001, 0.254), (2.0350001, 0.236), (2.4230001, 0.205), (1.876, 0.221), (1.651, 0.253), (1.738, 0.271), (2.306, 0.236), (1.7079999, 0.253), (1.978, 0.236), (2.7219999, 0.221), (1.7589999, 0.27), (1.927, 0.237), (2.2880001, 0.221), (2.01, 0.236), (1.807, 0.253), (2.2279999, 0.22), (2.3940001, 0.222), (2.678, 0.206), (2.0680001, 0.238), (2.437, 0.22), (2.1110001, 0.221), (1.778, 0.27), (2.5150001, 0.204), (2.181, 0.255), (1.9220001, 0.271), (2.349, 0.205), (2.3269999, 0.237), (2.108, 0.255), (2.4170001, 0.24), (2.3940001, 0.239), (2.707, 0.189), (2.1470001, 0.238), (1.998, 0.256), (2.0510001, 0.272), (2.2079999, 0.222), (2.326, 0.221), (2.277, 0.271), (1.595, 0.272), (2.744, 0.191), (2.2939999, 0.222), (2.2820001, 0.205), (1.914, 0.272), (2.2969999, 0.238), (1.733, 0.255), (2.102, 0.272), (2.5899999, 0.205), (2.6800001, 0.189), (2.3150001, 0.237), (2.2019999, 0.239), (2.464, 0.239), (2.2780001, 0.238), (2.316, 0.222), (2.7130001, 0.206), (2.289, 0.238), (2.8, 0.205), (2.132, 0.257), (1.933, 0.255), (1.978, 0.255), (2.1700001, 0.239), (2.1059999, 0.222), (2.0810001, 0.271), (2.0339999, 0.255), (2.0179999, 0.238), (1.992, 0.255), (2.105, 0.255), (2.461, 0.239), (1.9809999, 0.271), (2.049, 0.239), (2.2780001, 0.239), (2.234, 0.206), (2.0020001, 0.272), (1.807, 0.271), (2.289, 0.223), (2.049, 0.272), (2.1259999, 0.255), (2.5320001, 0.222), (2.4909999, 0.237), (2.1889999, 0.223), (1.966, 0.272), (2.2030001, 0.272), (2.2539999, 0.239), (1.899, 0.254), (2.082, 0.271), (2.056, 0.254), (2.506, 0.239), (2.3380001, 0.238), (1.913, 0.256), (2.1789999, 0.271), (2.1659999, 0.238), (2.1949999, 0.239), (2.049, 0.272), (2.0639999, 0.255), (2.1919999, 0.224), (2.013, 0.238), (2.2060001, 0.238), (2.2520001, 0.254), (1.839, 0.271), (1.973, 0.238), (2.007, 0.254), (2.2379999, 0.242), (2.2, 0.24), (2.2950001, 0.271), (1.7690001, 0.272), (1.821, 0.255), (1.841, 0.256), (2.158, 0.239), (1.831, 0.271), (2.052, 0.239), (2.54, 0.205), (2.1040001, 0.256), (1.959, 0.222), (2.8610001, 0.205), (2.0, 0.256), (2.142, 0.257), (2.3050001, 0.255), (2.1300001, 0.239), (2.0139999, 0.255), (2.4059999, 0.204), (2.108, 0.237), (1.881, 0.254), (1.773, 0.254), (1.855, 0.27), (2.326, 0.223), (1.626, 0.253), (1.9, 0.255), (1.936, 0.256), (2.302, 0.238), (2.27, 0.206), (2.2809999, 0.255), (2.1259999, 0.256), (2.1730001, 0.222), (2.056, 0.221), (2.3640001, 0.222), (2.224, 0.24), (2.0799999, 0.238), (2.546, 0.206), (2.5799999, 0.255), (1.8660001, 0.255), (1.899, 0.255), (2.247, 0.223), (2.0050001, 0.255), (2.319, 0.239), (1.974, 0.256), (1.876, 0.254), (2.0810001, 0.24), (2.4330001, 0.205), (1.978, 0.273), (2.1129999, 0.206), (2.352, 0.222), (2.415, 0.205), (1.994, 0.255), (2.063, 0.223), (1.483, 0.254), (1.784, 0.271), (1.936, 0.222), (2.177, 0.222), (2.0280001, 0.222), (2.3069999, 0.222), (1.8609999, 0.271), (2.6340001, 0.19), (2.6400001, 0.224), (1.909, 0.273), (2.273, 0.258), (1.826, 0.274), (2.234, 0.241), (2.221, 0.257), (2.289, 0.239), (2.329, 0.24), (2.122, 0.256), (2.0469999, 0.273), (2.299, 0.241), (2.556, 0.207), (2.355, 0.207), (2.0680001, 0.222), (2.5250001, 0.208), (2.3039999, 0.241), (2.2880001, 0.24), (2.2590001, 0.224), (2.4979999, 0.224), (2.3740001, 0.224), (2.1989999, 0.24), (1.882, 0.257), (2.4100001, 0.241), (2.4619999, 0.223), (2.7490001, 0.191), (2.3080001, 0.224), (2.539, 0.207), (2.2249999, 0.24), (2.2049999, 0.24), (2.5339999, 0.239), (2.6819999, 0.223), (2.1229999, 0.257), (2.4000001, 0.223), (2.5969999, 0.207), (2.267, 0.258), (2.059, 0.272), (2.217, 0.24), (2.1029999, 0.257), (2.132, 0.24), (2.3940001, 0.223), (1.97, 0.241), (2.076, 0.241), (1.994, 0.24), (2.362, 0.223), (1.957, 0.24), (2.267, 0.223), (1.905, 0.241), (2.4389999, 0.19), (2.6359999, 0.207), (2.3900001, 0.208), (2.4460001, 0.223), (1.749, 0.273), (2.2179999, 0.256), (2.151, 0.24), (2.684, 0.224), (2.0799999, 0.257), (2.3299999, 0.223), (2.7739999, 0.208), (1.921, 0.256), (1.766, 0.273), (2.3629999, 0.207), (2.3429999, 0.223), (1.835, 0.257), (2.1170001, 0.239), (2.763, 0.208), (2.112, 0.24), (1.8710001, 0.274), (1.893, 0.24), (1.99, 0.24), (2.0409999, 0.242), (2.309, 0.224), (2.2360001, 0.24), (2.2869999, 0.24), (1.8150001, 0.273), (2.6459999, 0.174), (1.8660001, 0.256), (2.029, 0.241), (1.962, 0.24), (2.102, 0.239), (2.3269999, 0.24), (1.755, 0.222), (2.257, 0.224), (1.774, 0.241), (2.2260001, 0.24), (2.0320001, 0.24), (1.8430001, 0.241), (2.168, 0.223), (2.586, 0.207), (1.475, 0.273), (1.937, 0.259), (2.563, 0.24), (2.2130001, 0.224), (2.184, 0.257), (1.715, 0.256), (2.4949999, 0.208), (2.2550001, 0.224), (1.562, 0.256), (2.0869999, 0.24), (2.323, 0.24), (1.965, 0.239), (2.326, 0.224), (1.727, 0.256), (1.969, 0.241), (2.4360001, 0.223), (2.0810001, 0.24), (1.951, 0.241), (1.7920001, 0.256), (1.832, 0.223), (1.8380001, 0.273), (1.579, 0.273), (2.494, 0.206), (1.844, 0.273), (1.814, 0.257), (1.743, 0.273), (1.576, 0.275), (1.549, 0.272), (2.3710001, 0.24), (2.3900001, 0.208), (2.052, 0.273), (2.395, 0.224), (1.971, 0.223), (1.441, 0.273), (2.319, 0.206), (2.5539999, 0.207), (1.705, 0.256), (2.3010001, 0.223), (2.237, 0.207), (2.2579999, 0.223), (1.825, 0.274), (2.7579999, 0.192), (2.2190001, 0.274), (2.4909999, 0.243), (2.4130001, 0.243), (1.967, 0.273), (2.425, 0.225), (1.9960001, 0.274), (2.497, 0.242), (2.359, 0.241), (2.3410001, 0.242), (2.4949999, 0.226), (2.0929999, 0.275), (2.6919999, 0.226), (2.0710001, 0.258), (2.0999999, 0.273), (2.178, 0.225), (2.48, 0.225), (2.0469999, 0.276), (2.4389999, 0.226), (1.865, 0.241), (2.3710001, 0.242), (2.8050001, 0.209), (2.8399999, 0.191), (2.069, 0.258), (2.3369999, 0.241), (2.0869999, 0.243), (1.961, 0.274), (2.375, 0.225), (2.4560001, 0.209), (2.0739999, 0.258), (2.0739999, 0.227), (2.2880001, 0.258), (1.926, 0.242), (2.3759999, 0.224), (2.1730001, 0.209), (2.839, 0.208), (1.79, 0.276), (1.896, 0.226), (2.618, 0.225), (2.062, 0.242), (2.8859999, 0.192), (2.6389999, 0.225), (2.622, 0.21), (2.1159999, 0.242), (2.049, 0.258), (1.837, 0.275), (1.949, 0.274), (2.1029999, 0.241), (2.086, 0.241), (2.54, 0.209), (2.3139999, 0.243), (2.0469999, 0.242), (2.063, 0.259), (1.804, 0.275), (2.211, 0.225), (1.8329999, 0.274), (1.87, 0.273), (2.2219999, 0.225), (2.5239999, 0.306), (1.804, 0.301), (2.4990001, 0.211), (1.928, 0.275), (1.9809999, 0.242), (2.1800001, 0.216), (2.2130001, 0.216), (2.266, 0.216), (2.707, 0.182), (1.7589999, 0.264), (2.276, 0.232), (2.086, 0.247), (2.566, 0.215), (2.089, 0.216), (1.914, 0.249), (2.0469999, 0.215), (1.729, 0.264), (2.3, 0.216), (2.651, 0.199), (1.609, 0.248), (2.049, 0.232), (2.237, 0.199), (1.839, 0.248), (2.145, 0.248), (1.776, 0.264), (1.955, 0.249), (1.944, 0.232), (2.0339999, 0.248), (2.0739999, 0.249), (2.303, 0.214), (1.9809999, 0.216), (1.943, 0.232), (1.822, 0.265), (2.092, 0.216), (1.91, 0.249), (2.237, 0.251), (2.5869999, 0.201), (2.0810001, 0.217), (2.2119999, 0.2), (1.8940001, 0.266), (1.881, 0.267), (2.4879999, 0.184), (2.398, 0.217), (1.836, 0.25), (2.3199999, 0.233), (1.674, 0.266), (2.3529999, 0.234), (2.2839999, 0.217), (1.972, 0.232), (2.2839999, 0.234), (1.6109999, 0.249), (2.276, 0.217), (2.102, 0.267), (2.2950001, 0.217), (2.7149999, 0.184), (2.0, 0.217), (1.8609999, 0.267), (2.0380001, 0.217), (1.737, 0.267), (1.711, 0.251), (2.434, 0.2), (1.954, 0.234), (2.424, 0.183), (1.814, 0.25), (2.29, 0.218), (2.1830001, 0.216), (1.883, 0.266), (1.5599999, 0.266), (1.8940001, 0.233), (2.069, 0.217), (1.809, 0.25), (2.0039999, 0.236), (2.26, 0.218), (2.2880001, 0.202), (1.91, 0.234), (1.79, 0.25), (1.755, 0.251), (1.9220001, 0.25), (2.3970001, 0.201), (2.5239999, 0.216), (2.3340001, 0.201), (2.2880001, 0.217), (1.984, 0.217), (2.1930001, 0.251), (1.846, 0.25), (1.885, 0.266), (2.177, 0.234), (2.0510001, 0.217), (2.049, 0.216), (1.78, 0.25), (2.5350001, 0.2), (1.98, 0.251), (2.1819999, 0.234), (2.4170001, 0.217), (1.78, 0.266), (1.929, 0.25), (1.8890001, 0.252), (2.086, 0.251), (2.2809999, 0.235), (2.2609999, 0.201), (1.869, 0.25), (2.428, 0.201), (1.8430001, 0.25), (2.05, 0.217), (2.6429999, 0.2), (1.961, 0.234), (1.914, 0.266), (2.082, 0.25), (1.7539999, 0.267), (2.1889999, 0.218), (1.92, 0.217), (2.207, 0.201), (2.2820001, 0.202), (1.8430001, 0.25), (1.865, 0.232), (2.3870001, 0.233), (1.704, 0.267), (2.0969999, 0.216), (2.273, 0.201), (1.658, 0.233), (2.3559999, 0.201), (1.8380001, 0.234), (1.951, 0.25), (2.7639999, 0.184), (1.693, 0.249), (1.923, 0.234), (1.839, 0.267), (2.033, 0.218), (1.641, 0.267), (2.0179999, 0.25), (1.767, 0.234), (2.0239999, 0.218), (1.8559999, 0.251), (2.224, 0.217), (1.8099999, 0.265), (2.112, 0.201), (1.702, 0.25), (2.4519999, 0.186), (2.191, 0.234), (2.28, 0.2), (1.78, 0.267), (2.523, 0.185), (2.1340001, 0.25), (1.648, 0.267), (1.538, 0.249), (1.846, 0.233), (2.0480001, 0.251), (2.0209999, 0.249), (2.404, 0.201), (2.2390001, 0.217), (2.194, 0.2), (1.7970001, 0.218), (2.336, 0.216), (1.594, 0.267), (2.4260001, 0.201), (1.706, 0.267), (2.2579999, 0.184), (2.1719999, 0.234), (1.783, 0.249), (1.903, 0.218), (1.831, 0.217), (1.816, 0.251), (1.8609999, 0.234), (2.0799999, 0.216), (1.853, 0.25), (1.464, 0.267), (1.775, 0.25), (1.7589999, 0.249), (2.0079999, 0.217), (1.915, 0.201), (1.8789999, 0.251), (2.2609999, 0.216), (2.0999999, 0.218), (2.27, 0.185), (2.2539999, 0.217), (1.735, 0.249), (1.568, 0.266), (2.197, 0.234), (1.643, 0.251), (1.791, 0.269), (2.125, 0.236), (1.735, 0.251), (1.631, 0.269), (1.7410001, 0.267), (2.444, 0.202), (2.1689999, 0.253), (2.108, 0.218), (2.0639999, 0.251), (2.1760001, 0.236), (1.467, 0.252), (2.5239999, 0.187), (1.951, 0.252), (2.3529999, 0.186), (2.277, 0.237), (2.0969999, 0.235), (2.3829999, 0.218), (2.0580001, 0.218), (1.956, 0.268), (1.942, 0.253), (2.1459999, 0.219), (1.803, 0.252), (1.791, 0.27), (1.8609999, 0.252), (1.826, 0.269), (2.02, 0.235), (2.023, 0.218), (2.277, 0.202), (1.767, 0.236), (1.874, 0.252), (2.095, 0.236), (1.84, 0.251), (2.2880001, 0.202), (1.568, 0.234), (2.1140001, 0.22), (1.867, 0.268), (2.02, 0.235), (1.886, 0.252), (2.5, 0.203), (2.3840001, 0.185), (1.949, 0.251), (2.0710001, 0.268), (1.978, 0.236), (2.3499999, 0.202), (2.2449999, 0.236), (1.985, 0.236), (2.0739999, 0.235), (2.154, 0.204), (2.2460001, 0.219), (1.88, 0.251), (2.543, 0.202), (2.2609999, 0.219), (1.839, 0.235), (1.839, 0.251), (1.807, 0.252), (1.7690001, 0.268), (1.6950001, 0.268), (1.726, 0.235), (1.694, 0.267), (2.066, 0.219), (2.1989999, 0.252), (2.131, 0.219), (1.428, 0.267), (2.075, 0.252), (2.1819999, 0.219), (2.198, 0.254), (2.3729999, 0.186), (2.2520001, 0.202), (1.6900001, 0.251), (1.881, 0.267), (2.0190001, 0.203), (1.7, 0.268), (2.3510001, 0.202), (1.7359999, 0.236), (1.999, 0.235), (2.2509999, 0.202), (1.704, 0.235), (1.352, 0.268), (1.557, 0.268), (2.1930001, 0.235), (2.0, 0.219), (1.998, 0.218), (1.949, 0.253), (1.5829999, 0.251), (1.687, 0.269), (1.822, 0.219), (1.795, 0.235), (1.381, 0.267), (1.905, 0.252), (1.779, 0.235), (1.432, 0.267), (2.3, 0.202), (1.738, 0.22), (1.483, 0.235), (2.293, 0.203), (2.01, 0.236), (1.743, 0.236), (1.661, 0.268), (1.997, 0.236), (1.885, 0.219), (1.576, 0.269), (1.5829999, 0.269), (1.7029999, 0.252), (1.751, 0.268), (1.771, 0.219), (1.938, 0.236), (1.397, 0.269), (1.553, 0.267), (1.557, 0.235), (1.738, 0.267), (2.2320001, 0.237), (2.1389999, 0.234), (1.654, 0.269), (1.8430001, 0.252), (1.99, 0.235), (2.2539999, 0.234), (1.617, 0.235), (1.837, 0.235), (2.3659999, 0.235), (1.8940001, 0.236), (2.4820001, 0.185), (1.875, 0.235), (1.516, 0.235), (1.415, 0.269), (1.812, 0.22), (2.0239999, 0.219), (1.756, 0.235), (1.995, 0.219), (2.1500001, 0.203), (1.788, 0.203), (1.684, 0.236), (1.933, 0.22), (1.8049999, 0.251), (2.0239999, 0.201), (1.575, 0.235), (1.4529999, 0.268), (2.346, 0.202), (1.988, 0.255), (1.561, 0.296), (1.955, 0.24), (1.477, 0.268), (2.112, 0.235), (2.1010001, 0.222), (1.789, 0.27), (2.8599999, 0.188), (1.946, 0.237), (2.1900001, 0.237), (2.0580001, 0.253), (2.3080001, 0.22), (1.725, 0.253), (2.6900001, 0.187), (2.1670001, 0.236), (1.954, 0.253), (2.0339999, 0.237), (1.745, 0.254), (2.234, 0.221), (2.5179999, 0.205), (2.2309999, 0.221), (2.0639999, 0.22), (2.141, 0.252), (2.622, 0.204), (1.886, 0.27), (2.1900001, 0.221), (2.168, 0.221), (1.892, 0.254), (2.253, 0.22), (2.381, 0.187), (1.601, 0.27), (1.7410001, 0.254), (2.0050001, 0.237), (2.3729999, 0.203), (1.938, 0.253), (2.266, 0.22), (2.0480001, 0.237), (1.969, 0.22), (1.818, 0.252), (2.405, 0.188), (1.9579999, 0.238), (2.0380001, 0.221), (2.309, 0.22), (2.1489999, 0.204), (2.1619999, 0.238), (1.7130001, 0.254), (2.1849999, 0.221), (1.581, 0.269), (1.469, 0.271), (1.7460001, 0.269), (2.0369999, 0.237), (1.793, 0.272), (2.1530001, 0.237), (1.9069999, 0.252), (1.85, 0.236), (1.744, 0.27), (1.5089999, 0.27), (2.572, 0.203), (1.846, 0.237), (2.441, 0.204), (1.835, 0.237), (1.928, 0.269), (1.988, 0.237), (2.131, 0.221), (1.959, 0.27), (1.96, 0.204), (2.5350001, 0.187), (1.817, 0.236), (1.902, 0.238), (1.5779999, 0.27), (1.997, 0.22), (2.1470001, 0.238), (2.329, 0.22), (1.624, 0.271), (1.673, 0.254), (1.636, 0.254), (1.826, 0.254), (1.58, 0.27), (1.7869999, 0.252), (1.785, 0.237), (1.829, 0.236), (1.965, 0.27), (1.899, 0.253), (1.845, 0.253), (1.5470001, 0.253), (1.605, 0.254), (1.8099999, 0.236), (2.0999999, 0.221), (2.023, 0.22), (1.6059999, 0.269), (1.515, 0.253), (1.503, 0.253), (1.6569999, 0.253), (1.364, 0.271), (1.9170001, 0.221), (1.587, 0.253), (1.477, 0.27), (2.0710001, 0.186), (1.7869999, 0.27), (2.0810001, 0.22), (2.2479999, 0.221), (1.649, 0.269), (2.016, 0.203), (2.3710001, 0.204), (1.721, 0.237), (2.2809999, 0.22), (1.64, 0.27), (1.557, 0.253), (1.793, 0.269), (1.987, 0.221), (1.691, 0.27), (1.97, 0.237), (1.946, 0.238), (1.87, 0.236), (1.77, 0.253), (1.829, 0.27), (2.1259999, 0.237), (2.0769999, 0.203), (1.7, 0.254), (1.827, 0.239), (2.187, 0.203), (1.551, 0.221), (1.4299999, 0.252), (1.529, 0.269), (2.0450001, 0.236), (1.562, 0.254), (1.76, 0.237), (2.4920001, 0.221), (1.5420001, 0.271), (1.709, 0.237), (2.119, 0.221), (1.811, 0.236), (1.567, 0.252), (1.938, 0.22), (2.2030001, 0.22), (2.402, 0.205), (1.728, 0.237), (2.175, 0.222), (1.841, 0.22), (1.573, 0.27), (2.3599999, 0.204), (1.988, 0.256), (1.725, 0.272), (2.1459999, 0.205), (2.1070001, 0.238), (1.857, 0.256), (2.1559999, 0.239), (2.046, 0.238), (2.4000001, 0.189), (1.898, 0.238), (1.762, 0.255), (1.895, 0.271), (1.97, 0.222), (2.0510001, 0.222), (2.0699999, 0.271), (1.436, 0.271), (2.5610001, 0.189), (2.0699999, 0.221), (2.0580001, 0.207), (1.7410001, 0.271), (2.046, 0.238), (1.558, 0.254), (1.911, 0.272), (2.286, 0.206), (2.4419999, 0.189), (2.0339999, 0.239), (2.0109999, 0.238), (2.277, 0.239), (2.046, 0.239), (2.0179999, 0.223), (2.5220001, 0.206), (2.0569999, 0.238), (2.5220001, 0.206), (1.8789999, 0.256), (1.697, 0.255), (1.7869999, 0.256), (1.957, 0.238), (1.849, 0.222), (1.869, 0.271), (1.8150001, 0.256), (1.77, 0.239), (1.816, 0.255), (1.89, 0.255), (2.224, 0.239), (1.793, 0.273), (1.748, 0.239), (2.056, 0.24), (2.0139999, 0.206), (1.781, 0.272), (1.569, 0.271), (1.9809999, 0.223), (1.848, 0.272), (1.897, 0.255), (2.2390001, 0.222), (2.1600001, 0.238), (1.931, 0.222), (1.801, 0.271), (1.957, 0.273), (2.0309999, 0.238), (1.698, 0.255), (1.936, 0.27), (1.798, 0.255), (2.2620001, 0.238), (2.145, 0.239), (1.678, 0.255), (2.016, 0.272), (1.978, 0.24), (1.925, 0.238), (1.919, 0.271), (1.765, 0.255), (1.983, 0.222), (1.827, 0.238), (1.943, 0.238), (2.096, 0.254), (1.668, 0.272), (1.664, 0.24), (1.751, 0.254), (1.969, 0.239), (1.9680001, 0.239), (2.0350001, 0.272), (1.625, 0.272), (1.631, 0.255), (1.5930001, 0.254), (1.9400001, 0.239), (1.538, 0.271), (1.66, 0.24), (2.2969999, 0.205), (1.791, 0.255), (1.59, 0.222), (2.576, 0.205), (1.705, 0.253), (1.814, 0.255), (2.0739999, 0.255), (1.9220001, 0.239), (1.795, 0.256), (2.105, 0.205), (1.822, 0.239), (1.61, 0.256), (1.603, 0.255), (1.7, 0.272), (1.965, 0.223), (1.3609999, 0.255), (1.617, 0.255), (1.7410001, 0.255), (2.0940001, 0.238), (2.033, 0.205), (2.0339999, 0.254), (1.92, 0.255), (1.9680001, 0.222), (1.852, 0.223), (2.131, 0.222), (2.0090001, 0.239), (1.826, 0.238), (2.24, 0.205), (2.3599999, 0.255), (1.586, 0.254), (1.74, 0.256), (2.063, 0.222), (1.737, 0.254), (2.0829999, 0.237), (1.692, 0.256), (1.651, 0.254), (1.84, 0.239), (2.0769999, 0.204), (1.757, 0.271), (1.743, 0.206), (2.1229999, 0.222), (2.168, 0.206), (1.8279999, 0.254), (1.791, 0.222), (1.29, 0.255), (1.609, 0.271), (1.613, 0.222), (1.942, 0.221), (1.777, 0.222), (1.95, 0.221), (1.687, 0.272), (2.319, 0.191), (2.391, 0.222), (1.679, 0.273), (2.128, 0.257), (1.684, 0.273), (2.0039999, 0.241), (1.989, 0.257), (2.0139999, 0.24), (2.1300001, 0.24), (1.9299999, 0.256), (1.836, 0.273), (2.026, 0.24), (2.332, 0.207), (2.1630001, 0.206), (1.893, 0.224), (2.3340001, 0.207), (2.1029999, 0.242), (2.1570001, 0.241), (2.0799999, 0.224), (2.2980001, 0.222), (2.1719999, 0.223), (2.0320001, 0.24), (1.699, 0.257), (2.2279999, 0.241), (2.2690001, 0.224), (2.385, 0.191), (2.112, 0.225), (2.2479999, 0.208), (2.0680001, 0.24), (2.0239999, 0.24), (2.2639999, 0.24), (2.3740001, 0.223), (1.948, 0.255), (2.1819999, 0.223), (2.2839999, 0.207), (2.0369999, 0.256), (1.8380001, 0.273), (1.959, 0.239), (1.928, 0.257), (1.9299999, 0.239), (2.1800001, 0.223), (1.7460001, 0.241), (1.852, 0.24), (1.7460001, 0.24), (2.152, 0.223), (1.737, 0.24), (2.099, 0.223), (1.698, 0.24), (2.138, 0.19), (2.283, 0.208), (2.099, 0.207), (2.2360001, 0.224), (1.538, 0.274), (2.039, 0.257), (1.874, 0.24), (2.494, 0.223), (1.8609999, 0.256), (2.125, 0.225), (2.4990001, 0.207), (1.734, 0.257), (1.567, 0.272), (2.0699999, 0.208), (2.089, 0.224), (1.612, 0.257), (1.944, 0.241), (2.5, 0.207), (1.855, 0.24), (1.63, 0.273), (1.658, 0.241), (1.729, 0.24), (1.7819999, 0.24), (2.026, 0.223), (1.955, 0.241), (2.0799999, 0.24), (1.66, 0.273), (2.3150001, 0.174), (1.609, 0.256), (1.836, 0.239), (1.66, 0.241), (1.9170001, 0.24), (2.0090001, 0.24), (1.42, 0.223), (1.911, 0.224), (1.4910001, 0.24), (2.0079999, 0.241), (1.809, 0.241), (1.577, 0.239), (1.851, 0.224), (2.266, 0.207), (1.2690001, 0.273), (1.701, 0.256), (2.2690001, 0.241), (1.972, 0.224), (1.9, 0.257), (1.4579999, 0.256), (2.1070001, 0.208), (1.983, 0.223), (1.381, 0.256), (1.883, 0.239), (2.135, 0.239), (1.772, 0.24), (2.085, 0.222), (1.497, 0.256), (1.7029999, 0.242), (2.2409999, 0.224), (1.8380001, 0.241), (1.6720001, 0.24), (1.577, 0.258), (1.654, 0.225), (1.7029999, 0.273), (1.399, 0.274), (2.128, 0.207), (1.665, 0.271), (1.546, 0.257), (1.564, 0.273), (1.395, 0.273), (1.352, 0.272), (2.105, 0.239), (2.086, 0.207), (1.902, 0.274), (2.2030001, 0.224), (1.725, 0.224), (1.232, 0.274), (1.977, 0.207), (2.253, 0.208), (1.48, 0.257), (2.0350001, 0.223), (1.929, 0.207), (2.066, 0.224), (1.659, 0.272), (2.5250001, 0.193), (2.0940001, 0.275), (2.286, 0.242), (2.243, 0.242), (1.841, 0.275), (2.2090001, 0.227), (1.803, 0.275), (2.2639999, 0.242), (2.1960001, 0.241), (2.177, 0.243), (2.3080001, 0.224), (1.918, 0.274), (2.461, 0.225), (1.864, 0.258), (1.9170001, 0.276), (1.941, 0.226), (2.3329999, 0.226), (1.7819999, 0.274), (2.237, 0.226), (1.7589999, 0.24), (2.188, 0.241), (2.533, 0.208), (2.517, 0.192), (1.859, 0.258), (2.1789999, 0.242), (1.931, 0.241), (1.809, 0.274), (2.181, 0.226), (2.326, 0.209), (1.9170001, 0.258), (1.892, 0.226), (2.135, 0.258), (1.74, 0.241), (2.1659999, 0.225), (1.97, 0.208), (2.5869999, 0.208), (1.642, 0.275), (1.716, 0.225), (2.4619999, 0.225), (1.864, 0.242), (2.654, 0.192), (2.45, 0.225), (2.4130001, 0.208), (1.918, 0.242), (1.881, 0.257), (1.674, 0.275), (1.745, 0.274), (1.874, 0.242), (1.885, 0.241), (2.3039999, 0.209), (2.112, 0.242), (1.821, 0.242), (1.955, 0.258), (1.656, 0.274), (2.003, 0.225), (1.707, 0.275), (1.737, 0.273), (2.1040001, 0.226), (2.3789999, 0.243), (1.637, 0.274), (2.257, 0.209), (1.7539999, 0.273), (1.847, 0.242), (2.0550001, 0.216), (2.0369999, 0.215), (2.102, 0.215), (2.536, 0.182), (1.642, 0.265), (2.1110001, 0.231), (1.9450001, 0.248), (2.4619999, 0.215), (1.967, 0.216), (1.799, 0.248), (1.938, 0.217), (1.6390001, 0.265), (2.1559999, 0.215), (2.487, 0.199), (1.482, 0.249), (1.932, 0.232), (2.0350001, 0.199), (1.757, 0.247), (2.0020001, 0.247), (1.66, 0.265), (1.747, 0.249), (1.816, 0.233), (1.938, 0.248), (1.914, 0.25), (2.095, 0.217), (1.823, 0.215), (1.795, 0.232), (1.706, 0.266), (2.003, 0.213), (1.834, 0.249), (2.0869999, 0.252), (2.398, 0.2), (1.868, 0.217), (1.969, 0.201), (1.707, 0.266), (1.734, 0.266), (2.2520001, 0.183), (2.1760001, 0.218), (1.7029999, 0.251), (2.1110001, 0.234), (1.535, 0.267), (2.2, 0.234), (2.0469999, 0.215), (1.836, 0.235), (2.0250001, 0.234), (1.489, 0.25), (2.046, 0.217), (1.972, 0.268), (2.1270001, 0.218), (2.3299999, 0.184), (1.811, 0.218), (1.712, 0.266), (1.868, 0.218), (1.557, 0.267), (1.581, 0.252), (2.2349999, 0.202), (1.844, 0.235), (2.1789999, 0.183), (1.679, 0.25), (2.0810001, 0.217), (2.0369999, 0.217), (1.733, 0.268), (1.446, 0.268), (1.701, 0.235), (1.897, 0.217), (1.681, 0.25), (1.7180001, 0.233), (2.056, 0.217), (2.0480001, 0.201), (1.752, 0.235), (1.6900001, 0.249), (1.549, 0.25), (1.777, 0.25), (2.1849999, 0.201), (2.3180001, 0.218), (2.095, 0.201), (2.063, 0.217), (1.832, 0.216), (1.9910001, 0.25), (1.608, 0.249), (1.674, 0.266), (1.966, 0.233), (1.867, 0.217), (1.803, 0.218), (1.615, 0.251), (2.3099999, 0.201), (1.772, 0.25), (1.97, 0.235), (2.197, 0.218), (1.622, 0.266), (1.727, 0.25), (1.735, 0.251), (1.929, 0.25), (2.072, 0.234), (2.082, 0.2), (1.7180001, 0.25), (2.214, 0.2), (1.681, 0.25), (1.834, 0.217), (2.404, 0.2), (1.7690001, 0.235), (1.762, 0.266), (1.865, 0.251), (1.651, 0.267), (1.911, 0.217), (1.687, 0.217), (1.954, 0.202), (2.05, 0.2), (1.6160001, 0.249), (1.696, 0.233), (2.2, 0.234), (1.597, 0.268), (1.852, 0.217), (1.988, 0.202), (1.431, 0.234), (2.1270001, 0.201), (1.628, 0.234), (1.768, 0.25), (2.454, 0.185), (1.475, 0.251), (1.668, 0.233), (1.658, 0.266), (1.7309999, 0.218), (1.456, 0.267), (1.795, 0.25), (1.613, 0.235), (1.7920001, 0.216), (1.6900001, 0.251), (2.0139999, 0.217), (1.653, 0.265), (1.818, 0.201), (1.517, 0.251), (2.25, 0.184), (1.982, 0.233), (2.046, 0.2), (1.6289999, 0.267), (2.2030001, 0.183), (1.941, 0.25), (1.477, 0.266), (1.405, 0.253), (1.656, 0.233), (1.916, 0.25), (1.8660001, 0.25), (2.1400001, 0.199), (2.017, 0.218), (2.039, 0.201), (1.534, 0.217), (2.1889999, 0.217), (1.426, 0.269), (2.118, 0.201), (1.609, 0.266), (2.0, 0.183), (1.911, 0.233), (1.628, 0.25), (1.688, 0.218), (1.613, 0.215), (1.683, 0.34), (1.673, 0.27), (1.821, 0.227), (1.645, 0.251), (1.27, 0.267), (1.612, 0.251), (1.625, 0.25), (1.7970001, 0.216), (1.682, 0.201), (1.663, 0.252), (2.0020001, 0.218), (1.903, 0.217), (1.984, 0.185), (2.1059999, 0.217), (1.541, 0.251), (1.424, 0.266), (2.0050001, 0.234), (1.497, 0.253), (1.617, 0.268), (2.0179999, 0.235), (1.575, 0.253), (1.559, 0.27), (1.602, 0.267), (2.201, 0.203), (1.925, 0.252), (1.916, 0.221), (1.876, 0.252), (1.987, 0.235), (1.336, 0.252), (2.2690001, 0.186), (1.8049999, 0.252), (2.0799999, 0.186), (2.0380001, 0.236), (1.896, 0.235), (2.1700001, 0.219), (1.811, 0.219), (1.783, 0.269), (1.6950001, 0.252), (1.941, 0.218), (1.706, 0.252), (1.637, 0.268), (1.745, 0.252), (1.617, 0.268), (1.829, 0.235), (1.834, 0.218), (2.0139999, 0.202), (1.562, 0.235), (1.697, 0.251), (1.946, 0.236), (1.7, 0.252), (2.0420001, 0.202), (1.362, 0.235), (1.909, 0.218), (1.6799999, 0.27), (1.845, 0.237), (1.668, 0.251), (2.313, 0.202), (2.158, 0.185), (1.776, 0.252), (1.908, 0.269), (1.766, 0.235), (2.142, 0.201), (2.0680001, 0.235), (1.859, 0.236), (1.88, 0.236), (1.899, 0.203), (2.0639999, 0.221), (1.6339999, 0.252), (2.2190001, 0.202), (2.076, 0.218), (1.679, 0.237), (1.643, 0.252), (1.584, 0.251), (1.598, 0.269), (1.512, 0.266), (1.562, 0.237), (1.536, 0.269), (1.8329999, 0.219), (2.086, 0.252), (1.946, 0.218), (1.201, 0.271), (1.924, 0.251), (2.029, 0.218), (1.957, 0.253), (2.1719999, 0.186), (2.0239999, 0.203), (1.548, 0.252), (1.717, 0.268), (1.8150001, 0.202), (1.563, 0.269), (2.1389999, 0.203), (1.563, 0.237), (1.827, 0.235), (2.027, 0.202), (1.47, 0.234), (1.122, 0.267), (1.3890001, 0.269), (2.0109999, 0.235), (1.8200001, 0.218), (1.826, 0.219), (1.774, 0.253), (1.416, 0.251), (1.447, 0.268), (1.6210001, 0.221), (1.552, 0.236), (1.176, 0.269), (1.727, 0.252), (1.5700001, 0.234), (1.263, 0.269), (2.029, 0.202), (1.541, 0.218), (1.245, 0.234), (2.095, 0.203), (1.812, 0.234), (1.579, 0.234), (1.477, 0.269), (1.8150001, 0.235), (1.652, 0.219), (1.4170001, 0.27), (1.418, 0.268), (1.511, 0.252), (1.651, 0.269), (1.571, 0.218), (1.756, 0.236), (1.222, 0.269), (1.402, 0.268), (1.396, 0.235), (1.582, 0.268), (2.099, 0.234), (1.9910001, 0.235), (1.4859999, 0.268), (1.677, 0.251), (1.76, 0.235), (2.072, 0.235), (1.393, 0.236), (1.624, 0.236), (2.2149999, 0.236), (1.692, 0.236), (2.243, 0.186), (1.753, 0.235), (1.335, 0.235), (1.27, 0.268), (1.527, 0.219), (1.776, 0.219), (1.63, 0.235), (1.794, 0.219), (1.992, 0.204), (1.552, 0.202), (1.538, 0.234), (1.728, 0.219), (1.609, 0.251), (1.904, 0.202), (1.351, 0.237), (1.296, 0.269), (2.1440001, 0.202), (1.632, 0.203), (1.448, 0.268), (1.706, 0.236), (1.245, 0.268), (1.951, 0.236), (1.891, 0.222), (1.664, 0.27), (2.615, 0.187), (1.7819999, 0.238), (1.992, 0.237), (1.868, 0.253), (2.056, 0.22), (1.561, 0.253), (2.461, 0.189), (2.0220001, 0.236), (1.824, 0.254), (1.873, 0.238), (1.626, 0.254), (2.076, 0.221), (2.293, 0.205), (2.039, 0.22), (1.845, 0.221), (1.9630001, 0.254), (2.3710001, 0.204), (1.717, 0.27), (2.0969999, 0.22), (1.994, 0.219), (1.681, 0.254), (2.0669999, 0.22), (2.131, 0.187), (1.513, 0.27), (1.552, 0.253), (1.867, 0.235), (2.198, 0.203), (1.78, 0.254), (2.072, 0.22), (1.837, 0.236), (1.776, 0.22), (1.6569999, 0.253), (2.161, 0.187), (1.778, 0.236), (1.853, 0.22), (2.1040001, 0.221), (1.902, 0.205), (1.951, 0.237), (1.609, 0.253), (2.1110001, 0.222), (1.4400001, 0.27), (1.33, 0.27), (1.581, 0.271), (1.858, 0.237), (1.531, 0.27), (1.977, 0.236), (1.742, 0.254), (1.636, 0.236), (1.575, 0.27), (1.339, 0.269), (2.4030001, 0.204), (1.648, 0.237), (2.194, 0.204), (1.627, 0.239), (1.784, 0.27), (1.785, 0.237), (1.925, 0.221), (1.83, 0.268), (1.774, 0.203), (2.2880001, 0.188), (1.618, 0.237), (1.761, 0.237), (1.4630001, 0.271), (1.8099999, 0.221), (1.999, 0.237), (2.118, 0.22), (1.477, 0.271), (1.507, 0.252), (1.4960001, 0.253), (1.674, 0.253), (1.38, 0.27), (1.568, 0.253), (1.65, 0.236), (1.645, 0.237), (1.8430001, 0.269), (1.682, 0.254), (1.674, 0.253), (1.359, 0.254), (1.529, 0.252), (1.53, 0.237), (1.887, 0.22), (1.845, 0.22), (1.376, 0.271), (1.309, 0.252), (1.275, 0.254), (1.462, 0.254), (1.153, 0.27), (1.715, 0.221), (1.441, 0.254), (1.372, 0.269), (1.807, 0.188), (1.694, 0.268), (1.808, 0.22), (2.056, 0.221), (1.47, 0.271), (1.795, 0.205), (2.1500001, 0.204), (1.459, 0.238), (2.1040001, 0.22), (1.448, 0.269), (1.431, 0.255), (1.637, 0.27), (1.7869999, 0.22), (1.535, 0.27), (1.804, 0.237), (1.813, 0.237), (1.737, 0.237), (1.615, 0.253), (1.619, 0.271), (1.978, 0.236), (1.877, 0.205), (1.5470001, 0.253), (1.658, 0.237), (2.017, 0.203), (1.308, 0.22), (1.249, 0.253), (1.369, 0.27), (1.823, 0.237), (1.431, 0.254), (1.531, 0.237), (2.2449999, 0.22), (1.369, 0.272), (1.524, 0.236), (1.9299999, 0.22), (1.64, 0.237), (1.3940001, 0.253), (1.724, 0.221), (1.989, 0.221), (2.188, 0.203), (1.4450001, 0.238), (2.036, 0.22), (1.676, 0.221), (1.41, 0.269), (2.1589999, 0.204), (1.8279999, 0.257), (1.603, 0.271), (1.967, 0.205), (1.964, 0.239), (1.7180001, 0.256), (1.952, 0.24), (1.807, 0.238), (2.197, 0.188), (1.636, 0.238), (1.574, 0.255), (1.755, 0.272), (1.714, 0.222), (1.911, 0.223), (1.872, 0.271), (1.337, 0.272), (2.3369999, 0.188), (1.897, 0.222), (1.878, 0.205), (1.598, 0.272), (1.845, 0.241), (1.359, 0.255), (1.766, 0.271), (2.0380001, 0.207), (2.267, 0.189), (1.83, 0.239), (1.826, 0.237), (2.1059999, 0.238), (1.883, 0.239), (1.793, 0.222), (2.349, 0.205), (1.891, 0.239), (2.3139999, 0.206), (1.716, 0.255), (1.5039999, 0.254), (1.615, 0.255), (1.762, 0.238), (1.6390001, 0.222), (1.7130001, 0.272), (1.6289999, 0.255), (1.589, 0.237), (1.664, 0.254), (1.675, 0.254), (2.049, 0.239), (1.651, 0.272), (1.58, 0.238), (1.914, 0.24), (1.79, 0.206), (1.626, 0.27), (1.432, 0.272), (1.823, 0.222), (1.673, 0.271), (1.712, 0.256), (1.977, 0.222), (1.87, 0.239), (1.724, 0.221), (1.599, 0.272), (1.758, 0.272), (1.934, 0.239), (1.5, 0.255), (1.781, 0.272), (1.592, 0.256), (2.017, 0.238), (2.023, 0.238), (1.48, 0.256), (1.88, 0.27), (1.817, 0.239), (1.684, 0.24), (1.798, 0.273), (1.533, 0.255), (1.777, 0.222), (1.666, 0.239), (1.699, 0.239), (1.9349999, 0.256), (1.53, 0.272), (1.3839999, 0.239), (1.546, 0.255), (1.783, 0.238), (1.793, 0.238), (1.827, 0.27), (1.498, 0.271), (1.409, 0.256), (1.3940001, 0.254), (1.717, 0.238), (1.335, 0.272), (1.411, 0.24), (2.05, 0.205), (1.545, 0.256), (1.277, 0.222), (2.2820001, 0.208), (1.4910001, 0.255), (1.548, 0.254), (1.934, 0.256), (1.747, 0.239), (1.6210001, 0.255), (1.796, 0.206), (1.624, 0.239), (1.452, 0.255), (1.462, 0.254), (1.544, 0.272), (1.739, 0.222), (1.17, 0.255), (1.401, 0.256), (1.567, 0.255), (1.899, 0.238), (1.811, 0.206), (1.908, 0.254), (1.729, 0.254), (1.748, 0.221), (1.656, 0.223), (1.909, 0.222), (1.8660001, 0.24), (1.687, 0.239), (2.0, 0.206), (2.1670001, 0.256), (1.457, 0.256), (1.576, 0.256), (1.909, 0.223), (1.551, 0.255), (1.956, 0.24), (1.473, 0.256), (1.501, 0.254), (1.686, 0.239), (1.802, 0.205), (1.613, 0.272), (1.4680001, 0.206), (1.855, 0.222), (1.9220001, 0.206), (1.67, 0.255), (1.563, 0.221), (1.112, 0.255), (1.483, 0.272), (1.4349999, 0.222), (1.761, 0.221), (1.614, 0.223), (1.654, 0.222), (1.548, 0.271), (2.0239999, 0.19), (2.174, 0.224), (1.5599999, 0.273), (1.9579999, 0.258), (1.605, 0.274), (1.8609999, 0.24), (1.8609999, 0.256), (1.8049999, 0.241), (1.928, 0.241), (1.7640001, 0.256), (1.712, 0.273), (1.862, 0.24), (2.1240001, 0.207), (1.975, 0.208), (1.735, 0.224), (2.1359999, 0.207), (1.869, 0.24), (1.985, 0.239), (1.938, 0.225), (2.1029999, 0.224), (2.0350001, 0.224), (1.834, 0.24), (1.511, 0.259), (2.04, 0.241), (2.089, 0.222), (2.122, 0.19), (1.914, 0.224), (2.0650001, 0.207), (1.8890001, 0.242), (1.84, 0.242), (2.0569999, 0.241), (2.0940001, 0.225), (1.757, 0.257), (1.977, 0.224), (2.069, 0.208), (1.807, 0.257), (1.649, 0.274), (1.729, 0.239), (1.739, 0.257), (1.779, 0.238), (1.977, 0.225), (1.584, 0.24), (1.669, 0.24), (1.59, 0.24), (1.9859999, 0.224), (1.534, 0.24), (1.938, 0.224), (1.566, 0.24), (1.874, 0.192), (2.0220001, 0.207), (1.89, 0.207), (2.0439999, 0.224), (1.421, 0.273), (1.846, 0.259), (1.692, 0.241), (2.3380001, 0.224), (1.688, 0.257), (1.965, 0.223), (2.3080001, 0.207), (1.581, 0.256), (1.419, 0.273), (1.8890001, 0.207), (1.8890001, 0.225), (1.415, 0.257), (1.798, 0.239), (2.2079999, 0.208), (1.723, 0.24), (1.465, 0.276), (1.505, 0.239), (1.531, 0.239), (1.627, 0.241), (1.881, 0.223), (1.749, 0.241), (1.8940001, 0.241), (1.461, 0.273), (2.053, 0.174), (1.436, 0.257), (1.637, 0.24), (1.4630001, 0.241), (1.768, 0.24), (1.785, 0.24), (1.1799999, 0.223), (1.697, 0.225), (1.278, 0.242), (1.873, 0.24), (1.6059999, 0.24), (1.392, 0.24), (1.567, 0.223), (2.0680001, 0.207), (1.156, 0.273), (1.525, 0.257), (2.0669999, 0.24), (1.7819999, 0.224), (1.7460001, 0.256), (1.252, 0.256), (1.834, 0.208), (1.7920001, 0.222), (1.263, 0.256), (1.697, 0.239), (1.933, 0.241), (1.6569999, 0.241), (1.863, 0.223), (1.332, 0.256), (1.492, 0.239), (2.0680001, 0.224), (1.6339999, 0.24), (1.459, 0.241), (1.449, 0.257), (1.478, 0.223), (1.569, 0.272), (1.222, 0.272), (1.87, 0.207), (1.522, 0.273), (1.382, 0.256), (1.369, 0.273), (1.255, 0.273), (1.244, 0.273), (1.8839999, 0.239), (1.881, 0.208), (1.75, 0.275), (2.0209999, 0.224), (1.563, 0.225), (1.084, 0.273), (1.798, 0.207), (2.0409999, 0.206), (1.295, 0.256), (1.864, 0.223), (1.693, 0.208), (1.874, 0.225), (1.535, 0.272), (2.237, 0.193), (1.99, 0.273), (2.0929999, 0.242), (2.1210001, 0.242), (1.702, 0.275), (1.978, 0.227), (1.655, 0.275), (2.155, 0.242), (2.0550001, 0.243), (2.0139999, 0.241), (2.1110001, 0.225), (1.751, 0.275), (2.375, 0.224), (1.696, 0.259), (1.76, 0.274), (1.758, 0.226), (2.1800001, 0.226), (1.661, 0.274), (2.0769999, 0.226), (1.6390001, 0.242), (2.0439999, 0.243), (2.345, 0.208), (2.306, 0.193), (1.742, 0.257), (2.0039999, 0.242), (1.793, 0.241), (1.6670001, 0.274), (2.0280001, 0.225), (2.1359999, 0.209), (1.753, 0.259), (1.778, 0.225), (1.9680001, 0.259), (1.595, 0.242), (2.0420001, 0.225), (1.804, 0.209), (2.3829999, 0.21), (1.526, 0.275), (1.523, 0.227), (2.276, 0.225), (1.715, 0.243), (2.4089999, 0.192), (2.2550001, 0.226), (2.263, 0.209), (1.755, 0.242), (1.696, 0.259), (1.562, 0.276), (1.637, 0.274), (1.637, 0.245), (1.6720001, 0.243), (2.1470001, 0.209), (1.9450001, 0.242), (1.654, 0.242), (1.816, 0.258), (1.549, 0.276), (1.847, 0.225), (1.592, 0.276), (1.59, 0.275), (1.924, 0.226), (2.2279999, 0.243), (1.52, 0.273), (2.0929999, 0.208), (1.6440001, 0.275), (1.702, 0.242), (1.908, 0.216), (1.92, 0.216), (2.0, 0.216), (2.3429999, 0.183), (1.568, 0.264), (2.0109999, 0.232), (1.865, 0.249), (2.247, 0.215), (1.841, 0.215), (1.722, 0.249), (1.839, 0.216), (1.526, 0.264), (2.069, 0.217), (2.296, 0.199), (1.375, 0.248), (1.819, 0.233), (1.9299999, 0.198), (1.683, 0.248), (1.899, 0.25), (1.5700001, 0.263), (1.617, 0.248), (1.73, 0.234), (1.8099999, 0.249), (1.821, 0.249), (1.927, 0.214), (1.76, 0.215), (1.701, 0.233), (1.614, 0.264), (1.841, 0.216), (1.75, 0.249), (1.9450001, 0.252), (2.276, 0.202), (1.689, 0.217), (1.831, 0.199), (1.572, 0.267), (1.574, 0.267), (2.0280001, 0.184), (1.9910001, 0.219), (1.608, 0.249), (1.954, 0.234), (1.46, 0.266), (2.046, 0.234), (1.869, 0.217), (1.724, 0.234), (1.863, 0.233), (1.399, 0.25), (1.875, 0.218), (1.848, 0.266), (1.938, 0.217), (2.0220001, 0.184), (1.725, 0.218), (1.592, 0.268), (1.719, 0.22), (1.386, 0.268), (1.467, 0.252), (2.0999999, 0.202), (1.668, 0.235), (1.943, 0.185), (1.5190001, 0.25), (1.844, 0.217), (1.868, 0.217), (1.632, 0.266), (1.337, 0.267), (1.602, 0.235), (1.689, 0.217), (1.584, 0.249), (1.508, 0.235), (1.9119999, 0.218), (1.867, 0.2), (1.646, 0.234), (1.6059999, 0.251), (1.369, 0.252), (1.633, 0.25), (2.0109999, 0.202), (2.1099999, 0.217), (1.9299999, 0.201), (1.827, 0.217), (1.694, 0.218), (1.819, 0.251), (1.431, 0.25), (1.535, 0.268), (1.84, 0.235), (1.726, 0.218), (1.624, 0.217), (1.469, 0.25), (2.056, 0.201), (1.659, 0.25), (1.773, 0.234), (1.99, 0.218), (1.444, 0.268), (1.575, 0.25), (1.6, 0.25), (1.798, 0.251), (1.914, 0.234), (1.926, 0.201), (1.59, 0.251), (2.007, 0.201), (1.571, 0.252), (1.712, 0.217), (2.2550001, 0.2), (1.622, 0.233), (1.647, 0.265), (1.691, 0.25), (1.51, 0.269), (1.738, 0.217), (1.459, 0.218), (1.783, 0.2), (1.842, 0.201), (1.441, 0.249), (1.605, 0.234), (2.0280001, 0.234), (1.492, 0.267), (1.675, 0.218), (1.778, 0.2), (1.263, 0.235), (1.924, 0.2), (1.456, 0.233), (1.627, 0.25), (2.2060001, 0.184), (1.3430001, 0.251), (1.461, 0.234), (1.516, 0.266), (1.4680001, 0.218), (1.322, 0.268), (1.605, 0.25), (1.46, 0.233), (1.626, 0.217), (1.489, 0.25), (1.855, 0.218), (1.534, 0.267), (1.647, 0.201), (1.4, 0.25), (2.0109999, 0.183), (1.83, 0.234), (1.869, 0.201), (1.513, 0.267), (1.942, 0.186), (1.827, 0.251), (1.314, 0.266), (1.3099999, 0.25), (1.554, 0.233), (1.79, 0.25), (1.735, 0.251), (1.9630001, 0.201), (1.834, 0.217), (1.898, 0.201), (1.395, 0.217), (2.0050001, 0.216), (1.306, 0.267), (1.882, 0.201), (1.494, 0.267), (1.775, 0.185), (1.739, 0.233), (1.478, 0.251), (1.544, 0.218), (1.432, 0.216), (1.551, 0.344), (1.46, 0.278), (1.682, 0.23), (1.52, 0.251), (1.145, 0.266), (1.495, 0.251), (1.505, 0.249), (1.661, 0.217), (1.531, 0.201), (1.523, 0.25), (1.8710001, 0.217), (1.78, 0.216), (1.756, 0.185), (1.9630001, 0.218), (1.421, 0.249), (1.3380001, 0.267), (1.845, 0.234), (1.369, 0.252), (1.466, 0.267), (1.938, 0.236), (1.447, 0.252), (1.433, 0.268), (1.471, 0.269), (1.9910001, 0.202), (1.757, 0.252), (1.737, 0.22), (1.671, 0.252), (1.857, 0.236), (1.224, 0.253), (2.073, 0.186), (1.651, 0.253), (1.903, 0.185), (1.853, 0.237), (1.702, 0.236), (1.9960001, 0.219), (1.575, 0.218), (1.605, 0.269), (1.508, 0.253), (1.7309999, 0.219), (1.605, 0.252), (1.472, 0.269), (1.646, 0.252), (1.47, 0.268), (1.712, 0.235), (1.693, 0.218), (1.878, 0.202), (1.395, 0.235), (1.546, 0.252), (1.777, 0.235), (1.567, 0.251), (1.853, 0.201), (1.2180001, 0.234), (1.706, 0.218), (1.525, 0.268), (1.6720001, 0.235), (1.521, 0.253), (2.0739999, 0.203), (1.937, 0.185), (1.607, 0.252), (1.7539999, 0.27), (1.664, 0.235), (1.9529999, 0.202), (1.913, 0.234), (1.6900001, 0.237), (1.756, 0.236), (1.729, 0.202), (1.875, 0.218), (1.489, 0.252), (1.99, 0.203), (1.878, 0.218), (1.527, 0.236), (1.4450001, 0.252), (1.4299999, 0.253), (1.473, 0.267), (1.406, 0.268), (1.399, 0.236), (1.396, 0.268), (1.637, 0.218), (1.944, 0.253), (1.748, 0.218), (1.036, 0.269), (1.795, 0.25), (1.868, 0.219), (1.766, 0.252), (1.987, 0.186), (1.814, 0.202), (1.4299999, 0.249), (1.5930001, 0.269), (1.675, 0.202), (1.433, 0.269), (1.969, 0.203), (1.4450001, 0.235), (1.705, 0.236), (1.841, 0.202), (1.316, 0.236), (0.963, 0.268), (1.244, 0.268), (1.8660001, 0.235), (1.6799999, 0.218), (1.692, 0.219), (1.666, 0.253), (1.258, 0.252), (1.244, 0.27), (1.446, 0.221), (1.395, 0.236), (1.051, 0.268), (1.579, 0.253), (1.349, 0.236), (1.119, 0.269), (1.753, 0.202), (1.357, 0.219), (1.0700001, 0.235), (1.9529999, 0.202), (1.66, 0.236), (1.385, 0.235), (1.396, 0.268), (1.733, 0.236), (1.497, 0.219), (1.298, 0.268), (1.3049999, 0.268), (1.359, 0.252), (1.499, 0.268), (1.431, 0.219), (1.576, 0.236), (1.058, 0.268), (1.324, 0.268), (1.2539999, 0.234), (1.442, 0.27), (1.9529999, 0.235), (1.882, 0.236), (1.375, 0.268), (1.523, 0.253), (1.5700001, 0.235), (1.921, 0.235), (1.262, 0.236), (1.441, 0.235), (2.098, 0.235), (1.5700001, 0.236), (2.04, 0.186), (1.618, 0.235), (1.249, 0.236), (1.16, 0.269), (1.318, 0.219), (1.609, 0.219), (1.526, 0.235), (1.627, 0.22), (1.8279999, 0.202), (1.357, 0.201), (1.424, 0.234), (1.598, 0.22), (1.408, 0.252), (1.6849999, 0.203), (1.201, 0.234), (1.21, 0.267), (1.939, 0.203), (1.4299999, 0.204), (1.334, 0.268), (1.581, 0.235), (1.091, 0.268), (1.8200001, 0.236), (1.778, 0.222), (1.557, 0.271), (2.368, 0.186), (1.562, 0.238), (1.834, 0.237), (1.653, 0.254), (1.858, 0.221), (1.392, 0.254), (2.2160001, 0.189), (1.8609999, 0.238), (1.687, 0.254), (1.728, 0.238), (1.5039999, 0.254), (1.886, 0.22), (2.072, 0.203), (1.816, 0.22), (1.661, 0.22), (1.853, 0.254), (2.155, 0.202), (1.561, 0.271), (1.913, 0.22), (1.849, 0.22), (1.498, 0.254), (1.9450001, 0.22), (1.936, 0.187), (1.433, 0.27), (1.418, 0.254), (1.7690001, 0.236), (2.029, 0.204), (1.614, 0.254), (1.974, 0.22), (1.643, 0.237), (1.562, 0.22), (1.534, 0.254), (1.914, 0.187), (1.704, 0.236), (1.7, 0.222), (1.967, 0.22), (1.704, 0.204), (1.765, 0.237), (1.493, 0.254), (1.931, 0.22), (1.278, 0.271), (1.196, 0.269), (1.4299999, 0.27), (1.682, 0.237), (1.344, 0.271), (1.744, 0.237), (1.584, 0.255), (1.472, 0.237), (1.4170001, 0.269), (1.214, 0.27), (2.237, 0.202), (1.4960001, 0.235), (1.999, 0.204), (1.46, 0.238), (1.669, 0.271), (1.602, 0.237), (1.729, 0.22), (1.699, 0.269), (1.631, 0.204), (2.029, 0.187), (1.47, 0.237), (1.582, 0.237), (1.3609999, 0.27), (1.592, 0.22), (1.8609999, 0.237), (1.92, 0.221), (1.363, 0.27), (1.36, 0.254), (1.372, 0.253), (1.558, 0.252), (1.21, 0.27), (1.408, 0.253), (1.541, 0.236), (1.506, 0.236), (1.649, 0.27), (1.562, 0.253), (1.545, 0.253), (1.184, 0.253), (1.415, 0.254), (1.3099999, 0.236), (1.7180001, 0.221), (1.715, 0.221), (1.214, 0.27), (1.165, 0.253), (1.133, 0.254), (1.3380001, 0.254), (0.94300002, 0.268), (1.548, 0.22), (1.288, 0.254), (1.255, 0.27), (1.612, 0.188), (1.579, 0.269), (1.595, 0.22), (1.882, 0.221), (1.3, 0.27), (1.598, 0.204), (1.966, 0.204), (1.3200001, 0.237), (1.9680001, 0.22), (1.244, 0.27), (1.313, 0.253), (1.535, 0.271), (1.618, 0.22), (1.401, 0.27), (1.656, 0.237), (1.659, 0.237), (1.607, 0.237), (1.4400001, 0.254), (1.487, 0.27), (1.807, 0.238), (1.7, 0.204), (1.4529999, 0.254), (1.488, 0.237), (1.848, 0.205), (1.109, 0.221), (1.1390001, 0.254), (1.2539999, 0.27), (1.625, 0.236), (1.34, 0.254), (1.4, 0.238), (2.072, 0.222), (1.22, 0.27), (1.377, 0.237), (1.777, 0.221), (1.502, 0.236), (1.285, 0.255), (1.508, 0.22), (1.819, 0.221), (2.0050001, 0.203), (1.2410001, 0.237), (1.9400001, 0.221), (1.4630001, 0.22), (1.294, 0.27), (1.964, 0.204), (1.654, 0.254), (1.487, 0.271), (1.848, 0.206), (1.783, 0.239), (1.544, 0.255), (1.72, 0.239), (1.592, 0.239), (2.017, 0.189), (1.444, 0.239), (1.46, 0.254), (1.664, 0.272), (1.544, 0.222), (1.7460001, 0.222), (1.726, 0.271), (1.262, 0.273), (2.0999999, 0.189), (1.7359999, 0.223), (1.693, 0.206), (1.488, 0.272), (1.684, 0.239), (1.247, 0.256), (1.655, 0.271), (1.773, 0.205), (2.1259999, 0.189), (1.682, 0.239), (1.6569999, 0.239), (1.994, 0.239), (1.7309999, 0.239), (1.603, 0.222), (2.1849999, 0.205), (1.725, 0.239), (2.1010001, 0.205), (1.53, 0.257), (1.336, 0.256), (1.437, 0.255), (1.623, 0.238), (1.462, 0.222), (1.557, 0.272), (1.483, 0.255), (1.431, 0.24), (1.502, 0.255), (1.48, 0.256), (1.8789999, 0.24), (1.474, 0.273), (1.388, 0.238), (1.743, 0.24), (1.5829999, 0.206), (1.478, 0.271), (1.274, 0.271), (1.596, 0.222), (1.5549999, 0.271), (1.5470001, 0.255), (1.789, 0.222), (1.6950001, 0.239), (1.5140001, 0.222), (1.518, 0.273), (1.58, 0.273), (1.771, 0.24), (1.37, 0.255), (1.65, 0.272), (1.434, 0.255), (1.775, 0.241), (1.86, 0.238), (1.285, 0.256), (1.744, 0.271), (1.675, 0.241), (1.535, 0.24), (1.6720001, 0.271), (1.4069999, 0.254), (1.605, 0.223), (1.526, 0.239), (1.493, 0.239), (1.822, 0.256), (1.369, 0.271), (1.194, 0.239), (1.395, 0.255), (1.647, 0.237), (1.642, 0.239), (1.6799999, 0.272), (1.3890001, 0.271), (1.295, 0.254), (1.268, 0.255), (1.552, 0.238), (1.1670001, 0.271), (1.204, 0.238), (1.92, 0.206), (1.3049999, 0.254), (1.11, 0.222), (2.0380001, 0.205), (1.382, 0.255), (1.336, 0.254), (1.7869999, 0.255), (1.576, 0.239), (1.444, 0.256), (1.658, 0.206), (1.4299999, 0.239), (1.313, 0.255), (1.306, 0.255), (1.451, 0.271), (1.571, 0.222), (1.028, 0.257), (1.214, 0.255), (1.423, 0.256), (1.719, 0.238), (1.6059999, 0.205), (1.766, 0.255), (1.585, 0.254), (1.614, 0.222), (1.511, 0.223), (1.711, 0.223), (1.707, 0.24), (1.5420001, 0.239), (1.784, 0.205), (2.0469999, 0.255), (1.291, 0.255), (1.517, 0.256), (1.7920001, 0.22), (1.4069999, 0.255), (1.77, 0.239), (1.288, 0.256), (1.353, 0.254), (1.554, 0.238), (1.61, 0.206), (1.471, 0.271), (1.242, 0.206), (1.689, 0.222), (1.784, 0.206), (1.513, 0.255), (1.4170001, 0.222), (0.991, 0.255), (1.372, 0.272), (1.221, 0.222), (1.618, 0.222), (1.464, 0.223), (1.499, 0.223), (1.414, 0.272), (1.846, 0.192), (2.02, 0.223), (1.399, 0.274), (1.83, 0.257), (1.512, 0.275), (1.687, 0.238), (1.663, 0.256), (1.664, 0.241), (1.744, 0.24), (1.612, 0.257), (1.597, 0.275), (1.679, 0.241), (1.931, 0.208), (1.852, 0.207), (1.59, 0.223), (1.941, 0.207), (1.697, 0.24), (1.8839999, 0.24), (1.732, 0.224), (1.913, 0.224), (1.906, 0.225), (1.7309999, 0.24), (1.431, 0.257), (1.883, 0.241), (1.9069999, 0.224), (1.789, 0.191), (1.78, 0.223), (1.896, 0.207), (1.776, 0.24), (1.702, 0.24), (1.895, 0.24), (1.849, 0.223), (1.633, 0.257), (1.883, 0.224), (1.851, 0.207), (1.679, 0.257), (1.506, 0.273), (1.51, 0.241), (1.5700001, 0.256), (1.6109999, 0.24), (1.7869999, 0.223), (1.45, 0.241), (1.526, 0.242), (1.473, 0.239), (1.8329999, 0.224), (1.3329999, 0.241), (1.825, 0.224), (1.42, 0.241), (1.678, 0.191), (1.771, 0.206), (1.677, 0.208), (1.8609999, 0.224), (1.266, 0.273), (1.715, 0.256), (1.487, 0.241), (2.1389999, 0.225), (1.556, 0.257), (1.8049999, 0.222), (2.171, 0.207), (1.446, 0.257), (1.317, 0.272), (1.691, 0.207), (1.67, 0.223), (1.262, 0.258), (1.697, 0.24), (2.0150001, 0.208), (1.55, 0.24), (1.303, 0.276), (1.352, 0.24), (1.353, 0.24), (1.444, 0.24), (1.76, 0.223), (1.5549999, 0.241), (1.7309999, 0.24), (1.369, 0.273), (1.8789999, 0.174), (1.275, 0.257), (1.4960001, 0.241), (1.273, 0.239), (1.651, 0.24), (1.6440001, 0.24), (1.006, 0.223), (1.497, 0.224), (1.099, 0.24), (1.704, 0.238), (1.4220001, 0.242), (1.253, 0.24), (1.4119999, 0.224), (1.826, 0.207), (1.024, 0.272), (1.367, 0.257), (1.865, 0.239), (1.632, 0.225), (1.581, 0.256), (1.113, 0.256), (1.575, 0.208), (1.597, 0.225), (1.159, 0.256), (1.493, 0.24), (1.8099999, 0.241), (1.508, 0.24), (1.719, 0.224), (1.219, 0.256), (1.3279999, 0.24), (1.938, 0.224), (1.466, 0.24), (1.339, 0.239), (1.3279999, 0.256), (1.341, 0.222), (1.459, 0.273), (1.113, 0.273), (1.678, 0.208), (1.3890001, 0.274), (1.251, 0.256), (1.261, 0.274), (1.127, 0.275), (1.081, 0.275), (1.747, 0.24), (1.665, 0.207), (1.607, 0.272), (1.887, 0.223), (1.415, 0.223), (0.93699998, 0.273), (1.59, 0.207), (1.832, 0.206), (1.21, 0.257), (1.694, 0.223), (1.499, 0.206), (1.763, 0.224), (1.3940001, 0.273), (2.0840001, 0.191), (1.868, 0.275), (1.9450001, 0.242), (1.955, 0.241), (1.594, 0.274), (1.831, 0.226), (1.522, 0.275), (1.971, 0.243), (1.895, 0.242), (1.8789999, 0.241), (1.949, 0.226), (1.6339999, 0.276), (2.1949999, 0.225), (1.5470001, 0.259), (1.605, 0.276), (1.633, 0.225), (1.994, 0.226), (1.546, 0.275), (1.934, 0.226), (1.544, 0.243), (1.88, 0.243), (2.1670001, 0.21), (2.0899999, 0.192), (1.636, 0.258), (1.92, 0.242), (1.673, 0.242), (1.55, 0.275), (1.8789999, 0.226), (1.947, 0.209), (1.597, 0.259), (1.699, 0.227), (1.855, 0.259), (1.482, 0.243), (1.8329999, 0.225), (1.671, 0.209), (2.1989999, 0.209), (1.406, 0.274), (1.372, 0.226), (2.112, 0.226), (1.562, 0.242), (2.115, 0.193), (2.0899999, 0.225), (2.096, 0.209), (1.594, 0.242), (1.596, 0.258), (1.437, 0.276), (1.521, 0.275), (1.492, 0.242), (1.5369999, 0.242), (1.998, 0.209), (1.842, 0.241), (1.511, 0.242), (1.706, 0.258), (1.461, 0.275), (1.719, 0.225), (1.485, 0.275), (1.4680001, 0.275), (1.821, 0.226), (2.1029999, 0.242), (1.363, 0.278), (1.908, 0.209), (1.587, 0.275), (1.5700001, 0.243), (1.812, 0.217), (1.845, 0.215), (1.902, 0.216), (2.2739999, 0.182), (1.498, 0.265), (1.901, 0.232), (1.743, 0.249), (2.119, 0.217), (1.715, 0.214), (1.653, 0.249), (1.744, 0.218), (1.428, 0.266), (1.929, 0.216), (2.1210001, 0.2), (1.306, 0.249), (1.714, 0.232), (1.7539999, 0.199), (1.567, 0.249), (1.755, 0.248), (1.534, 0.265), (1.483, 0.249), (1.665, 0.233), (1.699, 0.248), (1.6849999, 0.249), (1.822, 0.215), (1.65, 0.215), (1.584, 0.233), (1.4630001, 0.265), (1.715, 0.216), (1.6900001, 0.248), (1.8559999, 0.249), (2.0880001, 0.201), (1.513, 0.216), (1.729, 0.201), (1.45, 0.266), (1.405, 0.266), (1.865, 0.185), (1.874, 0.218), (1.5, 0.249), (1.794, 0.233), (1.3710001, 0.268), (1.8940001, 0.234), (1.742, 0.218), (1.648, 0.234), (1.645, 0.233), (1.279, 0.25), (1.749, 0.216), (1.743, 0.266), (1.772, 0.219), (1.795, 0.184), (1.599, 0.217), (1.515, 0.268), (1.602, 0.217), (1.295, 0.268), (1.392, 0.248), (1.936, 0.2), (1.601, 0.235), (1.76, 0.184), (1.447, 0.25), (1.6799999, 0.217), (1.745, 0.217), (1.549, 0.266), (1.235, 0.268), (1.501, 0.233), (1.61, 0.219), (1.451, 0.251), (1.302, 0.234), (1.7589999, 0.217), (1.706, 0.2), (1.566, 0.234), (1.521, 0.249), (1.237, 0.251), (1.517, 0.251), (1.853, 0.2), (2.0050001, 0.218), (1.766, 0.201), (1.701, 0.217), (1.598, 0.218), (1.651, 0.25), (1.303, 0.251), (1.387, 0.268), (1.669, 0.234), (1.613, 0.217), (1.464, 0.217), (1.386, 0.25), (1.931, 0.2), (1.534, 0.251), (1.669, 0.234), (1.783, 0.218), (1.3380001, 0.266), (1.462, 0.25), (1.498, 0.249), (1.6849999, 0.25), (1.689, 0.235), (1.73, 0.2), (1.511, 0.25), (1.867, 0.201), (1.441, 0.251), (1.579, 0.218), (2.062, 0.201), (1.498, 0.235), (1.498, 0.267), (1.619, 0.25), (1.433, 0.268), (1.5779999, 0.219), (1.294, 0.218), (1.651, 0.201), (1.698, 0.201), (1.322, 0.251), (1.464, 0.233), (1.851, 0.234), (1.39, 0.267), (1.506, 0.217), (1.61, 0.202), (1.096, 0.233), (1.802, 0.199), (1.318, 0.234), (1.5089999, 0.25), (1.988, 0.184), (1.211, 0.251), (1.302, 0.233), (1.357, 0.267), (1.277, 0.217), (1.166, 0.267), (1.49, 0.251), (1.375, 0.234), (1.47, 0.217), (1.336, 0.25), (1.707, 0.216), (1.429, 0.267), (1.459, 0.2), (1.267, 0.25), (1.8380001, 0.184), (1.663, 0.233), (1.714, 0.202), (1.429, 0.267), (1.83, 0.184), (1.6339999, 0.251), (1.21, 0.269), (1.198, 0.249), (1.388, 0.234), (1.661, 0.25), (1.62, 0.25), (1.794, 0.201), (1.66, 0.217), (1.752, 0.201), (1.21, 0.217), (1.87, 0.216), (1.219, 0.268), (1.709, 0.202), (1.424, 0.266), (1.679, 0.184), (1.607, 0.233), (1.365, 0.251), (1.4299999, 0.216), (1.3329999, 0.218), (1.452, 0.249), (1.39, 0.234), (1.502, 0.218), (1.398, 0.251), (1.068, 0.266), (1.3940001, 0.25), (1.3660001, 0.251), (1.535, 0.218), (1.386, 0.2), (1.353, 0.252), (1.728, 0.217), (1.65, 0.217), (1.573, 0.184), (1.845, 0.217), (1.296, 0.25), (1.249, 0.268), (1.6900001, 0.233), (1.2970001, 0.253), (1.3559999, 0.268), (1.7819999, 0.235), (1.313, 0.252), (1.331, 0.269), (1.385, 0.268), (1.824, 0.202), (1.614, 0.251), (1.569, 0.219), (1.568, 0.253), (1.686, 0.235), (1.138, 0.252), (1.8890001, 0.186), (1.517, 0.254), (1.76, 0.186), (1.697, 0.236), (1.538, 0.237), (1.886, 0.219), (1.405, 0.219), (1.517, 0.269), (1.339, 0.252), (1.596, 0.219), (1.457, 0.252), (1.377, 0.268), (1.561, 0.251), (1.395, 0.269), (1.5549999, 0.235), (1.586, 0.219), (1.679, 0.202), (1.2589999, 0.236), (1.423, 0.251), (1.702, 0.235), (1.477, 0.253), (1.749, 0.202), (1.076, 0.236), (1.559, 0.218), (1.395, 0.268), (1.474, 0.234), (1.3940001, 0.251), (1.938, 0.203), (1.724, 0.186), (1.488, 0.251), (1.5930001, 0.269), (1.505, 0.236), (1.761, 0.203), (1.723, 0.236), (1.591, 0.235), (1.609, 0.235), (1.476, 0.202), (1.739, 0.218), (1.329, 0.251), (1.751, 0.204), (1.751, 0.219), (1.388, 0.234), (1.303, 0.252), (1.278, 0.252), (1.365, 0.268), (1.3279999, 0.268), (1.309, 0.235), (1.223, 0.268), (1.484, 0.218), (1.834, 0.252), (1.5779999, 0.219), (0.92199999, 0.269), (1.704, 0.253), (1.735, 0.219), (1.652, 0.253), (1.859, 0.185), (1.655, 0.202), (1.308, 0.252), (1.476, 0.268), (1.574, 0.202), (1.325, 0.269), (1.821, 0.202), (1.342, 0.235), (1.548, 0.235), (1.7029999, 0.203), (1.1900001, 0.237), (0.88300002, 0.269), (1.169, 0.268), (1.721, 0.235), (1.485, 0.219), (1.601, 0.218), (1.5420001, 0.251), (1.165, 0.251), (1.091, 0.269), (1.298, 0.219), (1.244, 0.235), (0.95700002, 0.268), (1.434, 0.253), (1.2309999, 0.234), (1.062, 0.268), (1.517, 0.203), (1.2460001, 0.219), (0.93300003, 0.235), (1.821, 0.202), (1.541, 0.236), (1.2920001, 0.236), (1.281, 0.268), (1.582, 0.236), (1.327, 0.219), (1.184, 0.269), (1.177, 0.268), (1.284, 0.252), (1.423, 0.268), (1.291, 0.219), (1.4400001, 0.235), (0.92500001, 0.269), (1.2359999, 0.268), (1.176, 0.237), (1.367, 0.268), (1.806, 0.235), (1.733, 0.236), (1.244, 0.269), (1.42, 0.252), (1.409, 0.235), (1.75, 0.236), (1.155, 0.236), (1.3049999, 0.235), (1.915, 0.236), (1.433, 0.236), (1.844, 0.186), (1.558, 0.237), (1.168, 0.235), (1.077, 0.268), (1.183, 0.219), (1.488, 0.218), (1.424, 0.236), (1.505, 0.218), (1.722, 0.201), (1.251, 0.203), (1.3200001, 0.236), (1.4349999, 0.219), (1.284, 0.251), (1.598, 0.203), (1.066, 0.235), (1.1059999, 0.269), (1.768, 0.203), (1.278, 0.277), (1.2690001, 0.316), (1.414, 0.245), (0.995, 0.268), (1.757, 0.235), (1.6289999, 0.221), (1.508, 0.27), (2.1059999, 0.187), (1.408, 0.237), (1.7130001, 0.238), (1.538, 0.256), (1.673, 0.219), (1.255, 0.254), (2.03, 0.188), (1.726, 0.238), (1.4960001, 0.254), (1.587, 0.237), (1.419, 0.252), (1.697, 0.22), (1.903, 0.203), (1.646, 0.22), (1.543, 0.22), (1.717, 0.253), (1.99, 0.204), (1.395, 0.272), (1.78, 0.221), (1.727, 0.22), (1.415, 0.254), (1.8, 0.22), (1.719, 0.189), (1.367, 0.27), (1.257, 0.252), (1.615, 0.237), (1.898, 0.204), (1.459, 0.253), (1.831, 0.221), (1.4630001, 0.238), (1.437, 0.221), (1.3890001, 0.252), (1.655, 0.187), (1.604, 0.236), (1.55, 0.221), (1.802, 0.222), (1.546, 0.204), (1.602, 0.238), (1.383, 0.254), (1.874, 0.221), (1.189, 0.269), (1.1339999, 0.269), (1.309, 0.271), (1.594, 0.236), (1.21, 0.27), (1.6109999, 0.237), (1.476, 0.253), (1.332, 0.238), (1.3, 0.27), (1.152, 0.271), (2.0699999, 0.204), (1.355, 0.236), (1.873, 0.204), (1.317, 0.236), (1.569, 0.269), (1.419, 0.237), (1.589, 0.22), (1.582, 0.271), (1.4910001, 0.204), (1.87, 0.187), (1.324, 0.239), (1.494, 0.237), (1.293, 0.27), (1.506, 0.22), (1.766, 0.237), (1.714, 0.22), (1.256, 0.269), (1.228, 0.253), (1.1900001, 0.253), (1.473, 0.253), (1.087, 0.271), (1.258, 0.254), (1.454, 0.235), (1.354, 0.237), (1.5650001, 0.27), (1.4349999, 0.254), (1.424, 0.253), (1.074, 0.253), (1.308, 0.254), (1.146, 0.237), (1.561, 0.22), (1.595, 0.22), (1.073, 0.269), (1.05, 0.254), (1.0140001, 0.254), (1.221, 0.254), (0.80800003, 0.271), (1.414, 0.221), (1.211, 0.254), (1.197, 0.27), (1.4960001, 0.187), (1.5, 0.271), (1.436, 0.22), (1.697, 0.221), (1.187, 0.27), (1.444, 0.204), (1.794, 0.204), (1.178, 0.237), (1.801, 0.221), (1.117, 0.27), (1.204, 0.253), (1.446, 0.27), (1.494, 0.221), (1.3329999, 0.27), (1.5549999, 0.235), (1.556, 0.237), (1.473, 0.237), (1.341, 0.254), (1.373, 0.27), (1.709, 0.239), (1.592, 0.204), (1.3660001, 0.253), (1.378, 0.238), (1.636, 0.204), (0.96899998, 0.22), (1.028, 0.253), (1.1670001, 0.272), (1.45, 0.238), (1.252, 0.254), (1.245, 0.237), (1.812, 0.221), (1.098, 0.269), (1.258, 0.237), (1.674, 0.221), (1.396, 0.236), (1.168, 0.253), (1.369, 0.219), (1.716, 0.219), (1.883, 0.204), (1.117, 0.237), (1.789, 0.221), (1.337, 0.221), (1.209, 0.27), (1.844, 0.204), (1.554, 0.256), (1.376, 0.272), (1.681, 0.206), (1.651, 0.239), (1.421, 0.255), (1.591, 0.239), (1.464, 0.239), (1.7920001, 0.189), (1.308, 0.239), (1.348, 0.257), (1.533, 0.271), (1.421, 0.221), (1.625, 0.222), (1.5779999, 0.272), (1.133, 0.271), (1.924, 0.19), (1.5599999, 0.222), (1.582, 0.205), (1.337, 0.272), (1.516, 0.239), (1.153, 0.254), (1.545, 0.27), (1.623, 0.206), (1.974, 0.19), (1.5190001, 0.241), (1.543, 0.239), (1.857, 0.238), (1.6109999, 0.239), (1.479, 0.221), (2.007, 0.206), (1.6059999, 0.238), (1.923, 0.206), (1.38, 0.255), (1.207, 0.256), (1.277, 0.253), (1.503, 0.239), (1.2970001, 0.223), (1.433, 0.272), (1.341, 0.256), (1.334, 0.238), (1.367, 0.256), (1.385, 0.254), (1.761, 0.238), (1.307, 0.271), (1.306, 0.24), (1.6440001, 0.238), (1.455, 0.205), (1.336, 0.272), (1.164, 0.271), (1.471, 0.222), (1.456, 0.273), (1.404, 0.255), (1.581, 0.222), (1.4859999, 0.239), (1.392, 0.221), (1.4630001, 0.272), (1.459, 0.271), (1.608, 0.238), (1.2410001, 0.256), (1.523, 0.271), (1.2819999, 0.257), (1.674, 0.239), (1.743, 0.239), (1.176, 0.256), (1.673, 0.271), (1.52, 0.238), (1.4220001, 0.239), (1.586, 0.272), (1.2539999, 0.256), (1.527, 0.222), (1.408, 0.239), (1.342, 0.239), (1.665, 0.256), (1.267, 0.271), (1.04, 0.239), (1.24, 0.256), (1.483, 0.239), (1.4400001, 0.238), (1.495, 0.27), (1.3099999, 0.272), (1.182, 0.255), (1.135, 0.253), (1.397, 0.239), (1.075, 0.27), (1.061, 0.238), (1.732, 0.205), (1.154, 0.255), (0.97899997, 0.221), (1.8329999, 0.205), (1.234, 0.254), (1.188, 0.255), (1.669, 0.256), (1.467, 0.239), (1.3099999, 0.255), (1.513, 0.205), (1.325, 0.24), (1.189, 0.257), (1.178, 0.255), (1.353, 0.272), (1.436, 0.222), (0.94800001, 0.257), (1.097, 0.254), (1.341, 0.254), (1.604, 0.239), (1.401, 0.206), (1.6390001, 0.255), (1.517, 0.254), (1.4630001, 0.221), (1.392, 0.222), (1.5599999, 0.222), (1.572, 0.239), (1.427, 0.239), (1.61, 0.205), (1.886, 0.255), (1.207, 0.255), (1.385, 0.255), (1.668, 0.222), (1.302, 0.255), (1.659, 0.238), (1.1569999, 0.256), (1.263, 0.254), (1.409, 0.238), (1.4349999, 0.205), (1.392, 0.271), (1.017, 0.206), (1.551, 0.222), (1.633, 0.205), (1.395, 0.256), (1.28, 0.222), (0.903, 0.255), (1.307, 0.272), (1.109, 0.222), (1.498, 0.222), (1.346, 0.222), (1.321, 0.222), (1.306, 0.271), (1.691, 0.191), (1.817, 0.223), (1.286, 0.273), (1.702, 0.257), (1.452, 0.273), (1.503, 0.24), (1.511, 0.257), (1.501, 0.241), (1.587, 0.24), (1.461, 0.258), (1.497, 0.273), (1.566, 0.242), (1.771, 0.206), (1.701, 0.208), (1.465, 0.223), (1.822, 0.207), (1.529, 0.24), (1.78, 0.24), (1.631, 0.224), (1.753, 0.223), (1.714, 0.224), (1.589, 0.239), (1.299, 0.258), (1.78, 0.24), (1.777, 0.224), (1.582, 0.191), (1.624, 0.224), (1.692, 0.207), (1.602, 0.24), (1.554, 0.24), (1.749, 0.243), (1.665, 0.223), (1.534, 0.258), (1.666, 0.225), (1.725, 0.207), (1.5190001, 0.257), (1.382, 0.273), (1.409, 0.241), (1.396, 0.257), (1.522, 0.24), (1.648, 0.224), (1.351, 0.24), (1.406, 0.239), (1.4, 0.241), (1.688, 0.224), (1.247, 0.24), (1.737, 0.223), (1.275, 0.24), (1.515, 0.191), (1.5930001, 0.207), (1.498, 0.208), (1.77, 0.225), (1.199, 0.274), (1.54, 0.257), (1.322, 0.241), (1.998, 0.224), (1.418, 0.257), (1.643, 0.224), (1.99, 0.207), (1.351, 0.257), (1.2410001, 0.273), (1.6109999, 0.208), (1.584, 0.225), (1.128, 0.256), (1.628, 0.24), (1.8, 0.208), (1.401, 0.241), (1.164, 0.274), (1.215, 0.24), (1.226, 0.24), (1.374, 0.241), (1.637, 0.224), (1.447, 0.243), (1.55, 0.24), (1.2539999, 0.273), (1.75, 0.175), (1.174, 0.258), (1.353, 0.239), (1.151, 0.239), (1.529, 0.239), (1.406, 0.24), (0.84799999, 0.223), (1.373, 0.225), (0.94, 0.24), (1.643, 0.24), (1.253, 0.239), (1.187, 0.24), (1.306, 0.223), (1.696, 0.207), (0.95099998, 0.273), (1.266, 0.256), (1.676, 0.241), (1.442, 0.225), (1.495, 0.257), (1.007, 0.257), (1.421, 0.207), (1.4529999, 0.223), (1.076, 0.259), (1.386, 0.239), (1.7180001, 0.241), (1.4680001, 0.243), (1.566, 0.223), (1.119, 0.257), (1.1900001, 0.24), (1.802, 0.224), (1.335, 0.239), (1.198, 0.24), (1.256, 0.257), (1.2180001, 0.223), (1.355, 0.273), (1.0420001, 0.273), (1.483, 0.208), (1.302, 0.274), (1.1720001, 0.258), (1.14, 0.273), (1.053, 0.273), (0.97000003, 0.274), (1.587, 0.24), (1.5470001, 0.207), (1.516, 0.273), (1.6950001, 0.224), (1.346, 0.224), (0.87199998, 0.273), (1.472, 0.206), (1.686, 0.209), (1.094, 0.258), (1.584, 0.223), (1.324, 0.209), (1.619, 0.222), (1.2819999, 0.274), (1.874, 0.191), (1.801, 0.274), (1.826, 0.242), (1.818, 0.241), (1.5039999, 0.276), (1.642, 0.225), (1.39, 0.275), (1.877, 0.242), (1.86, 0.243), (1.723, 0.243), (1.773, 0.226), (1.517, 0.274), (2.0669999, 0.225), (1.441, 0.258), (1.527, 0.274), (1.544, 0.224), (1.8940001, 0.224), (1.414, 0.274), (1.761, 0.226), (1.397, 0.242), (1.8, 0.242), (1.964, 0.209), (1.895, 0.192), (1.557, 0.259), (1.819, 0.242), (1.598, 0.242), (1.4910001, 0.275), (1.791, 0.226), (1.847, 0.209), (1.493, 0.259), (1.623, 0.226), (1.7539999, 0.259), (1.388, 0.242), (1.721, 0.224), (1.6059999, 0.209), (2.0539999, 0.208), (1.298, 0.276), (1.229, 0.226), (1.983, 0.224), (1.459, 0.242), (2.0150001, 0.192), (1.9680001, 0.227), (1.947, 0.209), (1.454, 0.243), (1.4809999, 0.257), (1.362, 0.275), (1.386, 0.274), (1.357, 0.242), (1.467, 0.242), (1.8660001, 0.209), (1.74, 0.242), (1.403, 0.242), (1.604, 0.258), (1.3660001, 0.274), (1.59, 0.225), (1.4069999, 0.275), (1.352, 0.276), (1.677, 0.226), (1.983, 0.243), (1.289, 0.274), (1.784, 0.209), (1.497, 0.274), (1.441, 0.243), (1.698, 0.215), (1.694, 0.215), (1.775, 0.217), (2.1170001, 0.182), (1.414, 0.265), (1.77, 0.232), (1.6670001, 0.251), (1.99, 0.215), (1.6059999, 0.216), (1.543, 0.248), (1.619, 0.215), (1.354, 0.267), (1.811, 0.215), (2.0320001, 0.199), (1.237, 0.249), (1.628, 0.232), (1.641, 0.198), (1.501, 0.249), (1.668, 0.25), (1.447, 0.265), (1.3559999, 0.248), (1.5700001, 0.233), (1.589, 0.248), (1.579, 0.248), (1.6670001, 0.215), (1.5599999, 0.217), (1.511, 0.231), (1.411, 0.265), (1.619, 0.215), (1.6059999, 0.249), (1.727, 0.251), (1.967, 0.201), (1.378, 0.218), (1.615, 0.202), (1.355, 0.267), (1.273, 0.267), (1.6720001, 0.184), (1.702, 0.217), (1.415, 0.25), (1.645, 0.233), (1.278, 0.267), (1.7690001, 0.234), (1.6, 0.217), (1.536, 0.233), (1.586, 0.233), (1.189, 0.25), (1.6059999, 0.217), (1.6289999, 0.266), (1.686, 0.217), (1.579, 0.184), (1.4400001, 0.217), (1.456, 0.266), (1.531, 0.217), (1.187, 0.268), (1.319, 0.251), (1.898, 0.201), (1.47, 0.234), (1.562, 0.184), (1.326, 0.25), (1.529, 0.217), (1.652, 0.217), (1.424, 0.267), (1.182, 0.267), (1.377, 0.234), (1.499, 0.217), (1.377, 0.251), (1.183, 0.234), (1.599, 0.218), (1.534, 0.2), (1.459, 0.234), (1.472, 0.25), (1.145, 0.249), (1.443, 0.25), (1.7589999, 0.201), (1.8430001, 0.216), (1.572, 0.2), (1.609, 0.216), (1.492, 0.218), (1.501, 0.251), (1.191, 0.249), (1.325, 0.267), (1.625, 0.233), (1.501, 0.217), (1.34, 0.219), (1.274, 0.252), (1.732, 0.202), (1.465, 0.251), (1.517, 0.235), (1.649, 0.217), (1.222, 0.266), (1.325, 0.251), (1.385, 0.251), (1.605, 0.251), (1.586, 0.233), (1.664, 0.201), (1.392, 0.25), (1.692, 0.2), (1.392, 0.251), (1.477, 0.216), (1.915, 0.2), (1.413, 0.233), (1.411, 0.267), (1.533, 0.251), (1.326, 0.268), (1.459, 0.215), (1.191, 0.218), (1.5319999, 0.202), (1.571, 0.201), (1.174, 0.25), (1.399, 0.236), (1.712, 0.234), (1.306, 0.266), (1.377, 0.217), (1.4579999, 0.201), (0.98199999, 0.234), (1.66, 0.201), (1.2180001, 0.233), (1.391, 0.25), (1.76, 0.184), (1.089, 0.251), (1.168, 0.235), (1.2690001, 0.267), (1.153, 0.217), (1.069, 0.266), (1.3710001, 0.25), (1.2359999, 0.234), (1.352, 0.218), (1.217, 0.251), (1.612, 0.217), (1.347, 0.267), (1.3099999, 0.201), (1.163, 0.251), (1.666, 0.184), (1.5549999, 0.234), (1.64, 0.201), (1.303, 0.267), (1.619, 0.184), (1.497, 0.25), (1.117, 0.267), (1.123, 0.251), (1.301, 0.233), (1.566, 0.249), (1.51, 0.249), (1.6950001, 0.2), (1.476, 0.217), (1.61, 0.2), (1.143, 0.217), (1.7309999, 0.217), (1.177, 0.266), (1.584, 0.2), (1.367, 0.268), (1.467, 0.184), (1.482, 0.234), (1.298, 0.251), (1.342, 0.218), (1.2539999, 0.217), (1.332, 0.251), (1.281, 0.233), (1.367, 0.217), (1.2920001, 0.25), (0.99699998, 0.265), (1.299, 0.25), (1.267, 0.251), (1.424, 0.216), (1.35, 0.201), (1.2869999, 0.25), (1.571, 0.218), (1.526, 0.217), (1.405, 0.184), (1.757, 0.217), (1.2079999, 0.251), (1.154, 0.268), (1.5420001, 0.234), (1.199, 0.252), (1.2640001, 0.268), (1.686, 0.235), (1.205, 0.251), (1.274, 0.267), (1.2410001, 0.268), (1.6670001, 0.203), (1.489, 0.253), (1.4579999, 0.218), (1.421, 0.252), (1.597, 0.235), (1.075, 0.252), (1.762, 0.186), (1.391, 0.251), (1.594, 0.186), (1.607, 0.236), (1.438, 0.236), (1.72, 0.22), (1.272, 0.219), (1.402, 0.268), (1.205, 0.253), (1.408, 0.22), (1.353, 0.252), (1.239, 0.269), (1.452, 0.253), (1.281, 0.267), (1.469, 0.236), (1.457, 0.219), (1.569, 0.202), (1.164, 0.236), (1.34, 0.255), (1.539, 0.236), (1.352, 0.253), (1.63, 0.203), (0.99800003, 0.235), (1.4630001, 0.218), (1.277, 0.267), (1.3200001, 0.236), (1.239, 0.251), (1.816, 0.203), (1.564, 0.185), (1.38, 0.252), (1.472, 0.269), (1.406, 0.237), (1.594, 0.203), (1.574, 0.235), (1.48, 0.234), (1.515, 0.236), (1.335, 0.203), (1.569, 0.217), (1.191, 0.251), (1.6339999, 0.203), (1.614, 0.221), (1.258, 0.236), (1.165, 0.251), (1.1339999, 0.251), (1.258, 0.268), (1.26, 0.268), (1.2079999, 0.234), (1.166, 0.268), (1.392, 0.219), (1.758, 0.253), (1.501, 0.219), (0.85299999, 0.268), (1.613, 0.252), (1.608, 0.218), (1.5549999, 0.252), (1.661, 0.186), (1.507, 0.202), (1.219, 0.253), (1.376, 0.269), (1.495, 0.203), (1.238, 0.268), (1.6720001, 0.202), (1.2640001, 0.234), (1.419, 0.235), (1.536, 0.203), (1.095, 0.236), (0.77700001, 0.268), (1.072, 0.268), (1.598, 0.235), (1.352, 0.218), (1.48, 0.219), (1.469, 0.251), (1.096, 0.252), (0.98100001, 0.268), (1.1799999, 0.22), (1.161, 0.236), (0.85100001, 0.268), (1.349, 0.252), (1.068, 0.236), (0.94700003, 0.268), (1.386, 0.203), (1.131, 0.219), (0.815, 0.235), (1.705, 0.203), (1.437, 0.234), (1.13, 0.235), (1.168, 0.268), (1.47, 0.236), (1.216, 0.22), (1.1210001, 0.268), (1.1, 0.269), (1.183, 0.253), (1.358, 0.267), (1.188, 0.219), (1.281, 0.235), (0.84200001, 0.27), (1.1799999, 0.27), (1.066, 0.235), (1.239, 0.267), (1.707, 0.235), (1.62, 0.236), (1.166, 0.269), (1.308, 0.253), (1.253, 0.236), (1.6390001, 0.236), (1.062, 0.235), (1.215, 0.236), (1.799, 0.236), (1.33, 0.234), (1.7079999, 0.186), (1.443, 0.235), (1.081, 0.234), (0.99800003, 0.268), (1.084, 0.219), (1.3559999, 0.218), (1.313, 0.235), (1.3710001, 0.218), (1.579, 0.202), (1.146, 0.203), (1.216, 0.235), (1.352, 0.218), (1.2079999, 0.251), (1.465, 0.203), (0.94099998, 0.235), (1.086, 0.269), (1.683, 0.202), (1.164, 0.272), (1.22, 0.307), (1.301, 0.243), (0.91399997, 0.267), (1.618, 0.235), (1.473, 0.22), (1.4170001, 0.271), (1.926, 0.188), (1.298, 0.237), (1.568, 0.236), (1.41, 0.254), (1.515, 0.221), (1.15, 0.253), (1.8430001, 0.188), (1.61, 0.236), (1.466, 0.254), (1.4910001, 0.237), (1.349, 0.253), (1.592, 0.22), (1.762, 0.203), (1.485, 0.221), (1.376, 0.22), (1.625, 0.254), (1.848, 0.204), (1.3150001, 0.269), (1.696, 0.221), (1.592, 0.22), (1.298, 0.254), (1.663, 0.222), (1.601, 0.187), (1.275, 0.271), (1.191, 0.253), (1.527, 0.237), (1.76, 0.203), (1.339, 0.253), (1.7640001, 0.22), (1.355, 0.237), (1.309, 0.221), (1.3, 0.252), (1.485, 0.187), (1.466, 0.236), (1.473, 0.219), (1.62, 0.221), (1.464, 0.204), (1.48, 0.238), (1.3380001, 0.253), (1.719, 0.221), (1.1160001, 0.269), (1.0190001, 0.269), (1.193, 0.269), (1.436, 0.237), (1.0470001, 0.269), (1.452, 0.237), (1.3660001, 0.253), (1.22, 0.236), (1.184, 0.271), (1.085, 0.269), (1.939, 0.204), (1.2180001, 0.237), (1.664, 0.204), (1.1720001, 0.237), (1.494, 0.27), (1.312, 0.237), (1.474, 0.221), (1.451, 0.27), (1.306, 0.204), (1.642, 0.188), (1.224, 0.237), (1.388, 0.238), (1.205, 0.27), (1.402, 0.221), (1.615, 0.237), (1.526, 0.221), (1.14, 0.269), (1.163, 0.254), (1.127, 0.254), (1.358, 0.255), (0.98100001, 0.27), (1.159, 0.254), (1.378, 0.237), (1.224, 0.237), (1.459, 0.269), (1.312, 0.256), (1.368, 0.254), (0.94599998, 0.253), (1.23, 0.252), (1.0369999, 0.237), (1.436, 0.221), (1.517, 0.22), (0.972, 0.27), (1.002, 0.253), (0.90899998, 0.254), (1.125, 0.253), (0.68599999, 0.27), (1.3710001, 0.219), (1.124, 0.253), (1.153, 0.268), (1.336, 0.187), (1.436, 0.269), (1.296, 0.22), (1.61, 0.22), (1.097, 0.269), (1.337, 0.203), (1.661, 0.205), (1.049, 0.236), (1.709, 0.22), (1.0549999, 0.27), (1.1059999, 0.254), (1.376, 0.271), (1.3609999, 0.221), (1.228, 0.27), (1.436, 0.238), (1.4170001, 0.235), (1.372, 0.237), (1.2309999, 0.255), (1.275, 0.269), (1.591, 0.236), (1.443, 0.204), (1.26, 0.253), (1.298, 0.237), (1.525, 0.204), (0.87900001, 0.22), (0.954, 0.254), (1.097, 0.27), (1.3660001, 0.238), (1.155, 0.252), (1.142, 0.236), (1.6950001, 0.222), (1.0, 0.271), (1.155, 0.237), (1.571, 0.222), (1.334, 0.237), (1.084, 0.254), (1.216, 0.219), (1.524, 0.22), (1.749, 0.204), (0.98900002, 0.238), (1.648, 0.22), (1.2, 0.22), (1.135, 0.269), (1.7079999, 0.204), (1.4400001, 0.255), (1.273, 0.271), (1.5700001, 0.205), (1.522, 0.239), (1.316, 0.255), (1.35, 0.239), (1.357, 0.238), (1.614, 0.19), (1.177, 0.24), (1.22, 0.255), (1.471, 0.269), (1.2819999, 0.222), (1.48, 0.223), (1.446, 0.272), (1.044, 0.273), (1.801, 0.189), (1.396, 0.223), (1.404, 0.205), (1.2589999, 0.271), (1.351, 0.239), (1.063, 0.255), (1.52, 0.273), (1.408, 0.206), (1.806, 0.189), (1.433, 0.239), (1.45, 0.239), (1.767, 0.238), (1.5140001, 0.239), (1.243, 0.223), (1.823, 0.205), (1.501, 0.238), (1.6900001, 0.205), (1.2920001, 0.255), (1.126, 0.253), (1.204, 0.255), (1.354, 0.239), (1.179, 0.222), (1.281, 0.272), (1.273, 0.256), (1.219, 0.238), (1.265, 0.254), (1.265, 0.255), (1.63, 0.238), (1.2, 0.272), (1.1849999, 0.238), (1.5089999, 0.239), (1.357, 0.205), (1.2460001, 0.272), (1.057, 0.272), (1.376, 0.222), (1.382, 0.271), (1.303, 0.255), (1.425, 0.223), (1.352, 0.238), (1.252, 0.222), (1.352, 0.272), (1.367, 0.27), (1.54, 0.238), (1.113, 0.256), (1.457, 0.272), (1.154, 0.256), (1.493, 0.238), (1.631, 0.239), (1.098, 0.256), (1.559, 0.271), (1.421, 0.239), (1.294, 0.239), (1.471, 0.272), (1.145, 0.255), (1.37, 0.222), (1.324, 0.239), (1.243, 0.238), (1.5779999, 0.256), (1.189, 0.272), (0.94400001, 0.238), (1.174, 0.256), (1.404, 0.239), (1.36, 0.239), (1.397, 0.271), (1.243, 0.272), (1.057, 0.255), (1.079, 0.255), (1.319, 0.24), (1.038, 0.271), (0.93900001, 0.238), (1.581, 0.206), (1.052, 0.254), (0.86900002, 0.222), (1.706, 0.205), (1.17, 0.256), (1.061, 0.256), (1.581, 0.256), (1.337, 0.239), (1.248, 0.255), (1.334, 0.206), (1.2359999, 0.24), (1.107, 0.256), (1.095, 0.255), (1.294, 0.271), (1.326, 0.222), (0.875, 0.256), (0.97299999, 0.256), (1.267, 0.256), (1.473, 0.238), (1.252, 0.206), (1.483, 0.256), (1.353, 0.254), (1.3789999, 0.223), (1.2589999, 0.222), (1.449, 0.222), (1.472, 0.238), (1.308, 0.238), (1.4910001, 0.204), (1.8150001, 0.255), (1.135, 0.255), (1.329, 0.254), (1.598, 0.222), (1.222, 0.254), (1.573, 0.238), (1.057, 0.256), (1.171, 0.256), (1.2819999, 0.237), (1.304, 0.206), (1.322, 0.271), (0.92000002, 0.207), (1.476, 0.223), (1.489, 0.205), (1.345, 0.255), (1.141, 0.223), (0.82499999, 0.255), (1.227, 0.273), (1.053, 0.222), (1.345, 0.224), (1.201, 0.223), (1.197, 0.221), (1.2130001, 0.271), (1.527, 0.19), (1.701, 0.223), (1.198, 0.273), (1.631, 0.256), (1.345, 0.275), (1.374, 0.241), (1.402, 0.256), (1.36, 0.24), (1.473, 0.24), (1.3940001, 0.256), (1.402, 0.273), (1.4529999, 0.24), (1.572, 0.208), (1.594, 0.208), (1.35, 0.224), (1.6440001, 0.207), (1.432, 0.241), (1.633, 0.241), (1.506, 0.223), (1.665, 0.223), (1.591, 0.225), (1.483, 0.24), (1.209, 0.257), (1.585, 0.243), (1.711, 0.224), (1.403, 0.191), (1.469, 0.226), (1.516, 0.206), (1.478, 0.241), (1.404, 0.241), (1.591, 0.241), (1.47, 0.224), (1.428, 0.258), (1.536, 0.223), (1.585, 0.208), (1.398, 0.256), (1.2970001, 0.273), (1.229, 0.239), (1.2869999, 0.256), (1.4299999, 0.24), (1.521, 0.224), (1.2, 0.24), (1.308, 0.24), (1.293, 0.24), (1.545, 0.224), (1.105, 0.24), (1.608, 0.224), (1.206, 0.24), (1.334, 0.19), (1.411, 0.206), (1.358, 0.208), (1.617, 0.224), (1.066, 0.273), (1.461, 0.256), (1.205, 0.241), (1.852, 0.224), (1.307, 0.257), (1.551, 0.223), (1.844, 0.207), (1.244, 0.255), (1.132, 0.273), (1.455, 0.207), (1.401, 0.224), (1.015, 0.257), (1.4680001, 0.241), (1.63, 0.207), (1.347, 0.24), (1.133, 0.273), (1.11, 0.241), (1.115, 0.241), (1.251, 0.239), (1.543, 0.223), (1.33, 0.24), (1.452, 0.24), (1.1619999, 0.272), (1.568, 0.174), (1.085, 0.256), (1.225, 0.24), (1.046, 0.241), (1.438, 0.24), (1.2589999, 0.241), (0.74199998, 0.223), (1.214, 0.224), (0.84899998, 0.24), (1.487, 0.24), (1.152, 0.239), (1.041, 0.243), (1.1670001, 0.223), (1.545, 0.208), (0.87699997, 0.274), (1.181, 0.257), (1.568, 0.241), (1.319, 0.224), (1.349, 0.255), (0.93000001, 0.256), (1.317, 0.207), (1.38, 0.224), (1.001, 0.257), (1.293, 0.24), (1.646, 0.24), (1.308, 0.24), (1.432, 0.223), (1.0599999, 0.255), (1.068, 0.239), (1.702, 0.223), (1.2029999, 0.241), (1.085, 0.239), (1.175, 0.258), (1.205, 0.223), (1.28, 0.274), (0.94599998, 0.274), (1.342, 0.209), (1.227, 0.275), (1.114, 0.258), (1.066, 0.274), (1.0, 0.273), (0.91799998, 0.273), (1.502, 0.241), (1.383, 0.207), (1.421, 0.273), (1.599, 0.225), (1.2130001, 0.225), (0.79500002, 0.273), (1.351, 0.207), (1.536, 0.208), (1.039, 0.256), (1.502, 0.223), (1.196, 0.207), (1.545, 0.224), (1.1900001, 0.273), (1.658, 0.192), (1.712, 0.274), (1.683, 0.241), (1.661, 0.241), (1.382, 0.274), (1.501, 0.228), (1.293, 0.275), (1.7180001, 0.241), (1.7130001, 0.242), (1.631, 0.242), (1.598, 0.225), (1.415, 0.275), (1.975, 0.224), (1.368, 0.257), (1.405, 0.275), (1.413, 0.226), (1.742, 0.226), (1.3789999, 0.274), (1.614, 0.226), (1.3099999, 0.243), (1.663, 0.241), (1.808, 0.208), (1.747, 0.193), (1.479, 0.258), (1.7029999, 0.243), (1.505, 0.242), (1.396, 0.274), (1.648, 0.225), (1.701, 0.209), (1.388, 0.259), (1.584, 0.226), (1.6339999, 0.258), (1.309, 0.241), (1.5369999, 0.225), (1.473, 0.209), (1.851, 0.209), (1.21, 0.274), (1.122, 0.227), (1.904, 0.225), (1.347, 0.241), (1.774, 0.192), (1.857, 0.225), (1.808, 0.209), (1.372, 0.242), (1.348, 0.257), (1.24, 0.275), (1.3099999, 0.274), (1.248, 0.24), (1.318, 0.241), (1.802, 0.208), (1.608, 0.243), (1.299, 0.242), (1.522, 0.259), (1.295, 0.275), (1.5140001, 0.224), (1.346, 0.275), (1.277, 0.276), (1.573, 0.225), (1.905, 0.241), (1.2130001, 0.275), (1.592, 0.208), (1.438, 0.275), (1.4069999, 0.242), (1.612, 0.216), (1.609, 0.215), (1.648, 0.216), (1.966, 0.182), (1.3380001, 0.265), (1.6670001, 0.231), (1.573, 0.249), (1.915, 0.215), (1.475, 0.216), (1.5140001, 0.249), (1.524, 0.216), (1.2920001, 0.265), (1.6950001, 0.215), (1.888, 0.199), (1.179, 0.249), (1.521, 0.232), (1.518, 0.199), (1.45, 0.249), (1.564, 0.25), (1.4220001, 0.265), (1.248, 0.249), (1.521, 0.233), (1.511, 0.248), (1.5140001, 0.249), (1.561, 0.216), (1.452, 0.215), (1.409, 0.232), (1.352, 0.266), (1.508, 0.215), (1.525, 0.248), (1.687, 0.251), (1.816, 0.2), (1.242, 0.217), (1.5089999, 0.2), (1.263, 0.266), (1.182, 0.267), (1.603, 0.184), (1.567, 0.217), (1.3380001, 0.25), (1.526, 0.235), (1.193, 0.266), (1.649, 0.233), (1.493, 0.217), (1.431, 0.234), (1.507, 0.233), (1.079, 0.251), (1.493, 0.216), (1.549, 0.267), (1.513, 0.217), (1.42, 0.184), (1.358, 0.217), (1.367, 0.267), (1.399, 0.217), (1.136, 0.265), (1.229, 0.25), (1.76, 0.201), (1.36, 0.233), (1.4, 0.185), (1.224, 0.25), (1.381, 0.218), (1.5700001, 0.217), (1.3660001, 0.267), (1.102, 0.267), (1.322, 0.234), (1.398, 0.217), (1.281, 0.251), (1.084, 0.234), (1.4529999, 0.218), (1.423, 0.2), (1.332, 0.233), (1.424, 0.251), (1.046, 0.25), (1.337, 0.25), (1.626, 0.201), (1.704, 0.217), (1.418, 0.201), (1.526, 0.217), (1.381, 0.219), (1.426, 0.251), (1.094, 0.25), (1.223, 0.267), (1.5089999, 0.234), (1.3789999, 0.217), (1.281, 0.217), (1.207, 0.249), (1.52, 0.202), (1.376, 0.251), (1.403, 0.234), (1.5369999, 0.217), (1.168, 0.267), (1.262, 0.251), (1.27, 0.249), (1.5, 0.25), (1.437, 0.234), (1.502, 0.2), (1.306, 0.252), (1.577, 0.201), (1.294, 0.248), (1.304, 0.218), (1.765, 0.2), (1.289, 0.234), (1.3430001, 0.267), (1.414, 0.251), (1.256, 0.267), (1.344, 0.218), (1.084, 0.217), (1.393, 0.201), (1.454, 0.201), (1.0599999, 0.251), (1.271, 0.233), (1.605, 0.233), (1.2309999, 0.268), (1.255, 0.217), (1.369, 0.201), (0.87800002, 0.235), (1.567, 0.2), (1.128, 0.234), (1.317, 0.25), (1.618, 0.184), (1.033, 0.249), (1.0470001, 0.234), (1.166, 0.265), (1.013, 0.217), (0.98900002, 0.266), (1.302, 0.249), (1.159, 0.233), (1.199, 0.217), (1.127, 0.25), (1.46, 0.217), (1.283, 0.267), (1.232, 0.201), (1.051, 0.251), (1.51, 0.184), (1.41, 0.234), (1.513, 0.201), (1.2359999, 0.266), (1.475, 0.184), (1.4119999, 0.251), (1.003, 0.267), (1.0369999, 0.248), (1.2309999, 0.233), (1.425, 0.25), (1.416, 0.252), (1.512, 0.201), (1.351, 0.217), (1.499, 0.2), (1.025, 0.217), (1.6289999, 0.218), (1.097, 0.266), (1.409, 0.2), (1.2690001, 0.266), (1.4220001, 0.184), (1.41, 0.234), (1.205, 0.249), (1.261, 0.217), (1.158, 0.218), (1.299, 0.249), (1.155, 0.233), (1.2359999, 0.216), (1.222, 0.251), (0.89300001, 0.269), (1.2410001, 0.251), (1.217, 0.25), (1.307, 0.217), (1.261, 0.201), (1.1900001, 0.25), (1.4630001, 0.217), (1.427, 0.217), (1.273, 0.184), (1.632, 0.217), (1.152, 0.25), (1.079, 0.268), (1.446, 0.233), (1.158, 0.253), (1.193, 0.269), (1.577, 0.235), (1.109, 0.252), (1.204, 0.269), (1.2029999, 0.27), (1.45, 0.202), (1.392, 0.251), (1.383, 0.218), (1.321, 0.251), (1.487, 0.234), (0.95999998, 0.251), (1.656, 0.187), (1.33, 0.252), (1.441, 0.186), (1.488, 0.236), (1.2690001, 0.235), (1.614, 0.22), (1.126, 0.218), (1.3380001, 0.269), (1.096, 0.252), (1.2920001, 0.219), (1.267, 0.252), (1.1619999, 0.268), (1.357, 0.253), (1.145, 0.269), (1.3940001, 0.235), (1.3609999, 0.219), (1.4170001, 0.203), (1.095, 0.235), (1.273, 0.252), (1.4349999, 0.235), (1.288, 0.252), (1.515, 0.202), (0.92000002, 0.236), (1.382, 0.219), (1.214, 0.268), (1.228, 0.236), (1.132, 0.252), (1.651, 0.202), (1.386, 0.186), (1.268, 0.252), (1.376, 0.269), (1.2869999, 0.237), (1.507, 0.203), (1.484, 0.236), (1.419, 0.234), (1.388, 0.235), (1.233, 0.202), (1.469, 0.22), (1.073, 0.252), (1.515, 0.203), (1.409, 0.219), (1.183, 0.235), (1.081, 0.251), (1.082, 0.252), (1.1720001, 0.269), (1.1849999, 0.268), (1.155, 0.235), (1.039, 0.269), (1.293, 0.218), (1.684, 0.25), (1.36, 0.219), (0.74400002, 0.268), (1.534, 0.252), (1.485, 0.218), (1.501, 0.252), (1.563, 0.186), (1.39, 0.202), (1.1059999, 0.252), (1.29, 0.27), (1.337, 0.204), (1.135, 0.269), (1.5369999, 0.203), (1.179, 0.235), (1.304, 0.236), (1.415, 0.202), (1.013, 0.235), (0.69300002, 0.27), (0.98199999, 0.268), (1.49, 0.236), (1.247, 0.218), (1.424, 0.219), (1.369, 0.252), (0.99800003, 0.251), (0.89099997, 0.269), (1.089, 0.218), (1.087, 0.235), (0.801, 0.269), (1.245, 0.253), (0.98299998, 0.235), (0.86699998, 0.268), (1.196, 0.202), (1.022, 0.22), (0.70700002, 0.235), (1.5779999, 0.201), (1.317, 0.235), (1.013, 0.236), (1.1210001, 0.268), (1.385, 0.235), (1.12, 0.219), (1.002, 0.269), (1.026, 0.27), (1.113, 0.253), (1.309, 0.267), (1.0779999, 0.22), (1.225, 0.236), (0.77899998, 0.269), (1.117, 0.27), (1.0039999, 0.235), (1.187, 0.268), (1.567, 0.235), (1.472, 0.236), (1.059, 0.268), (1.235, 0.252), (1.1109999, 0.236), (1.566, 0.235), (1.026, 0.236), (1.11, 0.236), (1.743, 0.235), (1.224, 0.235), (1.515, 0.186), (1.355, 0.235), (0.98100001, 0.235), (0.90899998, 0.268), (0.99000001, 0.219), (1.247, 0.219), (1.188, 0.235), (1.261, 0.218), (1.434, 0.202), (1.038, 0.203), (1.15, 0.236), (1.232, 0.219), (1.1210001, 0.251), (1.349, 0.203), (0.86000001, 0.234), (1.002, 0.269), (1.525, 0.202), (1.108, 0.272), (1.148, 0.307), (1.229, 0.242), (0.85000002, 0.268), (1.472, 0.236), (1.3839999, 0.22), (1.319, 0.27), (1.747, 0.188), (1.214, 0.237), (1.475, 0.237), (1.285, 0.253), (1.358, 0.22), (1.058, 0.253), (1.655, 0.188), (1.494, 0.237), (1.342, 0.254), (1.385, 0.236), (1.286, 0.253), (1.4450001, 0.219), (1.604, 0.205), (1.3839999, 0.222), (1.226, 0.22), (1.506, 0.254), (1.707, 0.204), (1.204, 0.271), (1.572, 0.22), (1.466, 0.221), (1.2130001, 0.255), (1.541, 0.221), (1.4809999, 0.187), (1.2029999, 0.271), (1.053, 0.253), (1.465, 0.236), (1.6109999, 0.204), (1.267, 0.252), (1.652, 0.221), (1.262, 0.237), (1.178, 0.22), (1.21, 0.254), (1.341, 0.188), (1.398, 0.237), (1.324, 0.22), (1.524, 0.22), (1.2819999, 0.203), (1.398, 0.237), (1.244, 0.252), (1.571, 0.221), (1.034, 0.27), (0.96499997, 0.27), (1.133, 0.271), (1.307, 0.237), (1.006, 0.27), (1.3609999, 0.239), (1.277, 0.253), (1.1440001, 0.237), (1.067, 0.271), (1.021, 0.269), (1.813, 0.204), (1.117, 0.237), (1.528, 0.204), (1.072, 0.236), (1.388, 0.27), (1.168, 0.237), (1.335, 0.221), (1.3839999, 0.27), (1.2029999, 0.204), (1.479, 0.187), (1.133, 0.237), (1.296, 0.237), (1.151, 0.27), (1.283, 0.221), (1.51, 0.237), (1.369, 0.221), (1.115, 0.27), (1.062, 0.253), (1.024, 0.253), (1.293, 0.254), (0.91500002, 0.27), (1.08, 0.253), (1.291, 0.238), (1.142, 0.236), (1.387, 0.271), (1.227, 0.253), (1.298, 0.252), (0.85600001, 0.253), (1.174, 0.255), (0.92299998, 0.237), (1.285, 0.221), (1.447, 0.221), (0.85500002, 0.27), (0.96100003, 0.254), (0.81, 0.253), (1.0470001, 0.253), (0.58499998, 0.272), (1.232, 0.221), (1.02, 0.253), (1.052, 0.268), (1.245, 0.187), (1.354, 0.27), (1.175, 0.22), (1.483, 0.221), (1.02, 0.27), (1.175, 0.203), (1.526, 0.204), (0.99199998, 0.235), (1.562, 0.222), (0.963, 0.27), (1.054, 0.253), (1.253, 0.271), (1.295, 0.22), (1.191, 0.269), (1.352, 0.237), (1.3150001, 0.237), (1.233, 0.237), (1.1720001, 0.254), (1.187, 0.27), (1.505, 0.238), (1.319, 0.204), (1.226, 0.255), (1.171, 0.238), (1.378, 0.204), (0.74400002, 0.22), (0.84299999, 0.255), (1.0470001, 0.27), (1.24, 0.238), (1.1059999, 0.253), (1.0650001, 0.237), (1.551, 0.221), (0.926, 0.27), (1.061, 0.237), (1.483, 0.22), (1.211, 0.236), (0.98100001, 0.253), (1.175, 0.22), (1.429, 0.221), (1.655, 0.204), (0.89999998, 0.236), (1.541, 0.221), (1.0930001, 0.22), (1.02, 0.27), (1.597, 0.204), (1.3329999, 0.255), (1.177, 0.272), (1.456, 0.205), (1.42, 0.239), (1.229, 0.255), (1.206, 0.238), (1.27, 0.238), (1.536, 0.189), (1.0930001, 0.24), (1.1440001, 0.255), (1.358, 0.272), (1.192, 0.223), (1.37, 0.222), (1.3329999, 0.273), (1.007, 0.272), (1.689, 0.188), (1.2690001, 0.223), (1.3, 0.206), (1.1670001, 0.272), (1.27, 0.24), (0.98699999, 0.255), (1.415, 0.272), (1.317, 0.205), (1.7589999, 0.19), (1.3150001, 0.239), (1.339, 0.239), (1.614, 0.239), (1.395, 0.24), (1.2180001, 0.223), (1.783, 0.206), (1.38, 0.238), (1.5880001, 0.206), (1.137, 0.254), (1.002, 0.255), (1.132, 0.257), (1.2589999, 0.238), (1.073, 0.222), (1.196, 0.271), (1.1720001, 0.255), (1.148, 0.238), (1.181, 0.255), (1.1799999, 0.255), (1.595, 0.24), (1.109, 0.272), (1.087, 0.239), (1.4220001, 0.238), (1.25, 0.206), (1.164, 0.273), (0.98400003, 0.272), (1.288, 0.222), (1.313, 0.272), (1.202, 0.255), (1.3279999, 0.221), (1.211, 0.239), (1.178, 0.222), (1.335, 0.271), (1.274, 0.272), (1.42, 0.238), (1.043, 0.256), (1.37, 0.272), (1.069, 0.255), (1.414, 0.238), (1.474, 0.238), (1.007, 0.255), (1.521, 0.271), (1.325, 0.238), (1.248, 0.239), (1.368, 0.272), (1.1059999, 0.255), (1.281, 0.222), (1.205, 0.238), (1.12, 0.239), (1.4579999, 0.256), (1.077, 0.272), (0.88200003, 0.239), (1.0190001, 0.255), (1.329, 0.238), (1.224, 0.237), (1.2920001, 0.272), (1.164, 0.273), (0.98000002, 0.256), (1.012, 0.256), (1.211, 0.24), (0.935, 0.273), (0.86900002, 0.24), (1.488, 0.206), (0.94199997, 0.255), (0.80699998, 0.222), (1.523, 0.206), (1.046, 0.254), (1.003, 0.256), (1.4220001, 0.256), (1.26, 0.239), (1.142, 0.255), (1.235, 0.206), (1.161, 0.238), (1.017, 0.256), (1.033, 0.255), (1.221, 0.272), (1.2869999, 0.222), (0.79799998, 0.257), (0.91399997, 0.255), (1.204, 0.257), (1.388, 0.239), (1.181, 0.206), (1.454, 0.255), (1.249, 0.258), (1.277, 0.223), (1.1900001, 0.223), (1.357, 0.222), (1.386, 0.24), (1.211, 0.239), (1.395, 0.208), (1.709, 0.256), (1.077, 0.256), (1.21, 0.255), (1.414, 0.223), (1.166, 0.255), (1.4349999, 0.239), (0.94800001, 0.254), (1.089, 0.254), (1.205, 0.239), (1.196, 0.208), (1.2690001, 0.271), (0.79900002, 0.205), (1.299, 0.222), (1.403, 0.205), (1.215, 0.255), (1.025, 0.223), (0.77100003, 0.256), (1.163, 0.271), (0.95099998, 0.222), (1.293, 0.222), (1.1720001, 0.223), (1.122, 0.223), (1.117, 0.272), (1.4299999, 0.19), (1.617, 0.225), (1.091, 0.273), (1.467, 0.257), (1.274, 0.273), (1.245, 0.241), (1.302, 0.257), (1.235, 0.239), (1.28, 0.24), (1.28, 0.257), (1.332, 0.273), (1.342, 0.241), (1.472, 0.207), (1.385, 0.207), (1.238, 0.225), (1.507, 0.207), (1.335, 0.241), (1.513, 0.242), (1.432, 0.223), (1.525, 0.223), (1.493, 0.224), (1.4069999, 0.239), (1.1289999, 0.256), (1.495, 0.24), (1.576, 0.226), (1.274, 0.191), (1.3660001, 0.224), (1.437, 0.207), (1.4069999, 0.241), (1.304, 0.24), (1.441, 0.24), (1.345, 0.224), (1.325, 0.257), (1.3839999, 0.225), (1.524, 0.207), (1.2970001, 0.257), (1.183, 0.275), (1.181, 0.24), (1.202, 0.257), (1.3049999, 0.24), (1.397, 0.225), (1.202, 0.24), (1.219, 0.239), (1.221, 0.24), (1.461, 0.223), (1.059, 0.24), (1.497, 0.224), (1.131, 0.24), (1.214, 0.19), (1.306, 0.207), (1.251, 0.208), (1.478, 0.224), (1.017, 0.271), (1.3710001, 0.257), (1.099, 0.241), (1.75, 0.224), (1.189, 0.256), (1.451, 0.224), (1.696, 0.207), (1.179, 0.257), (1.029, 0.274), (1.4, 0.207), (1.306, 0.224), (0.92299998, 0.256), (1.3940001, 0.24), (1.5, 0.207), (1.244, 0.24), (1.0190001, 0.272), (1.017, 0.241), (1.063, 0.241), (1.1670001, 0.24), (1.431, 0.223), (1.237, 0.241), (1.331, 0.24), (1.071, 0.273), (1.404, 0.174), (1.007, 0.256), (1.14, 0.24), (0.95700002, 0.241), (1.335, 0.241), (1.119, 0.239), (0.66600001, 0.224), (1.107, 0.223), (0.77700001, 0.241), (1.378, 0.24), (1.0650001, 0.241), (0.97000003, 0.241), (1.0829999, 0.224), (1.408, 0.209), (0.80400002, 0.273), (1.104, 0.256), (1.461, 0.241), (1.232, 0.224), (1.303, 0.257), (0.83499998, 0.258), (1.183, 0.208), (1.26, 0.223), (0.92000002, 0.257), (1.181, 0.239), (1.518, 0.239), (1.238, 0.24), (1.3609999, 0.223), (0.95599997, 0.257), (0.98299998, 0.241), (1.546, 0.223), (1.085, 0.241), (0.99900001, 0.239), (1.0930001, 0.256), (1.086, 0.223), (1.2460001, 0.274), (0.90100002, 0.273), (1.169, 0.207), (1.168, 0.273), (1.062, 0.259), (0.98400003, 0.273), (0.94400001, 0.273), (0.84200001, 0.273), (1.3660001, 0.24), (1.2819999, 0.207), (1.341, 0.272), (1.524, 0.224), (1.138, 0.224), (0.73699999, 0.274), (1.198, 0.207), (1.399, 0.207), (0.96499997, 0.258), (1.381, 0.225), (1.0930001, 0.208), (1.421, 0.224), (1.096, 0.273), (1.563, 0.192), (1.623, 0.274), (1.564, 0.242), (1.618, 0.242), (1.298, 0.274), (1.39, 0.225), (1.189, 0.274), (1.6339999, 0.241), (1.581, 0.242), (1.527, 0.244), (1.525, 0.224), (1.352, 0.275), (1.822, 0.225), (1.295, 0.258), (1.326, 0.274), (1.323, 0.225), (1.646, 0.225), (1.321, 0.274), (1.5, 0.226), (1.26, 0.243), (1.533, 0.242), (1.71, 0.209), (1.602, 0.192), (1.409, 0.261), (1.659, 0.243), (1.424, 0.242), (1.346, 0.275), (1.595, 0.225), (1.624, 0.21), (1.308, 0.258), (1.4630001, 0.226), (1.53, 0.259), (1.247, 0.241), (1.4400001, 0.226), (1.378, 0.209), (1.74, 0.209), (1.1390001, 0.276), (1.012, 0.226), (1.744, 0.226), (1.281, 0.242), (1.645, 0.192), (1.734, 0.225), (1.7180001, 0.211), (1.276, 0.241), (1.266, 0.258), (1.1799999, 0.275), (1.209, 0.274), (1.171, 0.244), (1.207, 0.241), (1.67, 0.208), (1.508, 0.242), (1.235, 0.241), (1.436, 0.258), (1.211, 0.276), (1.415, 0.224), (1.268, 0.276), (1.196, 0.275), (1.444, 0.226), (1.771, 0.243), (1.148, 0.275), (1.443, 0.209), (1.38, 0.275), (1.337, 0.241), (1.476, 0.216), (1.517, 0.215), (1.55, 0.215), (1.903, 0.183), (1.279, 0.265), (1.638, 0.232), (1.513, 0.249), (1.819, 0.215), (1.3430001, 0.216), (1.3789999, 0.249), (1.45, 0.215), (1.243, 0.267), (1.626, 0.216), (1.802, 0.2), (1.095, 0.249), (1.442, 0.231), (1.339, 0.2), (1.377, 0.249), (1.4349999, 0.25), (1.335, 0.267), (1.1390001, 0.249), (1.449, 0.232), (1.457, 0.249), (1.415, 0.249), (1.4349999, 0.214), (1.414, 0.216), (1.327, 0.232), (1.239, 0.265), (1.4119999, 0.216), (1.415, 0.249), (1.5599999, 0.249), (1.697, 0.201), (1.101, 0.218), (1.395, 0.2), (1.178, 0.267), (1.105, 0.266), (1.474, 0.184), (1.529, 0.217), (1.2690001, 0.25), (1.426, 0.233), (1.151, 0.267), (1.562, 0.235), (1.386, 0.217), (1.347, 0.234), (1.375, 0.234), (1.072, 0.25), (1.406, 0.217), (1.47, 0.268), (1.42, 0.218), (1.337, 0.184), (1.266, 0.218), (1.284, 0.266), (1.373, 0.217), (1.048, 0.266), (1.152, 0.25), (1.6619999, 0.2), (1.344, 0.234), (1.205, 0.184), (1.155, 0.251), (1.302, 0.218), (1.48, 0.217), (1.268, 0.268), (1.052, 0.267), (1.191, 0.234), (1.316, 0.217), (1.181, 0.249), (0.94099998, 0.234), (1.431, 0.217), (1.311, 0.2), (1.29, 0.235), (1.3430001, 0.25), (0.991, 0.25), (1.275, 0.251), (1.543, 0.201), (1.613, 0.217), (1.355, 0.202), (1.4299999, 0.218), (1.322, 0.217), (1.331, 0.252), (1.005, 0.251), (1.175, 0.265), (1.4170001, 0.234), (1.2970001, 0.217), (1.166, 0.217), (1.137, 0.249), (1.462, 0.201), (1.308, 0.251), (1.291, 0.234), (1.402, 0.216), (1.058, 0.267), (1.1849999, 0.25), (1.207, 0.25), (1.408, 0.25), (1.342, 0.233), (1.3940001, 0.201), (1.237, 0.249), (1.452, 0.2), (1.2539999, 0.25), (1.23, 0.217), (1.627, 0.201), (1.232, 0.233), (1.221, 0.266), (1.312, 0.253), (1.191, 0.268), (1.28, 0.218), (0.986, 0.217), (1.302, 0.2), (1.348, 0.201), (0.98400003, 0.25), (1.232, 0.233), (1.485, 0.234), (1.148, 0.266), (1.148, 0.217), (1.248, 0.2), (0.81300002, 0.235), (1.4299999, 0.201), (1.013, 0.233), (1.209, 0.251), (1.53, 0.184), (0.921, 0.251), (0.95099998, 0.235), (1.073, 0.267), (0.949, 0.217), (0.93599999, 0.267), (1.178, 0.251), (1.059, 0.233), (1.127, 0.218), (1.005, 0.25), (1.348, 0.217), (1.192, 0.267), (1.14, 0.203), (1.005, 0.249), (1.359, 0.184), (1.34, 0.232), (1.413, 0.2), (1.184, 0.266), (1.39, 0.184), (1.321, 0.25), (0.95700002, 0.267), (0.97399998, 0.251), (1.138, 0.234), (1.365, 0.251), (1.409, 0.251), (1.419, 0.2), (1.257, 0.216), (1.451, 0.2), (0.97399998, 0.217), (1.495, 0.217), (1.04, 0.267), (1.295, 0.201), (1.221, 0.265), (1.309, 0.184), (1.346, 0.233), (1.187, 0.251), (1.1799999, 0.218), (1.063, 0.218), (1.194, 0.25), (1.101, 0.234), (1.2029999, 0.217), (1.12, 0.25), (0.85299999, 0.267), (1.184, 0.25), (1.179, 0.25), (1.205, 0.216), (1.128, 0.201), (1.095, 0.25), (1.323, 0.217), (1.352, 0.217), (1.192, 0.184), (1.561, 0.217), (1.044, 0.251), (1.017, 0.266), (1.35, 0.233), (1.0599999, 0.253), (1.14, 0.271), (1.4910001, 0.235), (1.034, 0.251), (1.094, 0.27), (1.086, 0.267), (1.348, 0.201), (1.321, 0.252), (1.2460001, 0.218), (1.235, 0.253), (1.4069999, 0.235), (0.92299998, 0.251), (1.533, 0.186), (1.2029999, 0.252), (1.374, 0.187), (1.42, 0.236), (1.1670001, 0.236), (1.501, 0.217), (1.079, 0.218), (1.265, 0.268), (1.008, 0.252), (1.221, 0.219), (1.194, 0.252), (1.073, 0.27), (1.265, 0.251), (1.091, 0.269), (1.33, 0.236), (1.258, 0.218), (1.2869999, 0.203), (1.007, 0.237), (1.165, 0.251), (1.33, 0.236), (1.212, 0.253), (1.368, 0.203), (0.84299999, 0.236), (1.277, 0.219), (1.152, 0.268), (1.127, 0.235), (0.98400003, 0.252), (1.54, 0.201), (1.308, 0.185), (1.228, 0.253), (1.303, 0.269), (1.1799999, 0.235), (1.368, 0.202), (1.425, 0.235), (1.3099999, 0.236), (1.331, 0.235), (1.1339999, 0.203), (1.382, 0.219), (1.007, 0.251), (1.3789999, 0.203), (1.3430001, 0.219), (1.1109999, 0.235), (0.986, 0.252), (0.977, 0.251), (1.056, 0.268), (1.112, 0.27), (1.1059999, 0.235), (0.99199998, 0.268), (1.13, 0.218), (1.577, 0.253), (1.271, 0.219), (0.69999999, 0.268), (1.4859999, 0.252), (1.408, 0.218), (1.349, 0.251), (1.432, 0.185), (1.277, 0.203), (1.067, 0.252), (1.217, 0.268), (1.299, 0.203), (1.0549999, 0.266), (1.437, 0.202), (1.1160001, 0.235), (1.253, 0.235), (1.335, 0.202), (0.93300003, 0.236), (0.63599998, 0.269), (0.93400002, 0.269), (1.405, 0.235), (1.148, 0.219), (1.312, 0.219), (1.268, 0.252), (0.94999999, 0.253), (0.75800002, 0.27), (0.995, 0.22), (1.005, 0.236), (0.75300002, 0.269), (1.182, 0.251), (0.85799998, 0.234), (0.83499998, 0.269), (1.117, 0.204), (0.95099998, 0.218), (0.66000003, 0.236), (1.513, 0.202), (1.283, 0.235), (0.98699999, 0.235), (1.0829999, 0.267), (1.329, 0.236), (1.057, 0.219), (0.93300003, 0.268), (0.93900001, 0.268), (1.028, 0.252), (1.23, 0.268), (1.002, 0.219), (1.1440001, 0.236), (0.70700002, 0.268), (1.059, 0.269), (0.94999999, 0.234), (1.101, 0.27), (1.505, 0.235), (1.451, 0.236), (0.98100001, 0.268), (1.108, 0.251), (1.034, 0.235), (1.4299999, 0.235), (0.986, 0.236), (1.035, 0.234), (1.602, 0.236), (1.127, 0.234), (1.426, 0.186), (1.2869999, 0.236), (0.949, 0.236), (0.83899999, 0.269), (0.94300002, 0.218), (1.165, 0.219), (1.1109999, 0.235), (1.178, 0.217), (1.321, 0.203), (0.96600002, 0.202), (1.039, 0.235), (1.128, 0.218), (1.062, 0.252), (1.2640001, 0.203), (0.81099999, 0.236), (0.95200002, 0.268), (1.442, 0.202), (1.0, 0.235), (1.076, 0.282), (1.119, 0.236), (0.78899997, 0.27), (1.438, 0.236), (1.311, 0.221), (1.248, 0.271), (1.596, 0.187), (1.133, 0.238), (1.349, 0.237), (1.228, 0.254), (1.242, 0.22), (1.0089999, 0.253), (1.492, 0.188), (1.3839999, 0.237), (1.247, 0.254), (1.253, 0.237), (1.188, 0.254), (1.393, 0.22), (1.474, 0.203), (1.253, 0.22), (1.142, 0.22), (1.4349999, 0.253), (1.5549999, 0.204), (1.133, 0.271), (1.479, 0.221), (1.372, 0.221), (1.146, 0.253), (1.483, 0.221), (1.3660001, 0.187), (1.1619999, 0.27), (1.003, 0.254), (1.375, 0.237), (1.493, 0.204), (1.125, 0.253), (1.571, 0.221), (1.206, 0.237), (1.092, 0.22), (1.173, 0.253), (1.229, 0.188), (1.314, 0.237), (1.2819999, 0.22), (1.462, 0.22), (1.245, 0.203), (1.323, 0.238), (1.216, 0.253), (1.499, 0.22), (1.002, 0.271), (0.92699999, 0.27), (1.04, 0.27), (1.237, 0.237), (0.93599999, 0.27), (1.276, 0.237), (1.199, 0.254), (1.0829999, 0.236), (0.97299999, 0.27), (0.96200001, 0.27), (1.669, 0.203), (1.057, 0.238), (1.3559999, 0.205), (1.036, 0.239), (1.316, 0.271), (1.1109999, 0.236), (1.239, 0.22), (1.2869999, 0.269), (1.159, 0.204), (1.399, 0.188), (1.064, 0.237), (1.216, 0.237), (1.096, 0.271), (1.228, 0.221), (1.374, 0.237), (1.263, 0.221), (1.027, 0.27), (1.0420001, 0.254), (0.954, 0.253), (1.235, 0.253), (0.89099997, 0.271), (1.0039999, 0.252), (1.243, 0.237), (1.075, 0.236), (1.275, 0.271), (1.146, 0.254), (1.262, 0.254), (0.76499999, 0.254), (1.1160001, 0.254), (0.88, 0.237), (1.211, 0.221), (1.355, 0.22), (0.83200002, 0.271), (0.86400002, 0.254), (0.73699999, 0.253), (1.002, 0.255), (0.52899998, 0.271), (1.148, 0.22), (0.96200001, 0.253), (0.99599999, 0.27), (1.149, 0.187), (1.3, 0.27), (1.08, 0.22), (1.35, 0.22), (0.96200001, 0.27), (1.128, 0.205), (1.467, 0.203), (0.90499997, 0.237), (1.483, 0.22), (0.88800001, 0.271), (1.003, 0.254), (1.226, 0.27), (1.1849999, 0.22), (1.153, 0.27), (1.24, 0.236), (1.263, 0.237), (1.2, 0.236), (1.081, 0.253), (1.114, 0.271), (1.395, 0.238), (1.309, 0.204), (1.148, 0.253), (1.096, 0.237), (1.321, 0.205), (0.70700002, 0.22), (0.77700001, 0.254), (0.963, 0.271), (1.179, 0.237), (1.052, 0.253), (0.99400002, 0.237), (1.3609999, 0.22), (0.833, 0.27), (0.98100001, 0.236), (1.3839999, 0.221), (1.166, 0.238), (0.90499997, 0.254), (1.082, 0.221), (1.341, 0.22), (1.541, 0.204), (0.79299998, 0.237), (1.4220001, 0.22), (0.935, 0.22), (0.96600002, 0.271), (1.4579999, 0.204), (1.227, 0.256), (1.09, 0.27), (1.3380001, 0.206), (1.3710001, 0.238), (1.135, 0.254), (1.132, 0.237), (1.138, 0.239), (1.34, 0.189), (1.021, 0.239), (1.052, 0.257), (1.268, 0.272), (1.117, 0.222), (1.275, 0.223), (1.272, 0.271), (0.93199998, 0.272), (1.523, 0.189), (1.2029999, 0.222), (1.135, 0.206), (1.0700001, 0.272), (1.1849999, 0.24), (0.93300003, 0.255), (1.352, 0.272), (1.1799999, 0.205), (1.636, 0.191), (1.248, 0.238), (1.281, 0.239), (1.562, 0.24), (1.3150001, 0.238), (1.099, 0.222), (1.661, 0.206), (1.341, 0.239), (1.4220001, 0.205), (1.074, 0.256), (0.94199997, 0.254), (1.05, 0.255), (1.1900001, 0.24), (0.93099999, 0.222), (1.1, 0.271), (1.1339999, 0.254), (1.1160001, 0.239), (1.082, 0.254), (1.079, 0.255), (1.482, 0.239), (1.073, 0.272), (1.0039999, 0.239), (1.33, 0.238), (1.138, 0.205), (1.054, 0.272), (0.94700003, 0.271), (1.194, 0.221), (1.295, 0.272), (1.112, 0.256), (1.181, 0.222), (1.152, 0.238), (1.079, 0.222), (1.245, 0.272), (1.178, 0.274), (1.3, 0.238), (0.95899999, 0.256), (1.279, 0.271), (1.0, 0.255), (1.313, 0.24), (1.432, 0.24), (0.94, 0.254), (1.4220001, 0.271), (1.225, 0.239), (1.142, 0.239), (1.3200001, 0.272), (1.022, 0.255), (1.173, 0.221), (1.159, 0.239), (1.034, 0.239), (1.425, 0.256), (0.99900001, 0.272), (0.81, 0.239), (0.95099998, 0.254), (1.222, 0.24), (1.127, 0.239), (1.22, 0.272), (1.1, 0.273), (0.912, 0.255), (0.90899998, 0.255), (1.124, 0.239), (0.86500001, 0.272), (0.81999999, 0.239), (1.408, 0.205), (0.87900001, 0.255), (0.71899998, 0.222), (1.367, 0.206), (0.98000002, 0.256), (0.90100002, 0.258), (1.33, 0.255), (1.112, 0.239), (1.068, 0.255), (1.124, 0.206), (1.095, 0.239), (0.99000001, 0.255), (0.96399999, 0.255), (1.166, 0.271), (1.155, 0.223), (0.755, 0.254), (0.83200002, 0.256), (1.159, 0.255), (1.26, 0.238), (1.011, 0.205), (1.352, 0.255), (1.142, 0.255), (1.145, 0.223), (1.12, 0.222), (1.25, 0.223), (1.3, 0.239), (1.1289999, 0.24), (1.2309999, 0.205), (1.602, 0.255), (0.98000002, 0.255), (1.1339999, 0.255), (1.3940001, 0.223), (1.063, 0.255), (1.3789999, 0.239), (0.90200001, 0.255), (1.0420001, 0.254), (1.127, 0.238), (1.114, 0.207), (1.175, 0.271), (0.72500002, 0.206), (1.189, 0.222), (1.2029999, 0.206), (1.104, 0.255), (0.95999998, 0.222), (0.69800001, 0.255), (1.136, 0.271), (0.86699998, 0.223), (1.156, 0.223), (1.0599999, 0.222), (1.008, 0.222), (1.051, 0.271), (1.329, 0.19), (1.4220001, 0.224), (1.0650001, 0.273), (1.425, 0.257), (1.228, 0.274), (1.149, 0.241), (1.192, 0.259), (1.17, 0.24), (1.191, 0.241), (1.206, 0.257), (1.273, 0.274), (1.211, 0.241), (1.374, 0.207), (1.327, 0.207), (1.133, 0.224), (1.383, 0.207), (1.25, 0.24), (1.3940001, 0.241), (1.3380001, 0.224), (1.375, 0.224), (1.432, 0.224), (1.346, 0.24), (1.062, 0.258), (1.3609999, 0.243), (1.48, 0.224), (1.125, 0.191), (1.286, 0.225), (1.3609999, 0.208), (1.3609999, 0.241), (1.229, 0.24), (1.375, 0.241), (1.202, 0.223), (1.238, 0.256), (1.277, 0.225), (1.373, 0.206), (1.221, 0.256), (1.112, 0.275), (1.125, 0.241), (1.089, 0.258), (1.2690001, 0.24), (1.37, 0.223), (1.0829999, 0.242), (1.118, 0.24), (1.149, 0.241), (1.357, 0.223), (0.95899999, 0.239), (1.4220001, 0.224), (1.012, 0.239), (1.124, 0.191), (1.232, 0.207), (1.159, 0.208), (1.428, 0.223), (0.949, 0.273), (1.261, 0.257), (1.028, 0.24), (1.573, 0.225), (1.138, 0.257), (1.363, 0.223), (1.636, 0.206), (1.09, 0.255), (0.99699998, 0.274), (1.232, 0.208), (1.2079999, 0.223), (0.875, 0.257), (1.303, 0.239), (1.404, 0.207), (1.158, 0.241), (0.96499997, 0.274), (0.97100002, 0.241), (0.98900002, 0.24), (1.091, 0.24), (1.395, 0.224), (1.1160001, 0.241), (1.211, 0.24), (1.001, 0.272), (1.301, 0.174), (0.93199998, 0.256), (1.05, 0.239), (0.86400002, 0.24), (1.242, 0.241), (1.061, 0.241), (0.58099997, 0.225), (0.995, 0.224), (0.68800002, 0.241), (1.322, 0.24), (1.0089999, 0.24), (0.91100001, 0.24), (1.026, 0.223), (1.2920001, 0.207), (0.79900002, 0.274), (1.031, 0.256), (1.337, 0.241), (1.1390001, 0.224), (1.2460001, 0.256), (0.80699998, 0.257), (1.073, 0.207), (1.1109999, 0.223), (0.84799999, 0.256), (1.1289999, 0.241), (1.4400001, 0.24), (1.1619999, 0.24), (1.239, 0.224), (0.91799998, 0.258), (0.91299999, 0.24), (1.476, 0.224), (0.99400002, 0.24), (0.95899999, 0.241), (1.016, 0.257), (1.02, 0.225), (1.193, 0.273), (0.84299999, 0.274), (1.11, 0.207), (1.148, 0.272), (1.02, 0.257), (0.93800002, 0.274), (0.917, 0.273), (0.77399999, 0.273), (1.274, 0.239), (1.161, 0.206), (1.266, 0.274), (1.375, 0.224), (1.0650001, 0.225), (0.71799999, 0.272), (1.123, 0.206), (1.3, 0.206), (0.91900003, 0.258), (1.325, 0.223), (0.97500002, 0.207), (1.268, 0.224), (1.0369999, 0.274), (1.42, 0.193), (1.567, 0.274), (1.45, 0.242), (1.4859999, 0.242), (1.244, 0.275), (1.304, 0.226), (1.156, 0.275), (1.538, 0.243), (1.462, 0.242), (1.479, 0.242), (1.398, 0.225), (1.268, 0.275), (1.656, 0.225), (1.256, 0.258), (1.249, 0.275), (1.263, 0.225), (1.554, 0.227), (1.242, 0.274), (1.4299999, 0.225), (1.194, 0.241), (1.4859999, 0.244), (1.5369999, 0.21), (1.5039999, 0.192), (1.3609999, 0.257), (1.507, 0.242), (1.312, 0.242), (1.274, 0.275), (1.479, 0.226), (1.5089999, 0.208), (1.233, 0.257), (1.4, 0.226), (1.443, 0.258), (1.127, 0.242), (1.347, 0.225), (1.345, 0.208), (1.6059999, 0.208), (1.079, 0.275), (0.95300001, 0.225), (1.6289999, 0.225), (1.181, 0.242), (1.539, 0.192), (1.635, 0.226), (1.589, 0.21), (1.229, 0.242), (1.193, 0.257), (1.103, 0.275), (1.165, 0.275), (1.135, 0.243), (1.146, 0.241), (1.613, 0.21), (1.436, 0.242), (1.15, 0.241), (1.358, 0.259), (1.133, 0.277), (1.322, 0.226), (1.1849999, 0.274), (1.095, 0.275), (1.415, 0.226), (1.671, 0.243), (1.08, 0.275), (1.378, 0.21), (1.309, 0.275), (1.238, 0.241), (1.411, 0.215), (1.372, 0.216), (1.464, 0.216), (1.819, 0.183), (1.197, 0.267), (1.524, 0.233), (1.424, 0.248), (1.6950001, 0.216), (1.274, 0.216), (1.35, 0.25), (1.345, 0.215), (1.1670001, 0.265), (1.512, 0.216), (1.72, 0.199), (1.035, 0.248), (1.392, 0.232), (1.24, 0.198), (1.349, 0.249), (1.369, 0.249), (1.298, 0.265), (1.076, 0.25), (1.393, 0.233), (1.3789999, 0.249), (1.353, 0.249), (1.354, 0.214), (1.314, 0.214), (1.229, 0.232), (1.156, 0.266), (1.329, 0.215), (1.398, 0.248), (1.472, 0.25), (1.575, 0.201), (1.027, 0.217), (1.308, 0.201), (1.12, 0.267), (1.008, 0.268), (1.365, 0.185), (1.434, 0.217), (1.173, 0.25), (1.345, 0.233), (1.0650001, 0.266), (1.464, 0.235), (1.28, 0.217), (1.291, 0.234), (1.3099999, 0.235), (0.97799999, 0.25), (1.322, 0.217), (1.398, 0.266), (1.319, 0.217), (1.174, 0.184), (1.214, 0.218), (1.25, 0.268), (1.265, 0.217), (0.99199998, 0.266), (1.091, 0.251), (1.612, 0.201), (1.228, 0.232), (1.11, 0.184), (1.13, 0.251), (1.198, 0.217), (1.3839999, 0.218), (1.201, 0.266), (0.97399998, 0.267), (1.145, 0.234), (1.27, 0.217), (1.142, 0.25), (0.926, 0.234), (1.329, 0.218), (1.184, 0.201), (1.232, 0.234), (1.2869999, 0.249), (0.89300001, 0.25), (1.193, 0.25), (1.408, 0.201), (1.536, 0.216), (1.179, 0.201), (1.3150001, 0.216), (1.26, 0.218), (1.184, 0.248), (1.001, 0.249), (1.153, 0.267), (1.312, 0.235), (1.217, 0.217), (1.124, 0.217), (1.1, 0.251), (1.308, 0.201), (1.199, 0.249), (1.244, 0.233), (1.3200001, 0.217), (0.96600002, 0.267), (1.072, 0.252), (1.1440001, 0.252), (1.365, 0.25), (1.204, 0.234), (1.314, 0.2), (1.1569999, 0.25), (1.3609999, 0.2), (1.192, 0.249), (1.128, 0.217), (1.5470001, 0.201), (1.1799999, 0.234), (1.16, 0.267), (1.24, 0.251), (1.109, 0.267), (1.205, 0.218), (0.94099998, 0.217), (1.196, 0.201), (1.214, 0.201), (0.90100002, 0.25), (1.1339999, 0.233), (1.391, 0.233), (1.1390001, 0.266), (1.0880001, 0.216), (1.176, 0.2), (0.736, 0.233), (1.387, 0.201), (1.005, 0.233), (1.163, 0.249), (1.401, 0.184), (0.87199998, 0.25), (0.86900002, 0.235), (0.98900002, 0.267), (0.86900002, 0.217), (0.88599998, 0.267), (1.1440001, 0.249), (0.99199998, 0.234), (1.0599999, 0.216), (0.95999998, 0.25), (1.276, 0.217), (1.142, 0.266), (1.043, 0.201), (0.94099998, 0.251), (1.3, 0.184), (1.223, 0.234), (1.3150001, 0.2), (1.118, 0.269), (1.256, 0.183), (1.234, 0.25), (0.90499997, 0.266), (0.90600002, 0.25), (1.045, 0.234), (1.23, 0.252), (1.288, 0.249), (1.365, 0.202), (1.115, 0.217), (1.3430001, 0.201), (0.866, 0.218), (1.441, 0.216), (1.006, 0.268), (1.131, 0.2), (1.13, 0.266), (1.222, 0.184), (1.258, 0.233), (1.087, 0.25), (1.14, 0.216), (1.033, 0.217), (1.097, 0.25), (1.0549999, 0.234), (1.105, 0.217), (1.077, 0.251), (0.80400002, 0.266), (1.128, 0.25), (1.102, 0.251), (1.1109999, 0.218), (1.051, 0.2), (1.012, 0.251), (1.253, 0.218), (1.235, 0.217), (1.103, 0.185), (1.475, 0.217), (1.031, 0.249), (0.98100001, 0.267), (1.21, 0.234), (0.95300001, 0.252), (1.0880001, 0.268), (1.401, 0.235), (1.0089999, 0.25), (1.05, 0.268), (1.048, 0.268), (1.2460001, 0.204), (1.245, 0.252), (1.202, 0.219), (1.161, 0.253), (1.2970001, 0.236), (0.875, 0.253), (1.469, 0.185), (1.168, 0.252), (1.219, 0.185), (1.332, 0.234), (1.058, 0.236), (1.369, 0.219), (0.98000002, 0.219), (1.1670001, 0.269), (0.95099998, 0.252), (1.1569999, 0.22), (1.1720001, 0.252), (1.027, 0.269), (1.205, 0.253), (1.012, 0.268), (1.237, 0.234), (1.194, 0.219), (1.221, 0.202), (0.95300001, 0.237), (1.0470001, 0.251), (1.288, 0.235), (1.108, 0.252), (1.271, 0.202), (0.80400002, 0.235), (1.173, 0.218), (1.071, 0.268), (1.027, 0.235), (0.93400002, 0.251), (1.492, 0.203), (1.188, 0.186), (1.154, 0.253), (1.214, 0.268), (1.159, 0.234), (1.285, 0.202), (1.317, 0.236), (1.249, 0.236), (1.235, 0.236), (1.044, 0.203), (1.248, 0.219), (0.91600001, 0.253), (1.276, 0.203), (1.253, 0.22), (1.034, 0.237), (0.89700001, 0.254), (0.93599999, 0.253), (1.005, 0.269), (1.0829999, 0.27), (1.0319999, 0.237), (0.90899998, 0.269), (1.035, 0.22), (1.467, 0.252), (1.187, 0.219), (0.63700002, 0.27), (1.4220001, 0.252), (1.354, 0.22), (1.3, 0.252), (1.353, 0.185), (1.12, 0.202), (0.94599998, 0.253), (1.14, 0.268), (1.214, 0.202), (1.027, 0.27), (1.3789999, 0.202), (1.064, 0.235), (1.136, 0.236), (1.267, 0.202), (0.80900002, 0.235), (0.60100001, 0.269), (0.875, 0.269), (1.323, 0.235), (1.062, 0.219), (1.186, 0.218), (1.26, 0.252), (0.86400002, 0.252), (0.74900001, 0.267), (0.94599998, 0.218), (0.958, 0.236), (0.72799999, 0.269), (1.1059999, 0.253), (0.78500003, 0.235), (0.75700003, 0.268), (0.991, 0.203), (0.90700001, 0.219), (0.58700001, 0.235), (1.368, 0.203), (1.165, 0.235), (0.90499997, 0.235), (0.98900002, 0.269), (1.227, 0.235), (0.96600002, 0.219), (0.90799999, 0.268), (0.88999999, 0.269), (0.98799998, 0.251), (1.198, 0.269), (0.99900001, 0.218), (1.04, 0.235), (0.67799997, 0.268), (1.002, 0.268), (0.90399998, 0.234), (1.011, 0.267), (1.433, 0.236), (1.314, 0.236), (0.89099997, 0.268), (1.077, 0.254), (0.949, 0.236), (1.427, 0.235), (0.91600001, 0.236), (0.97399998, 0.236), (1.4910001, 0.236), (1.079, 0.236), (1.321, 0.185), (1.276, 0.235), (0.90700001, 0.235), (0.80900002, 0.268), (0.82800001, 0.219), (1.115, 0.218), (1.031, 0.235), (1.125, 0.219), (1.2539999, 0.202), (0.89999998, 0.203), (0.94999999, 0.236), (1.068, 0.22), (1.027, 0.252), (1.178, 0.202), (0.72799999, 0.234), (0.90700001, 0.269), (1.304, 0.202), (0.94599998, 0.214), (1.0420001, 0.27), (1.073, 0.235), (0.71899998, 0.268), (1.37, 0.235), (1.221, 0.221), (1.2, 0.269), (1.457, 0.187), (1.034, 0.236), (1.235, 0.24), (1.118, 0.254), (1.165, 0.221), (0.94700003, 0.254), (1.401, 0.187), (1.2869999, 0.236), (1.1569999, 0.252), (1.183, 0.238), (1.141, 0.254), (1.223, 0.221), (1.386, 0.203), (1.099, 0.22), (1.061, 0.22), (1.374, 0.252), (1.457, 0.204), (1.0599999, 0.27), (1.459, 0.22), (1.336, 0.22), (1.0650001, 0.253), (1.345, 0.222), (1.294, 0.188), (1.125, 0.269), (0.93300003, 0.254), (1.29, 0.237), (1.424, 0.204), (1.038, 0.254), (1.477, 0.22), (1.1289999, 0.235), (1.05, 0.22), (1.086, 0.253), (1.041, 0.187), (1.197, 0.237), (1.181, 0.22), (1.3279999, 0.221), (1.128, 0.206), (1.205, 0.237), (1.148, 0.253), (1.404, 0.22), (0.92900002, 0.27), (0.85100001, 0.271), (0.96899998, 0.27), (1.126, 0.237), (0.83899999, 0.27), (1.227, 0.235), (1.138, 0.254), (0.958, 0.238), (0.92299998, 0.27), (0.91299999, 0.268), (1.556, 0.205), (0.99299997, 0.238), (1.3, 0.204), (0.89899999, 0.237), (1.234, 0.269), (1.024, 0.237), (1.173, 0.221), (1.228, 0.271), (1.0549999, 0.203), (1.239, 0.187), (0.99599999, 0.237), (1.132, 0.237), (1.049, 0.27), (1.122, 0.222), (1.273, 0.238), (1.216, 0.22), (0.99199998, 0.269), (0.958, 0.253), (0.91500002, 0.254), (1.154, 0.254), (0.79299998, 0.269), (0.917, 0.252), (1.147, 0.236), (1.035, 0.238), (1.184, 0.27), (1.058, 0.254), (1.1950001, 0.254), (0.759, 0.253), (1.0650001, 0.252), (0.81400001, 0.236), (1.132, 0.22), (1.359, 0.221), (0.72500002, 0.27), (0.84100002, 0.253), (0.70200002, 0.254), (0.96600002, 0.253), (0.45500001, 0.27), (1.076, 0.222), (0.90799999, 0.253), (0.96399999, 0.269), (1.066, 0.186), (1.2029999, 0.27), (0.986, 0.22), (1.298, 0.221), (0.89600003, 0.27), (1.001, 0.204), (1.3559999, 0.204), (0.87199998, 0.236), (1.402, 0.221), (0.80900002, 0.27), (0.94199997, 0.253), (1.147, 0.271), (1.077, 0.22), (1.041, 0.27), (1.171, 0.238), (1.2029999, 0.236), (1.1440001, 0.237), (1.003, 0.255), (1.002, 0.27), (1.2819999, 0.237), (1.194, 0.204), (1.108, 0.252), (1.0039999, 0.237), (1.223, 0.205), (0.66799998, 0.22), (0.755, 0.253), (0.94199997, 0.27), (1.091, 0.237), (1.011, 0.253), (0.93900001, 0.237), (1.3099999, 0.221), (0.77600002, 0.269), (0.97000003, 0.237), (1.3049999, 0.219), (1.081, 0.239), (0.852, 0.252), (0.98000002, 0.221), (1.227, 0.22), (1.396, 0.204), (0.745, 0.238), (1.373, 0.22), (0.93000001, 0.221), (0.92699999, 0.27), (1.413, 0.203), (1.15, 0.254), (1.074, 0.271), (1.2359999, 0.205), (1.281, 0.24), (1.091, 0.255), (1.045, 0.24), (1.126, 0.239), (1.309, 0.188), (0.90899998, 0.239), (1.0190001, 0.255), (1.212, 0.272), (1.0549999, 0.222), (1.193, 0.223), (1.227, 0.271), (0.89899999, 0.272), (1.39, 0.189), (1.1390001, 0.223), (1.098, 0.206), (1.031, 0.271), (1.077, 0.239), (0.84500003, 0.256), (1.267, 0.273), (1.149, 0.205), (1.525, 0.189), (1.191, 0.239), (1.216, 0.239), (1.432, 0.239), (1.2460001, 0.239), (1.006, 0.223), (1.55, 0.205), (1.243, 0.24), (1.3279999, 0.205), (1.059, 0.255), (0.88700002, 0.255), (0.96700001, 0.257), (1.098, 0.238), (0.90600002, 0.222), (1.048, 0.272), (1.052, 0.255), (1.008, 0.238), (1.001, 0.254), (1.001, 0.255), (1.392, 0.238), (0.99400002, 0.272), (0.94300002, 0.239), (1.234, 0.238), (1.064, 0.206), (0.98400003, 0.272), (0.84100002, 0.271), (1.08, 0.223), (1.239, 0.272), (1.0319999, 0.256), (1.1390001, 0.222), (1.069, 0.239), (1.0369999, 0.221), (1.215, 0.271), (1.136, 0.272), (1.188, 0.238), (0.93800002, 0.253), (1.239, 0.272), (0.90899998, 0.255), (1.2, 0.238), (1.317, 0.238), (0.85399997, 0.255), (1.375, 0.272), (1.187, 0.239), (1.084, 0.239), (1.262, 0.271), (0.96700001, 0.256), (1.104, 0.222), (1.1059999, 0.239), (0.977, 0.239), (1.337, 0.256), (0.98100001, 0.271), (0.75099999, 0.239), (0.926, 0.255), (1.1950001, 0.239), (1.072, 0.238), (1.194, 0.272), (1.02, 0.271), (0.84799999, 0.255), (0.87199998, 0.255), (1.046, 0.238), (0.84600002, 0.271), (0.78600001, 0.237), (1.223, 0.206), (0.81599998, 0.255), (0.67000002, 0.222), (1.243, 0.207), (0.949, 0.256), (0.838, 0.257), (1.285, 0.255), (1.079, 0.239), (0.98900002, 0.256), (1.059, 0.206), (0.97899997, 0.239), (0.935, 0.256), (0.90700001, 0.257), (1.1109999, 0.273), (1.1289999, 0.223), (0.71499997, 0.257), (0.82599998, 0.255), (1.097, 0.258), (1.206, 0.24), (0.972, 0.206), (1.299, 0.256), (1.133, 0.255), (1.0779999, 0.222), (1.057, 0.222), (1.145, 0.221), (1.2460001, 0.239), (1.057, 0.24), (1.136, 0.207), (1.564, 0.253), (0.95999998, 0.255), (1.051, 0.256), (1.316, 0.222), (1.02, 0.256), (1.273, 0.237), (0.86199999, 0.254), (0.97399998, 0.253), (1.045, 0.24), (1.034, 0.206), (1.159, 0.272), (0.62400001, 0.206), (1.057, 0.222), (1.206, 0.205), (1.0779999, 0.254), (0.89899999, 0.222), (0.64899999, 0.256), (1.075, 0.272), (0.80199999, 0.222), (1.1059999, 0.222), (0.96600002, 0.222), (0.88099998, 0.223), (0.99900001, 0.27), (1.2130001, 0.191), (1.311, 0.223), (0.98900002, 0.274), (1.3430001, 0.256), (1.156, 0.274), (1.085, 0.241), (1.108, 0.257), (1.067, 0.24), (1.1289999, 0.24), (1.108, 0.257), (1.2029999, 0.273), (1.184, 0.24), (1.278, 0.207), (1.233, 0.207), (1.092, 0.224), (1.3099999, 0.207), (1.154, 0.241), (1.344, 0.239), (1.278, 0.224), (1.334, 0.224), (1.349, 0.225), (1.2920001, 0.241), (1.018, 0.257), (1.294, 0.24), (1.342, 0.223), (1.026, 0.191), (1.211, 0.223), (1.2309999, 0.207), (1.271, 0.24), (1.174, 0.242), (1.2869999, 0.24), (1.156, 0.223), (1.156, 0.256), (1.199, 0.223), (1.2970001, 0.207), (1.152, 0.256), (1.086, 0.273), (1.063, 0.241), (1.005, 0.256), (1.223, 0.24), (1.261, 0.224), (0.991, 0.24), (1.0880001, 0.241), (1.061, 0.241), (1.229, 0.223), (0.87400001, 0.24), (1.363, 0.223), (0.93300003, 0.24), (1.0039999, 0.191), (1.1390001, 0.207), (1.108, 0.207), (1.325, 0.224), (0.90499997, 0.274), (1.1950001, 0.257), (0.96799999, 0.24), (1.54, 0.224), (1.0599999, 0.257), (1.278, 0.223), (1.5089999, 0.207), (1.062, 0.257), (0.93699998, 0.274), (1.202, 0.207), (1.143, 0.225), (0.85000002, 0.256), (1.272, 0.24), (1.294, 0.207), (1.117, 0.242), (0.88800001, 0.271), (0.95499998, 0.241), (0.93000001, 0.241), (1.081, 0.241), (1.26, 0.223), (1.0650001, 0.241), (1.174, 0.24), (0.96700001, 0.275), (1.2180001, 0.174), (0.84799999, 0.257), (0.98699999, 0.24), (0.81599998, 0.241), (1.16, 0.239), (0.963, 0.238), (0.54500002, 0.224), (0.90200001, 0.225), (0.66399997, 0.24), (1.243, 0.242), (0.89499998, 0.241), (0.83499998, 0.241), (0.94400001, 0.224), (1.1799999, 0.207), (0.755, 0.274), (0.94099998, 0.256), (1.291, 0.24), (1.054, 0.225), (1.158, 0.257), (0.74299997, 0.258), (0.986, 0.207), (1.052, 0.223), (0.78200001, 0.255), (1.1109999, 0.239), (1.359, 0.241), (1.113, 0.241), (1.163, 0.224), (0.84100002, 0.257), (0.83999997, 0.241), (1.376, 0.225), (0.92500001, 0.238), (0.88700002, 0.24), (0.97899997, 0.256), (1.013, 0.224), (1.159, 0.273), (0.78399998, 0.274), (1.041, 0.208), (1.0650001, 0.274), (0.94, 0.258), (0.884, 0.272), (0.86199999, 0.273), (0.755, 0.274), (1.214, 0.241), (1.118, 0.208), (1.207, 0.274), (1.311, 0.224), (1.044, 0.224), (0.65899998, 0.274), (1.0599999, 0.207), (1.2309999, 0.208), (0.87099999, 0.257), (1.234, 0.224), (0.93199998, 0.208), (1.2309999, 0.224), (0.97600001, 0.273), (1.252, 0.192), (1.49, 0.274), (1.357, 0.242), (1.438, 0.242), (1.21, 0.276), (1.1569999, 0.225), (1.098, 0.275), (1.4809999, 0.241), (1.403, 0.242), (1.391, 0.243), (1.319, 0.225), (1.127, 0.275), (1.5319999, 0.225), (1.21, 0.258), (1.1849999, 0.275), (1.161, 0.225), (1.493, 0.226), (1.1950001, 0.275), (1.347, 0.225), (1.125, 0.243), (1.396, 0.242), (1.506, 0.207), (1.386, 0.192), (1.303, 0.259), (1.464, 0.242), (1.324, 0.242), (1.22, 0.274), (1.385, 0.225), (1.368, 0.208), (1.13, 0.258), (1.312, 0.226), (1.3839999, 0.257), (1.124, 0.242), (1.217, 0.226), (1.223, 0.208), (1.541, 0.209), (1.041, 0.274), (0.87099999, 0.226), (1.559, 0.226), (1.1289999, 0.243), (1.3559999, 0.193), (1.576, 0.226), (1.476, 0.209), (1.1, 0.243), (1.1210001, 0.259), (1.031, 0.274), (1.0880001, 0.273), (1.02, 0.243), (1.095, 0.242), (1.49, 0.209), (1.374, 0.241), (1.1, 0.242), (1.3150001, 0.258), (1.086, 0.275), (1.268, 0.226), (1.14, 0.275), (1.0650001, 0.275), (1.2970001, 0.225)]\n"
     ]
    }
   ],
   "source": [
    "LSTM_UNI_ATTN_LOSSES_PATH   = './checkpointed_data/losses/LSTM_UNI_ATTN_LOSS_ARR.p'\n",
    "GRU_UNI_ATTN_LOSSES_PATH   = './checkpointed_data/losses/GRU_UNI_ATTN_LOSS_ARR.p'\n",
    "LSTM_BI_ATTN_LOSSES_PATH   = './checkpointed_data/losses/LSTM_BI_ATTN_LOSS_ARR.p'\n",
    "GRU_BI_ATTN_LOSSES_PATH   = './checkpointed_data/losses/GRU_BI_ATTN_LOSS_ARR.p'\n",
    "LSTM_UNI_LOSSES_PATH   = './checkpointed_data/losses/LSTM_UNI_LOSS_ARR.p'\n",
    "GRU_UNI_LOSSES_PATH   = './checkpointed_data/losses/GRU_UNI_LOSS_ARR.p'\n",
    "LSTM_BI_LOSSES_PATH   = './checkpointed_data/losses/LSTM_BI_LOSS_ARR.p'\n",
    "GRU_BI_LOSSES_PATH   = './checkpointed_data/losses/GRU_BI_LOSS_ARR.p'\n",
    "\n",
    "LSTM_UNI_ATTN_LOSSES = pickle.load(open(LSTM_UNI_ATTN_LOSSES_PATH, mode='rb'))\n",
    "GRU_UNI_ATTN_LOSSES = pickle.load(open(GRU_UNI_ATTN_LOSSES_PATH, mode='rb'))\n",
    "LSTM_BI_ATTN_LOSSES = pickle.load(open(LSTM_BI_ATTN_LOSSES_PATH, mode='rb'))\n",
    "GRU_BI_ATTN_LOSSES = pickle.load(open(GRU_BI_ATTN_LOSSES_PATH, mode='rb'))\n",
    "LSTM_UNI_LOSSES = pickle.load(open(LSTM_UNI_LOSSES_PATH, mode='rb'))\n",
    "GRU_UNI_LOSSES = pickle.load(open(GRU_UNI_LOSSES_PATH, mode='rb'))\n",
    "LSTM_BI_LOSSES = pickle.load(open(LSTM_BI_LOSSES_PATH, mode='rb'))\n",
    "GRU_BI_LOSSES = pickle.load(open(GRU_BI_LOSSES_PATH, mode='rb'))\n",
    "\n",
    "# print(\"LSTM_UNI_ATTN_LOSSES: \", LSTM_UNI_ATTN_LOSSES)\n",
    "# print(\"GRU_UNI_ATTN_LOSSES: \", GRU_UNI_ATTN_LOSSES)\n",
    "# print(\"LSTM_BI_ATTN_LOSSES: \", LSTM_BI_ATTN_LOSSES)\n",
    "# print(\"GRU_BI_ATTN_LOSSES: \", GRU_BI_ATTN_LOSSES)\n",
    "# print(\"LSTM_UNI_LOSSES: \", LSTM_UNI_LOSSES)\n",
    "# print(\"GRU_UNI_LOSSES: \", GRU_UNI_LOSSES)\n",
    "# print(\"LSTM_BI_LOSSES: \", LSTM_BI_LOSSES)\n",
    "print(\"GRU_BI_LOSSES: \", GRU_BI_LOSSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.908,\n",
       " 9.8100004,\n",
       " 8.5419998,\n",
       " 8.1020002,\n",
       " 4.717,\n",
       " 4.9000001,\n",
       " 4.0419998,\n",
       " 5.2880001,\n",
       " 4.777,\n",
       " 4.283,\n",
       " 4.5219998,\n",
       " 3.721,\n",
       " 4.5890002,\n",
       " 4.9260001,\n",
       " 3.306,\n",
       " 3.8469999,\n",
       " 4.5640001,\n",
       " 3.431,\n",
       " 3.5420001,\n",
       " 3.0869999,\n",
       " 3.3469999,\n",
       " 3.4549999,\n",
       " 3.322,\n",
       " 3.2620001,\n",
       " 3.7,\n",
       " 3.1930001,\n",
       " 3.1140001,\n",
       " 2.78,\n",
       " 3.2219999,\n",
       " 2.8540001,\n",
       " 3.2379999,\n",
       " 3.6819999,\n",
       " 3.2149999,\n",
       " 3.526,\n",
       " 2.7509999,\n",
       " 2.7839999,\n",
       " 3.783,\n",
       " 3.4920001,\n",
       " 2.6370001,\n",
       " 3.211,\n",
       " 2.3989999,\n",
       " 3.2090001,\n",
       " 3.3169999,\n",
       " 2.836,\n",
       " 3.1900001,\n",
       " 2.404,\n",
       " 3.4100001,\n",
       " 2.845,\n",
       " 3.4089999,\n",
       " 4.0279999,\n",
       " 2.845,\n",
       " 2.605,\n",
       " 2.983,\n",
       " 2.477,\n",
       " 2.5120001,\n",
       " 3.211,\n",
       " 2.7520001,\n",
       " 3.582,\n",
       " 2.5309999,\n",
       " 3.256,\n",
       " 3.05,\n",
       " 2.6919999,\n",
       " 2.3399999,\n",
       " 2.641,\n",
       " 2.938,\n",
       " 2.5539999,\n",
       " 2.8310001,\n",
       " 3.2,\n",
       " 3.2320001,\n",
       " 2.516,\n",
       " 2.576,\n",
       " 2.5739999,\n",
       " 2.7360001,\n",
       " 3.4349999,\n",
       " 3.5350001,\n",
       " 3.5020001,\n",
       " 3.2309999,\n",
       " 2.7260001,\n",
       " 2.9630001,\n",
       " 2.6949999,\n",
       " 2.5469999,\n",
       " 2.9920001,\n",
       " 2.9619999,\n",
       " 2.9590001,\n",
       " 2.5020001,\n",
       " 3.4560001,\n",
       " 2.8050001,\n",
       " 3.0450001,\n",
       " 3.3759999,\n",
       " 2.5190001,\n",
       " 2.744,\n",
       " 2.569,\n",
       " 2.7739999,\n",
       " 3.184,\n",
       " 3.286,\n",
       " 2.5510001,\n",
       " 3.3469999,\n",
       " 2.4990001,\n",
       " 2.993,\n",
       " 3.556,\n",
       " 2.7290001,\n",
       " 2.4400001,\n",
       " 2.8440001,\n",
       " 2.4360001,\n",
       " 3.1659999,\n",
       " 2.809,\n",
       " 3.053,\n",
       " 3.1170001,\n",
       " 2.5639999,\n",
       " 2.707,\n",
       " 3.25,\n",
       " 2.448,\n",
       " 3.0369999,\n",
       " 3.263,\n",
       " 2.437,\n",
       " 3.25,\n",
       " 2.608,\n",
       " 2.628,\n",
       " 3.7820001,\n",
       " 2.4990001,\n",
       " 2.8169999,\n",
       " 2.5580001,\n",
       " 2.9100001,\n",
       " 2.2690001,\n",
       " 2.7060001,\n",
       " 2.4820001,\n",
       " 3.013,\n",
       " 2.5999999,\n",
       " 2.937,\n",
       " 2.3959999,\n",
       " 3.1489999,\n",
       " 2.414,\n",
       " 3.563,\n",
       " 3.033,\n",
       " 3.299,\n",
       " 2.365,\n",
       " 3.6459999,\n",
       " 2.8150001,\n",
       " 2.3970001,\n",
       " 2.1489999,\n",
       " 2.598,\n",
       " 2.707,\n",
       " 2.7579999,\n",
       " 3.348,\n",
       " 2.9560001,\n",
       " 2.9070001,\n",
       " 2.655,\n",
       " 3.1589999,\n",
       " 2.188,\n",
       " 3.2579999,\n",
       " 2.243,\n",
       " 3.2190001,\n",
       " 3.0350001,\n",
       " 2.5309999,\n",
       " 2.7130001,\n",
       " 2.7490001,\n",
       " 2.5079999,\n",
       " 2.723,\n",
       " 2.9909999,\n",
       " 2.645,\n",
       " 2.171,\n",
       " 2.395,\n",
       " 2.513,\n",
       " 2.8829999,\n",
       " 2.836,\n",
       " 2.6619999,\n",
       " 3.168,\n",
       " 2.7950001,\n",
       " 3.395,\n",
       " 3.0350001,\n",
       " 2.3929999,\n",
       " 2.118,\n",
       " 2.967,\n",
       " 2.358,\n",
       " 2.325,\n",
       " 2.7030001,\n",
       " 2.3499999,\n",
       " 2.1719999,\n",
       " 2.3800001,\n",
       " 3.517,\n",
       " 2.9430001,\n",
       " 2.9230001,\n",
       " 2.756,\n",
       " 2.796,\n",
       " 2.1789999,\n",
       " 3.5209999,\n",
       " 2.5150001,\n",
       " 3.237,\n",
       " 3.1259999,\n",
       " 2.904,\n",
       " 3.132,\n",
       " 2.8729999,\n",
       " 2.674,\n",
       " 2.757,\n",
       " 3.0090001,\n",
       " 2.4809999,\n",
       " 2.3970001,\n",
       " 2.4419999,\n",
       " 2.5739999,\n",
       " 2.763,\n",
       " 2.717,\n",
       " 3.148,\n",
       " 2.5810001,\n",
       " 2.575,\n",
       " 2.803,\n",
       " 2.385,\n",
       " 3.0380001,\n",
       " 2.3640001,\n",
       " 3.027,\n",
       " 2.47,\n",
       " 2.8099999,\n",
       " 2.5650001,\n",
       " 3.3340001,\n",
       " 3.2869999,\n",
       " 2.619,\n",
       " 2.7130001,\n",
       " 2.6389999,\n",
       " 3.0880001,\n",
       " 2.9630001,\n",
       " 2.635,\n",
       " 2.882,\n",
       " 3.027,\n",
       " 3.0179999,\n",
       " 2.5999999,\n",
       " 3.494,\n",
       " 3.026,\n",
       " 2.4519999,\n",
       " 2.6010001,\n",
       " 2.5179999,\n",
       " 2.421,\n",
       " 2.404,\n",
       " 2.415,\n",
       " 2.4200001,\n",
       " 2.8940001,\n",
       " 2.7650001,\n",
       " 2.875,\n",
       " 2.227,\n",
       " 2.74,\n",
       " 2.973,\n",
       " 2.9159999,\n",
       " 3.402,\n",
       " 3.22,\n",
       " 2.2780001,\n",
       " 2.286,\n",
       " 2.8239999,\n",
       " 2.349,\n",
       " 3.1070001,\n",
       " 2.513,\n",
       " 2.7550001,\n",
       " 3.039,\n",
       " 2.5409999,\n",
       " 2.2260001,\n",
       " 2.1789999,\n",
       " 2.9619999,\n",
       " 2.7179999,\n",
       " 2.6860001,\n",
       " 2.54,\n",
       " 2.3099999,\n",
       " 2.53,\n",
       " 2.5669999,\n",
       " 2.5910001,\n",
       " 2.1470001,\n",
       " 2.5780001,\n",
       " 2.5079999,\n",
       " 2.171,\n",
       " 3.3180001,\n",
       " 2.4690001,\n",
       " 2.3710001,\n",
       " 3.023,\n",
       " 2.711,\n",
       " 2.54,\n",
       " 2.2219999,\n",
       " 2.813,\n",
       " 2.6889999,\n",
       " 2.1989999,\n",
       " 2.1600001,\n",
       " 2.369,\n",
       " 2.362,\n",
       " 2.7279999,\n",
       " 2.6500001,\n",
       " 2.197,\n",
       " 2.1489999,\n",
       " 2.299,\n",
       " 2.303,\n",
       " 2.7920001,\n",
       " 2.7509999,\n",
       " 2.277,\n",
       " 2.4860001,\n",
       " 2.8499999,\n",
       " 2.855,\n",
       " 2.2349999,\n",
       " 2.6630001,\n",
       " 3.0999999,\n",
       " 2.5780001,\n",
       " 3.3369999,\n",
       " 2.533,\n",
       " 2.368,\n",
       " 2.098,\n",
       " 2.6889999,\n",
       " 3.007,\n",
       " 2.4070001,\n",
       " 2.756,\n",
       " 2.8789999,\n",
       " 2.7490001,\n",
       " 2.3870001,\n",
       " 2.6789999,\n",
       " 2.448,\n",
       " 2.707,\n",
       " 2.3929999,\n",
       " 2.0639999,\n",
       " 3.355,\n",
       " 3.2,\n",
       " 1.992,\n",
       " 2.7160001,\n",
       " 2.223,\n",
       " 2.79,\n",
       " 2.72,\n",
       " 2.28,\n",
       " 3.6659999,\n",
       " 2.553,\n",
       " 2.829,\n",
       " 2.6300001,\n",
       " 2.9890001,\n",
       " 2.3640001,\n",
       " 3.573,\n",
       " 2.7750001,\n",
       " 2.553,\n",
       " 2.6129999,\n",
       " 2.256,\n",
       " 2.928,\n",
       " 3.2650001,\n",
       " 3.0569999,\n",
       " 2.707,\n",
       " 2.6500001,\n",
       " 3.3940001,\n",
       " 2.4679999,\n",
       " 2.8499999,\n",
       " 2.707,\n",
       " 2.503,\n",
       " 3.0009999,\n",
       " 3.191,\n",
       " 2.0350001,\n",
       " 2.3710001,\n",
       " 2.556,\n",
       " 3.148,\n",
       " 2.51,\n",
       " 2.8789999,\n",
       " 2.8399999,\n",
       " 2.589,\n",
       " 2.4170001,\n",
       " 3.29,\n",
       " 2.5450001,\n",
       " 2.7590001,\n",
       " 3.02,\n",
       " 3.0039999,\n",
       " 2.7820001,\n",
       " 2.2219999,\n",
       " 2.783,\n",
       " 2.164,\n",
       " 1.98,\n",
       " 2.3099999,\n",
       " 2.677,\n",
       " 2.5420001,\n",
       " 2.7620001,\n",
       " 2.438,\n",
       " 2.5039999,\n",
       " 2.3699999,\n",
       " 2.0650001,\n",
       " 3.4070001,\n",
       " 2.5829999,\n",
       " 3.2190001,\n",
       " 2.4679999,\n",
       " 2.3199999,\n",
       " 2.6359999,\n",
       " 2.7739999,\n",
       " 2.454,\n",
       " 2.619,\n",
       " 3.5039999,\n",
       " 2.428,\n",
       " 2.3870001,\n",
       " 2.092,\n",
       " 2.5880001,\n",
       " 2.802,\n",
       " 3.1170001,\n",
       " 2.161,\n",
       " 2.3659999,\n",
       " 2.227,\n",
       " 2.414,\n",
       " 2.1289999,\n",
       " 2.4909999,\n",
       " 2.256,\n",
       " 2.3710001,\n",
       " 2.4489999,\n",
       " 2.5139999,\n",
       " 2.4449999,\n",
       " 2.2780001,\n",
       " 2.1530001,\n",
       " 2.5910001,\n",
       " 2.793,\n",
       " 2.655,\n",
       " 2.1800001,\n",
       " 2.2479999,\n",
       " 2.178,\n",
       " 2.312,\n",
       " 2.046,\n",
       " 2.6429999,\n",
       " 2.148,\n",
       " 1.992,\n",
       " 2.9549999,\n",
       " 2.2750001,\n",
       " 2.977,\n",
       " 3.0079999,\n",
       " 2.2460001,\n",
       " 2.7460001,\n",
       " 3.131,\n",
       " 2.4679999,\n",
       " 2.9030001,\n",
       " 2.362,\n",
       " 2.102,\n",
       " 2.2049999,\n",
       " 2.6619999,\n",
       " 2.256,\n",
       " 2.599,\n",
       " 2.5780001,\n",
       " 2.4000001,\n",
       " 2.5,\n",
       " 2.3870001,\n",
       " 2.786,\n",
       " 2.6900001,\n",
       " 2.29,\n",
       " 2.4389999,\n",
       " 2.7880001,\n",
       " 2.4170001,\n",
       " 2.0769999,\n",
       " 2.0439999,\n",
       " 2.773,\n",
       " 2.0610001,\n",
       " 2.4059999,\n",
       " 3.1559999,\n",
       " 2.1659999,\n",
       " 2.3150001,\n",
       " 2.655,\n",
       " 2.3429999,\n",
       " 2.2149999,\n",
       " 2.7320001,\n",
       " 2.8559999,\n",
       " 3.1889999,\n",
       " 2.6719999,\n",
       " 2.839,\n",
       " 2.566,\n",
       " 2.0539999,\n",
       " 2.9560001,\n",
       " 2.5009999,\n",
       " 2.267,\n",
       " 2.829,\n",
       " 2.6270001,\n",
       " 2.5109999,\n",
       " 2.8640001,\n",
       " 2.8570001,\n",
       " 3.243,\n",
       " 2.5580001,\n",
       " 2.3570001,\n",
       " 2.3299999,\n",
       " 2.658,\n",
       " 2.7260001,\n",
       " 2.632,\n",
       " 1.8839999,\n",
       " 3.2019999,\n",
       " 2.6199999,\n",
       " 2.747,\n",
       " 2.2090001,\n",
       " 2.7279999,\n",
       " 2.0480001,\n",
       " 2.471,\n",
       " 3.0929999,\n",
       " 3.1689999,\n",
       " 2.7579999,\n",
       " 2.5120001,\n",
       " 2.7980001,\n",
       " 2.6860001,\n",
       " 2.766,\n",
       " 3.151,\n",
       " 2.7349999,\n",
       " 3.319,\n",
       " 2.5510001,\n",
       " 2.388,\n",
       " 2.3469999,\n",
       " 2.5150001,\n",
       " 2.539,\n",
       " 2.4579999,\n",
       " 2.401,\n",
       " 2.369,\n",
       " 2.325,\n",
       " 2.414,\n",
       " 2.9170001,\n",
       " 2.3610001,\n",
       " 2.517,\n",
       " 2.6459999,\n",
       " 2.743,\n",
       " 2.359,\n",
       " 2.138,\n",
       " 2.691,\n",
       " 2.4590001,\n",
       " 2.5220001,\n",
       " 2.9809999,\n",
       " 2.948,\n",
       " 2.5929999,\n",
       " 2.247,\n",
       " 2.5409999,\n",
       " 2.6670001,\n",
       " 2.299,\n",
       " 2.3699999,\n",
       " 2.4530001,\n",
       " 2.9130001,\n",
       " 2.747,\n",
       " 2.289,\n",
       " 2.543,\n",
       " 2.5239999,\n",
       " 2.635,\n",
       " 2.342,\n",
       " 2.438,\n",
       " 2.55,\n",
       " 2.4200001,\n",
       " 2.6229999,\n",
       " 2.5420001,\n",
       " 2.1259999,\n",
       " 2.444,\n",
       " 2.49,\n",
       " 2.6570001,\n",
       " 2.5650001,\n",
       " 2.6570001,\n",
       " 2.0550001,\n",
       " 2.2539999,\n",
       " 2.1659999,\n",
       " 2.5710001,\n",
       " 2.2809999,\n",
       " 2.599,\n",
       " 2.944,\n",
       " 2.5829999,\n",
       " 2.556,\n",
       " 3.405,\n",
       " 2.438,\n",
       " 2.5599999,\n",
       " 2.6259999,\n",
       " 2.5179999,\n",
       " 2.4119999,\n",
       " 2.9159999,\n",
       " 2.5999999,\n",
       " 2.323,\n",
       " 2.135,\n",
       " 2.1240001,\n",
       " 2.921,\n",
       " 2.0829999,\n",
       " 2.3759999,\n",
       " 2.316,\n",
       " 2.704,\n",
       " 2.71,\n",
       " 2.6489999,\n",
       " 2.464,\n",
       " 2.5150001,\n",
       " 2.5239999,\n",
       " 2.757,\n",
       " 2.576,\n",
       " 2.4449999,\n",
       " 2.994,\n",
       " 2.9630001,\n",
       " 2.1989999,\n",
       " 2.1889999,\n",
       " 2.6259999,\n",
       " 2.4059999,\n",
       " 2.6919999,\n",
       " 2.4000001,\n",
       " 2.2079999,\n",
       " 2.5120001,\n",
       " 3.0120001,\n",
       " 2.332,\n",
       " 2.6960001,\n",
       " 2.8169999,\n",
       " 2.8870001,\n",
       " 2.3080001,\n",
       " 2.47,\n",
       " 1.867,\n",
       " 2.1429999,\n",
       " 2.4860001,\n",
       " 2.6429999,\n",
       " 2.3900001,\n",
       " 2.8559999,\n",
       " 2.1400001,\n",
       " 3.223,\n",
       " 2.9990001,\n",
       " 2.2179999,\n",
       " 2.5550001,\n",
       " 2.0899999,\n",
       " 2.575,\n",
       " 2.503,\n",
       " 2.733,\n",
       " 2.7880001,\n",
       " 2.4070001,\n",
       " 2.323,\n",
       " 2.6429999,\n",
       " 2.95,\n",
       " 2.6500001,\n",
       " 2.3740001,\n",
       " 2.8770001,\n",
       " 2.707,\n",
       " 2.55,\n",
       " 2.5999999,\n",
       " 2.8499999,\n",
       " 2.665,\n",
       " 2.5450001,\n",
       " 2.1429999,\n",
       " 2.773,\n",
       " 2.8280001,\n",
       " 3.2690001,\n",
       " 2.642,\n",
       " 2.977,\n",
       " 2.5650001,\n",
       " 2.4860001,\n",
       " 2.8829999,\n",
       " 3.0480001,\n",
       " 2.3829999,\n",
       " 2.7869999,\n",
       " 3.0209999,\n",
       " 2.72,\n",
       " 2.3989999,\n",
       " 2.569,\n",
       " 2.369,\n",
       " 2.4389999,\n",
       " 2.7379999,\n",
       " 2.2820001,\n",
       " 2.451,\n",
       " 2.3180001,\n",
       " 2.6849999,\n",
       " 2.3959999,\n",
       " 2.6619999,\n",
       " 2.2149999,\n",
       " 2.895,\n",
       " 3.1589999,\n",
       " 2.881,\n",
       " 2.8310001,\n",
       " 2.072,\n",
       " 2.527,\n",
       " 2.5039999,\n",
       " 3.0450001,\n",
       " 2.385,\n",
       " 2.7160001,\n",
       " 3.155,\n",
       " 2.313,\n",
       " 2.003,\n",
       " 2.737,\n",
       " 2.737,\n",
       " 2.1689999,\n",
       " 2.3299999,\n",
       " 3.122,\n",
       " 2.523,\n",
       " 2.2490001,\n",
       " 2.2449999,\n",
       " 2.3829999,\n",
       " 2.3740001,\n",
       " 2.6530001,\n",
       " 2.6570001,\n",
       " 2.704,\n",
       " 2.1070001,\n",
       " 3.2750001,\n",
       " 2.217,\n",
       " 2.316,\n",
       " 2.3599999,\n",
       " 2.4000001,\n",
       " 2.7850001,\n",
       " 2.3540001,\n",
       " 2.7030001,\n",
       " 2.2,\n",
       " 2.5380001,\n",
       " 2.395,\n",
       " 2.3180001,\n",
       " 2.648,\n",
       " 3.033,\n",
       " 1.8329999,\n",
       " 2.2460001,\n",
       " 2.974,\n",
       " 2.5580001,\n",
       " 2.536,\n",
       " 2.1070001,\n",
       " 3.007,\n",
       " 2.654,\n",
       " 1.869,\n",
       " 2.4649999,\n",
       " 2.5940001,\n",
       " 2.2219999,\n",
       " 2.687,\n",
       " 2.0899999,\n",
       " 2.3570001,\n",
       " 2.7190001,\n",
       " 2.4170001,\n",
       " 2.391,\n",
       " 2.0650001,\n",
       " 2.227,\n",
       " 2.0929999,\n",
       " 1.882,\n",
       " 2.9879999,\n",
       " 2.1440001,\n",
       " 2.1329999,\n",
       " 2.0420001,\n",
       " 1.858,\n",
       " 1.896,\n",
       " 2.6719999,\n",
       " 2.8959999,\n",
       " 2.3440001,\n",
       " 2.661,\n",
       " 2.3629999,\n",
       " 1.776,\n",
       " 2.7869999,\n",
       " 2.983,\n",
       " 2.0610001,\n",
       " 2.6730001,\n",
       " 2.7449999,\n",
       " 2.556,\n",
       " 2.0840001,\n",
       " 3.2030001,\n",
       " 2.414,\n",
       " 2.747,\n",
       " 2.661,\n",
       " 2.158,\n",
       " 2.7869999,\n",
       " 2.293,\n",
       " 2.8,\n",
       " 2.6600001,\n",
       " 2.638,\n",
       " 2.7950001,\n",
       " 2.368,\n",
       " 3.02,\n",
       " 2.3269999,\n",
       " 2.3970001,\n",
       " 2.4809999,\n",
       " 2.7390001,\n",
       " 2.4349999,\n",
       " 2.777,\n",
       " 2.1170001,\n",
       " 2.6570001,\n",
       " 3.1849999,\n",
       " 3.263,\n",
       " 2.362,\n",
       " 2.592,\n",
       " 2.392,\n",
       " 2.152,\n",
       " 2.635,\n",
       " 2.7349999,\n",
       " 2.3269999,\n",
       " 2.3440001,\n",
       " 2.539,\n",
       " 2.1889999,\n",
       " 2.6819999,\n",
       " 2.513,\n",
       " 3.22,\n",
       " 2.0420001,\n",
       " 2.1800001,\n",
       " 2.8989999,\n",
       " 2.358,\n",
       " 3.279,\n",
       " 2.875,\n",
       " 3.006,\n",
       " 2.372,\n",
       " 2.302,\n",
       " 2.082,\n",
       " 2.194,\n",
       " 2.473,\n",
       " 2.405,\n",
       " 2.9189999,\n",
       " 2.609,\n",
       " 2.3410001,\n",
       " 2.2980001,\n",
       " 2.0739999,\n",
       " 2.5250001,\n",
       " 2.0780001,\n",
       " 2.154,\n",
       " 2.5280001,\n",
       " 2.7579999,\n",
       " 2.04,\n",
       " 2.8340001,\n",
       " 2.1919999,\n",
       " 2.2479999,\n",
       " 2.421,\n",
       " 2.494,\n",
       " 2.5309999,\n",
       " 2.954,\n",
       " 1.946,\n",
       " 2.5139999,\n",
       " 2.2939999,\n",
       " 2.812,\n",
       " 2.3570001,\n",
       " 2.0610001,\n",
       " 2.3150001,\n",
       " 1.877,\n",
       " 2.4879999,\n",
       " 2.918,\n",
       " 1.804,\n",
       " 2.2679999,\n",
       " 2.6010001,\n",
       " 2.046,\n",
       " 2.3499999,\n",
       " 1.948,\n",
       " 2.152,\n",
       " 2.1830001,\n",
       " 2.2379999,\n",
       " 2.2720001,\n",
       " 2.569,\n",
       " 2.2160001,\n",
       " 2.138,\n",
       " 2.013,\n",
       " 2.3410001,\n",
       " 2.0739999,\n",
       " 2.438,\n",
       " 2.8369999,\n",
       " 2.352,\n",
       " 2.539,\n",
       " 2.0929999,\n",
       " 2.0999999,\n",
       " 2.8139999,\n",
       " 2.658,\n",
       " 2.0320001,\n",
       " 2.5220001,\n",
       " 1.832,\n",
       " 2.5599999,\n",
       " 2.5739999,\n",
       " 2.1960001,\n",
       " 2.526,\n",
       " 1.8559999,\n",
       " 2.5899999,\n",
       " 2.263,\n",
       " 2.576,\n",
       " 3.1240001,\n",
       " 2.233,\n",
       " 2.0450001,\n",
       " 2.2980001,\n",
       " 1.979,\n",
       " 1.943,\n",
       " 2.6489999,\n",
       " 2.178,\n",
       " 2.756,\n",
       " 2.023,\n",
       " 2.566,\n",
       " 2.4519999,\n",
       " 2.0899999,\n",
       " 1.789,\n",
       " 2.079,\n",
       " 2.358,\n",
       " 1.965,\n",
       " 2.2709999,\n",
       " 2.5510001,\n",
       " 2.5599999,\n",
       " 2.085,\n",
       " 1.993,\n",
       " 2.0190001,\n",
       " 2.1689999,\n",
       " 2.73,\n",
       " 2.812,\n",
       " 2.717,\n",
       " 2.592,\n",
       " 2.1800001,\n",
       " 2.414,\n",
       " 2.0840001,\n",
       " 2.098,\n",
       " 2.3940001,\n",
       " 2.3280001,\n",
       " 2.3329999,\n",
       " 1.998,\n",
       " 2.839,\n",
       " 2.2320001,\n",
       " 2.4949999,\n",
       " 2.6719999,\n",
       " 2.0050001,\n",
       " 2.1800001,\n",
       " 2.1370001,\n",
       " 2.2650001,\n",
       " 2.5380001,\n",
       " 2.5699999,\n",
       " 2.0650001,\n",
       " 2.7279999,\n",
       " 2.033,\n",
       " 2.3559999,\n",
       " 2.9489999,\n",
       " 2.2320001,\n",
       " 2.069,\n",
       " 2.3529999,\n",
       " 1.965,\n",
       " 2.559,\n",
       " 2.2060001,\n",
       " 2.48,\n",
       " 2.5669999,\n",
       " 2.098,\n",
       " 2.1140001,\n",
       " 2.6670001,\n",
       " 1.969,\n",
       " 2.4089999,\n",
       " 2.642,\n",
       " 1.905,\n",
       " 2.612,\n",
       " 2.063,\n",
       " 2.1300001,\n",
       " 3.082,\n",
       " 1.921,\n",
       " 2.243,\n",
       " 2.0450001,\n",
       " 2.3199999,\n",
       " 1.878,\n",
       " 2.27,\n",
       " 1.9809999,\n",
       " 2.414,\n",
       " 2.096,\n",
       " 2.428,\n",
       " 1.967,\n",
       " 2.5280001,\n",
       " 1.937,\n",
       " 2.7869999,\n",
       " 2.487,\n",
       " 2.6760001,\n",
       " 1.957,\n",
       " 2.8599999,\n",
       " 2.3380001,\n",
       " 1.904,\n",
       " 1.719,\n",
       " 2.0899999,\n",
       " 2.283,\n",
       " 2.247,\n",
       " 2.7290001,\n",
       " 2.4530001,\n",
       " 2.4089999,\n",
       " 2.102,\n",
       " 2.6010001,\n",
       " 1.789,\n",
       " 2.7579999,\n",
       " 1.8559999,\n",
       " 2.576,\n",
       " 2.4779999,\n",
       " 2.0450001,\n",
       " 2.161,\n",
       " 2.1340001,\n",
       " 2.059,\n",
       " 2.1500001,\n",
       " 2.4030001,\n",
       " 2.1600001,\n",
       " 1.706,\n",
       " 1.972,\n",
       " 1.989,\n",
       " 2.2780001,\n",
       " 2.233,\n",
       " 2.1270001,\n",
       " 2.5710001,\n",
       " 2.303,\n",
       " 2.6659999,\n",
       " 2.4849999,\n",
       " 1.923,\n",
       " 1.729,\n",
       " 2.4519999,\n",
       " 1.845,\n",
       " 1.975,\n",
       " 2.2969999,\n",
       " 1.955,\n",
       " 1.8,\n",
       " 1.929,\n",
       " 2.7550001,\n",
       " 2.4549999,\n",
       " 2.415,\n",
       " 2.283,\n",
       " 2.3940001,\n",
       " 1.6849999,\n",
       " 2.858,\n",
       " 2.1389999,\n",
       " 2.612,\n",
       " 2.589,\n",
       " 2.3870001,\n",
       " 2.6140001,\n",
       " 2.3670001,\n",
       " 2.2149999,\n",
       " 2.2179999,\n",
       " 2.45,\n",
       " 2.0350001,\n",
       " 1.994,\n",
       " 2.0339999,\n",
       " 2.0840001,\n",
       " 2.2550001,\n",
       " 2.2260001,\n",
       " 2.569,\n",
       " 2.0680001,\n",
       " 2.1329999,\n",
       " 2.345,\n",
       " 1.999,\n",
       " 2.5280001,\n",
       " 1.845,\n",
       " 2.4619999,\n",
       " 2.0409999,\n",
       " 2.329,\n",
       " 2.109,\n",
       " 2.789,\n",
       " 2.677,\n",
       " 2.223,\n",
       " 2.276,\n",
       " 2.1630001,\n",
       " 2.572,\n",
       " 2.503,\n",
       " ...)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_losses, batch_times = zip(*GRU_BI_LOSSES)\n",
    "batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97787162b0>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD8CAYAAACINTRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nECZ1IqIQ8v8gi4Ib0gHdGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f955008e588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.LSTMCell"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
